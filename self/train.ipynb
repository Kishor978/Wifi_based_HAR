{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pywt\n",
    "import logging\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler,Dataset\n",
    "from torchinfo import summary\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import decomposition\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate_single_phase(phases):\n",
    "    \"\"\"\n",
    "    Calibrate phase data from the single time moment\n",
    "    Based on:\n",
    "        https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/sys031fp.pdf\n",
    "        https://github.com/ermongroup/Wifi_Activity_Recognition/.../phase_calibration.m\n",
    "\n",
    "    :param phases: phase in the single time moment, np.array of shape(1, num of subcarriers)\n",
    "    :return: calibrate phase, np.array of shape(1, num of subcarriers)\n",
    "    \"\"\"\n",
    "\n",
    "    phases = np.array(phases)\n",
    "    difference = 0\n",
    "\n",
    "    calibrated_phase, calibrated_phase_final = np.zeros_like(phases), np.zeros_like(phases)\n",
    "    calibrated_phase[0] = phases[0]\n",
    "\n",
    "    phases_len = phases.shape[0]\n",
    "\n",
    "    for i in range(1, phases_len):\n",
    "        temp = phases[i] - phases[i - 1]\n",
    "\n",
    "        if abs(temp) > np.pi:\n",
    "            difference = difference + 1 * np.sign(temp)\n",
    "\n",
    "        calibrated_phase[i] = phases[i] - difference * 2 * np.pi\n",
    "\n",
    "    k = (calibrated_phase[-1] - calibrated_phase[0]) / (phases_len - 1)\n",
    "    b = np.mean(calibrated_phase)\n",
    "\n",
    "    for i in range(phases_len):\n",
    "        calibrated_phase_final[i] = calibrated_phase[i] - k * i - b\n",
    "\n",
    "    return calibrated_phase_final\n",
    "\n",
    "def calibrate_phase(phases):\n",
    "    \"\"\"\n",
    "    Calibrate phase data based on the following method:\n",
    "        https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/sys031fp.pdf\n",
    "        https://github.com/ermongroup/Wifi_Activity_Recognition/.../phase_calibration.m\n",
    "\n",
    "    :param phases: np.array of shape(data len, num of subcarries)\n",
    "    :return: calibrated phases: np.array of shape(data len, num of subcarriers)\n",
    "    \"\"\"\n",
    "\n",
    "    calibrated_phases = np.zeros_like(phases)\n",
    "\n",
    "    for i in range(phases.shape[0]):\n",
    "        calibrated_phases[i] = calibrate_single_phase(np.unwrap(phases[i]))\n",
    "\n",
    "    return calibrated_phases\n",
    "\n",
    "def calibrate_amplitude(amplitudes, rssi=1):\n",
    "    \"\"\"\n",
    "    Simple amplitude normalization, that could be multiplied by rsii\n",
    "    ((data - min(data)) / (max(data) - min(data))) * rssi\n",
    "\n",
    "    :param amplitudes: np.array of shape(data len, num of subcarriers)\n",
    "    :param rssi: number\n",
    "    :return: normalized_amplitude: np.array of shape(data len, num of subcarriers)\n",
    "    \"\"\"\n",
    "\n",
    "    amplitudes = np.array(amplitudes)\n",
    "    return ((amplitudes - np.min(amplitudes)) / (np.max(amplitudes) - np.min(amplitudes))) * rssi\n",
    "\n",
    "\n",
    "def calibrate_amplitude_custom(amplitudes, min_val, max_val, rssi=1):\n",
    "    amplitudes = np.array(amplitudes)\n",
    "    return ((amplitudes - min_val) / (max_val - min_val)) * rssi\n",
    "\n",
    "\n",
    "\n",
    "def dwn_noise(vals):\n",
    "    data = vals.copy()\n",
    "    threshold = 0.06  # Threshold for filtering\n",
    "\n",
    "    w = pywt.Wavelet('sym5')\n",
    "    maxlev = pywt.dwt_max_level(data.shape[0], w.dec_len)\n",
    "\n",
    "    coeffs = pywt.wavedec(data, 'sym5', level=maxlev)\n",
    "\n",
    "    for i in range(1, len(coeffs)):\n",
    "        coeffs[i] = pywt.threshold(coeffs[i], threshold * max(coeffs[i]))\n",
    "\n",
    "    datarec = pywt.waverec(coeffs, 'sym5')\n",
    "\n",
    "    return datarec\n",
    "\n",
    "\n",
    "def hampel(vals_orig, k=7, t0=3):\n",
    "    # Make copy so original not edited\n",
    "    vals = pd.Series(vals_orig.copy())\n",
    "\n",
    "    # Hampel Filter\n",
    "    L = 1.4826\n",
    "\n",
    "    rolling_median = vals.rolling(k).median()\n",
    "    difference = np.abs(rolling_median - vals)\n",
    "    median_abs_deviation = difference.rolling(k).median()\n",
    "    threshold = t0 * L * median_abs_deviation\n",
    "    outlier_idx = difference > threshold\n",
    "    vals[outlier_idx] = rolling_median\n",
    "\n",
    "    # print(\"vals: \", vals.shape)\n",
    "    return vals.to_numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_BiLSTM_Attention(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, dropout_rate, bidirectional, output_dim, seq_dim):\n",
    "        super(CNN_BiLSTM_Attention, self).__init__()\n",
    "\n",
    "        # CNN layers with ReLU activation, BatchNorm, and MaxPool\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3, 3), padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n",
    "\n",
    "        # Compute H and W dynamically\n",
    "        self.H = input_dim // 4  # Approximate feature map size after pooling\n",
    "        self.W = seq_dim // 4\n",
    "\n",
    "        # BiLSTM\n",
    "        lstm_input_size = 64 * self.H\n",
    "        self.bilstm = nn.LSTM(\n",
    "            input_size=lstm_input_size,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=layer_dim,\n",
    "            dropout=dropout_rate if layer_dim > 1 else 0,\n",
    "            bidirectional=bidirectional,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        # Attention mechanism\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.fc_out = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout_rate)  # Extra dropout for regularization\n",
    "\n",
    "    def forward(self, x):\n",
    "        # CNN Processing\n",
    "        x = torch.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.maxpool1(x)  # Apply MaxPool after first conv block\n",
    "        \n",
    "        x = torch.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.maxpool2(x)  # Apply MaxPool after second conv block\n",
    "\n",
    "        # Reshape for BiLSTM\n",
    "        batch_size = x.size(0)\n",
    "        x = x.permute(0, 3, 1, 2).contiguous().view(batch_size, self.W, -1)\n",
    "\n",
    "        # BiLSTM Processing\n",
    "        lstm_out, _ = self.bilstm(x)  # Shape: (batch, W, hidden_dim * num_directions)\n",
    "\n",
    "        # Attention Weights\n",
    "        attn_scores = self.attention(lstm_out)  # Shape: (batch, W, 1)\n",
    "        attn_weights = torch.softmax(attn_scores.squeeze(-1), dim=-1)  # Shape: (batch, W)\n",
    "\n",
    "        # Context Vector\n",
    "        context_vector = torch.sum(lstm_out * attn_weights.unsqueeze(-1), dim=1)\n",
    "\n",
    "        # Fully Connected Layer\n",
    "        out = self.fc_out(self.dropout(context_vector))\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBCARRIES_NUM=52\n",
    "\n",
    "def read_csi_data_from_csv(path_to_csv,  antenna_pairs=1):\n",
    "    \"\"\"\n",
    "    Read csi data(amplitude, phase) from .csv data\n",
    "\n",
    "    :param path_to_csv: string\n",
    "    :param is_five_hhz: boolean\n",
    "    :param antenna_pairs: integer\n",
    "    :return: (amplitudes, phases) => (np.array of shape(data len, num_of_subcarriers * antenna_pairs),\n",
    "                                     np.array of shape(data len, num_of_subcarriers * antenna_pairs))\n",
    "    \"\"\"\n",
    "\n",
    "    data = pd.read_csv(path_to_csv, header=None).values\n",
    "    # print(\"shape\",data.shape)\n",
    "\n",
    "    \n",
    "    subcarries_num = SUBCARRIES_NUM\n",
    "\n",
    "    # 1 -> to skip subcarriers numbers in data\n",
    "    amplitudes = data[:, :subcarries_num *  antenna_pairs]\n",
    "    phases = data[:, subcarries_num * antenna_pairs:]\n",
    "\n",
    "    return amplitudes, phases\n",
    "\n",
    "\n",
    "def read_labels_from_csv(path_to_csv, expected_length):\n",
    "    \"\"\"\n",
    "    Read labels (human activities) from csv file and remove unwanted classes.\n",
    "    \n",
    "    :param path_to_csv: string\n",
    "    :return: filtered labels, np.array of shape (data_len, 1)\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(path_to_csv, header=None).values\n",
    "    labels = data[:, 1]\n",
    "    \n",
    "    # Ensure labels match the expected length\n",
    "    if len(labels) > expected_length:\n",
    "        labels = labels[:expected_length]  # Trim extra labels if any\n",
    "    elif len(labels) < expected_length:\n",
    "        raise ValueError(f\"Label file {path_to_csv} has fewer rows than CSI data!\")\n",
    "\n",
    "    return labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBCARRIES_NUM=52\n",
    "\n",
    "\n",
    "PHASE_MIN, PHASE_MAX = 3.1389, 3.1415\n",
    "AMP_MIN, AMP_MAX = 0.0, 577.6582\n",
    "\n",
    "\n",
    "def csi_data(csis):\n",
    "    \"\"\"\n",
    "    Read csi data(amplitude, phase) from .csv data\n",
    "\n",
    "    :param path_to_csv: string\n",
    "    :param is_five_hhz: boolean\n",
    "    :param antenna_pairs: integer\n",
    "    :return: (amplitudes, phases) => (np.array of shape(data len, num_of_subcarriers * antenna_pairs),\n",
    "                                     np.array of shape(data len, num_of_subcarriers * antenna_pairs))\n",
    "    \"\"\"\n",
    "    subcarries_num = SUBCARRIES_NUM\n",
    "    amplitudes_list = []\n",
    "    phases_list = []\n",
    "\n",
    "    for data in csis:\n",
    "        if len(data) != subcarries_num  * 2:\n",
    "            raise ValueError(f\"Data length mismatch: expected {subcarries_num * 2}, got {len(data)}\")\n",
    "\n",
    "        amplitudes = data[:subcarries_num ]\n",
    "        phases = data[subcarries_num :]\n",
    "        \n",
    "        amplitudes_list.append(amplitudes)\n",
    "        phases_list.append(phases)\n",
    "\n",
    "    return np.array(amplitudes_list), np.array(phases_list)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "class CSIDataset(Dataset):\n",
    "    \"\"\"CSI Dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, train_csi, labels, window_size=32, step=1,is_training=False):\n",
    "        self.is_training = is_training\n",
    "        self.amplitudes, self.phases= csi_data(train_csi)\n",
    "        # print(\"len\",len(self.amplitudes))\n",
    "        # print(self.phases.shape)\n",
    "        self.labels = labels\n",
    " \n",
    "        self.amplitudes = calibrate_amplitude(self.amplitudes)\n",
    "\n",
    "        pca = decomposition.PCA(n_components=12)\n",
    "\n",
    "        self.amplitudes_pca = []\n",
    "\n",
    "        data_len = self.phases.shape[0]\n",
    "        print('data_len',data_len)\n",
    "        for i in range(self.phases.shape[1]):\n",
    "            self.amplitudes[:data_len, i] = dwn_noise(hampel(self.amplitudes[:, i]))[\n",
    "                :data_len\n",
    "            ]\n",
    "        # print(\"Amplitudes shape:\", self.amplitudes.shape)\n",
    "        self.amplitudes_pca = pca.fit_transform(self.amplitudes)\n",
    "        # print(\"PCA output shape:\", self.amplitudes_pca.shape)\n",
    "        self.explained_variance_ratio = pca.explained_variance_ratio_\n",
    "        print(\"Explained variance ratio:\", self.explained_variance_ratio)\n",
    "        self.cumulative_explained_variance_ratio = np.cumsum(\n",
    "            self.explained_variance_ratio\n",
    "        )\n",
    "        print(\"Cumulative explained variance ratio:\", self.cumulative_explained_variance_ratio)\n",
    "        self.amplitudes_pca = np.array(self.amplitudes_pca)\n",
    "        self.label_keys = list(set(self.labels))\n",
    "        self.class_to_idx = {\n",
    "            \"standing\": 0,\n",
    "            \"walking\": 1,\n",
    "            \"jumping\": 2,\n",
    "            \"no_person\": 3,\n",
    "        }\n",
    "        self.idx_to_class = {v: k for k, v in self.class_to_idx.items()}\n",
    "\n",
    "        self.window = window_size\n",
    "        if window_size == -1:\n",
    "            self.window = self.labels.shape[0] - 1\n",
    "\n",
    "        self.step = step\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.window == 0:\n",
    "            return (\n",
    "                np.append(self.amplitudes[idx], self.phases[idx]),\n",
    "                self.class_to_idx[self.labels[idx + self.window - 1]],\n",
    "            )\n",
    "\n",
    "        idx = idx * self.step\n",
    "        all_xs = []\n",
    "\n",
    "        for index in range(idx, idx + self.window):\n",
    "        # Load the amplitude and PCA data for this timestep\n",
    "            amplitude = self.amplitudes[index]\n",
    "            phase= self.phases[index]\n",
    "            pca = self.amplitudes_pca[index]\n",
    "\n",
    "            # Combine features\n",
    "            combined = np.append(phase, amplitude)\n",
    "\n",
    "            # Add noise to this individual sample \n",
    "            if self.is_training:\n",
    "                noise = np.random.normal(0, 0.01, size=combined.shape)\n",
    "                combined += noise\n",
    "\n",
    "            all_xs.append(combined)\n",
    "\n",
    "\n",
    "        return np.array(all_xs), self.class_to_idx[self.labels[idx + self.window - 1]]\n",
    "\n",
    "    def __len__(self):\n",
    "        length = max(1, int((self.labels.shape[0] - self.window) // self.step) + 1)\n",
    "        print(f\"CSIDataset length: {length}\")  # Debugging\n",
    "        return length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-28 13:21:16,434 - INFO - Device: cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amplitudes Shape: (355860, 52)\n",
      "max: 132.3782459469833\n",
      "min: 0.0\n",
      "Phases Shape: (355860, 52)\n",
      "max: 3.141592653589793\n",
      "min: -3.1266683885997084\n",
      "Scaled Amplitudes Shape: (355860, 52)\n",
      "scaled max: 1.0\n",
      "scaled min: 0.0\n",
      "Scaled Phases Shape: (355860, 52)\n",
      "scaled max: 1.0000000000000002\n",
      "scaled min: -1.0\n",
      "Train class distribution: {'jumping': 71172, 'no_person': 71172, 'standing': 71172, 'walking': 71172}\n",
      "Validation class distribution: {'jumping': 17793, 'no_person': 17793, 'standing': 17793, 'walking': 17793}\n",
      "data_len 284688\n",
      "Explained variance ratio: [0.77007663 0.0748044  0.01985271 0.01184649 0.00771351 0.00626069\n",
      " 0.00447664 0.00425141 0.00399074 0.00356864 0.00351989 0.00333974]\n",
      "Cumulative explained variance ratio: [0.77007663 0.84488103 0.86473374 0.87658024 0.88429375 0.89055444\n",
      " 0.89503108 0.89928248 0.90327322 0.90684186 0.91036175 0.91370149]\n",
      "data_len 71172\n",
      "Explained variance ratio: [0.77591428 0.07291508 0.01918219 0.0116129  0.0076221  0.00619472\n",
      " 0.00450321 0.00417915 0.0038408  0.00345344 0.00341703 0.00329071]\n",
      "Cumulative explained variance ratio: [0.77591428 0.84882937 0.86801156 0.87962446 0.88724656 0.89344128\n",
      " 0.89794449 0.90212363 0.90596443 0.90941787 0.9128349  0.91612561]\n",
      "CSIDataset length: 70917\n",
      "Dataset size: 70917\n",
      "CSIDataset length: 70917\n",
      "Max index in dataset: 70916\n",
      "CSIDataset length: 17538\n",
      "Max index in dataset: 17537\n",
      "Sample Weights Shape: (70916,)\n",
      "Unique Weights: [0.98741298 0.99662713 1.00555839 1.01071775]\n",
      "Sampler Length: 70916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Wifi_based_HAR\\venv\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
      "Epoch 1:   0%|          | 2/1108 [01:14<11:27:27, 37.29s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 305\u001b[0m\n\u001b[0;32m    302\u001b[0m         logging\u001b[38;5;241m.\u001b[39minfo\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 305\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 233\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    230\u001b[0m y_batch \u001b[38;5;241m=\u001b[39m y_batch\u001b[38;5;241m.\u001b[39mlong()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m    232\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m--> 233\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    234\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, y_batch)\n\u001b[0;32m    236\u001b[0m \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n",
      "File \u001b[1;32me:\\Wifi_based_HAR\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\Wifi_based_HAR\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 53\u001b[0m, in \u001b[0;36mCNN_BiLSTM_Attention.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     50\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(batch_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# BiLSTM Processing\u001b[39;00m\n\u001b[1;32m---> 53\u001b[0m lstm_out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbilstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Shape: (batch, W, hidden_dim * num_directions)\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# Attention Weights\u001b[39;00m\n\u001b[0;32m     56\u001b[0m attn_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention(lstm_out)  \u001b[38;5;66;03m# Shape: (batch, W, 1)\u001b[39;00m\n",
      "File \u001b[1;32me:\\Wifi_based_HAR\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\Wifi_based_HAR\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32me:\\Wifi_based_HAR\\venv\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:878\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    875\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[0;32m    877\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 878\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[0;32m    882\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Configure logging\n",
    "log_filename = \"training.log\"\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(log_filename),  # Log to a file\n",
    "        logging.StreamHandler(),  # Log to the console\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Cuda support\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "logging.info(\"Device: {}\".format(device))\n",
    "\n",
    "# Define dataset structure\n",
    "# DATASET_FOLDER = \"/content/drive/MyDrive/data\"\n",
    "DATASET_FOLDER=\"E:\\\\Wifi_based_HAR\\\\preprocessing\\\\merged\"\n",
    "\n",
    "# LSTM Model parameters\n",
    "input_dim = 104  \n",
    "hidden_dim = 512\n",
    "layer_dim = 2\n",
    "output_dim = 4\n",
    "dropout_rate = 0.2\n",
    "bidirectional = False\n",
    "SEQ_DIM = 1024\n",
    "DATA_STEP = 4\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS_NUM = 100\n",
    "LEARNING_RATE = 0.0001\n",
    "\n",
    "def save_checkpoint(state, filename=\"checkpoint.pth\"):\n",
    "    torch.save(state, filename)\n",
    "    logging.info(f\"Checkpoint saved: {filename}\")\n",
    "\n",
    "\n",
    "def load_checkpoint(filename=\"checkpoint.pth\"):\n",
    "    if torch.cuda.is_available():\n",
    "        checkpoint = torch.load(filename)\n",
    "    else:\n",
    "        checkpoint = torch.load(filename, map_location=torch.device(\"cpu\"))\n",
    "\n",
    "    logging.info(f\"Checkpoint loaded: {filename}\")\n",
    "    return checkpoint\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def read_all_data_from_files(data_path, label_path, antenna_pairs=1):\n",
    "    \"\"\"\n",
    "    Read CSI and labels from merged CSV files and apply scaling to amplitudes and phases.\n",
    "    \"\"\"\n",
    "    amplitudes, phases = read_csi_data_from_csv(data_path, antenna_pairs)\n",
    "    labels = read_labels_from_csv(label_path, len(amplitudes))\n",
    "\n",
    "    # Convert to numpy arrays if not already\n",
    "    amplitudes = np.array(amplitudes)\n",
    "    print(\"Amplitudes Shape:\", amplitudes.shape)\n",
    "    print(\"max:\", np.max(amplitudes))\n",
    "    print(\"min:\", np.min(amplitudes))\n",
    "    phases = np.array(phases)\n",
    "    print(\"Phases Shape:\", phases.shape)\n",
    "    print(\"max:\", np.max(phases))\n",
    "    print(\"min:\", np.min(phases))\n",
    "\n",
    "    # Initialize scalers\n",
    "    amp_scaler = MinMaxScaler()\n",
    "    phase_scaler = MinMaxScaler(feature_range=(-1, 1))  # For phases (-π to π)\n",
    "\n",
    "    # Reshape if necessary (for 1D arrays)\n",
    "    if len(amplitudes.shape) == 1:\n",
    "        amplitudes = amplitudes.reshape(-1, 1)\n",
    "    if len(phases.shape) == 1:\n",
    "        phases = phases.reshape(-1, 1)\n",
    "\n",
    "    # Apply scaling\n",
    "    scaled_amplitudes = amp_scaler.fit_transform(amplitudes)\n",
    "    print(\"Scaled Amplitudes Shape:\", scaled_amplitudes.shape)\n",
    "    print(\"scaled max:\", np.max(scaled_amplitudes))\n",
    "    print(\"scaled min:\", np.min(scaled_amplitudes))\n",
    "    scaled_phases = phase_scaler.fit_transform(phases)\n",
    "    print(\"Scaled Phases Shape:\", scaled_phases.shape)\n",
    "    print(\"scaled max:\", np.max(scaled_phases))\n",
    "    print(\"scaled min:\", np.min(scaled_phases))\n",
    "    return scaled_amplitudes, scaled_phases, labels\n",
    "\n",
    "def get_class_weights(labels):\n",
    "    \"\"\"Compute inverse class frequencies to balance sampling.\"\"\"\n",
    "    class_to_idx = {\n",
    "        \"standing\": 0,\n",
    "        \"walking\": 1,\n",
    "        \"jumping\": 2,\n",
    "        \"no_person\": 3,\n",
    "    }\n",
    "\n",
    "    # Convert string labels to integers\n",
    "    labels = np.array([class_to_idx[label] for label in labels])\n",
    "    class_counts = np.bincount(labels)  # Count occurrences of each class\n",
    "    total_samples = len(labels)\n",
    "    class_weights = total_samples / (len(class_counts) * class_counts)  # Inverse frequency\n",
    "    sample_weights = np.array([class_weights[label] for label in labels])\n",
    "    return sample_weights\n",
    "\n",
    "def load_data():\n",
    "    # Load merged CSI data and labels\n",
    "    data_path = os.path.join(DATASET_FOLDER, \"data.csv\")\n",
    "    label_path = os.path.join(DATASET_FOLDER, \"label.csv\")\n",
    "    amplitudes, phases, labels = read_all_data_from_files(data_path, label_path)\n",
    "\n",
    "    # print(\"Label shape:\", labels.shape)\n",
    "    # print(\"Amplitudes shape:\", amplitudes.shape)\n",
    "\n",
    "    # Concatenate amplitude and phase data for input features\n",
    "    csi_data = np.hstack((amplitudes, phases))\n",
    "\n",
    "    # Shuffle the dataset before splitting (optional, useful if classes are sequential)\n",
    "    indices = np.arange(len(labels))\n",
    "    np.random.shuffle(indices)\n",
    "    csi_data, labels = csi_data[indices], labels[indices]\n",
    "\n",
    "    # Stratified split to maintain class balance\n",
    "    train_csi, val_csi, train_labels, val_labels = train_test_split(\n",
    "        csi_data, labels, test_size=0.2, stratify=labels, random_state=42\n",
    "    )\n",
    "    \n",
    "    unique, counts = np.unique(train_labels, return_counts=True)\n",
    "    print(\"Train class distribution:\", dict(zip(unique, counts)))\n",
    "\n",
    "    unique, counts = np.unique(val_labels, return_counts=True)\n",
    "    print(\"Validation class distribution:\", dict(zip(unique, counts)))\n",
    "\n",
    "\n",
    "    # Compute normalization stats on training set\n",
    "    train_mean = np.mean(train_csi, axis=0)\n",
    "    train_std = np.std(train_csi, axis=0) + 1e-8  # Avoid division by zero\n",
    "    train_csi = (train_csi - train_mean) / train_std\n",
    "    val_csi = (val_csi - train_mean) / train_std\n",
    "\n",
    "    # Create datasets\n",
    "    train_dataset = CSIDataset(\n",
    "        train_csi, train_labels, window_size=SEQ_DIM, step=DATA_STEP, is_training=True\n",
    "    )\n",
    "    val_dataset = CSIDataset(\n",
    "        val_csi, val_labels, window_size=SEQ_DIM, step=DATA_STEP, is_training=False\n",
    "    )\n",
    "    print(f\"Dataset size: {len(train_dataset)}\")\n",
    "    print(f\"Max index in dataset: {max(range(len(train_dataset)))}\")\n",
    "    print(f\"Max index in dataset: {max(range(len(val_dataset)))}\")\n",
    "\n",
    "    \n",
    "    # Compute weights for stratified sampling\n",
    "    # Adjust sample weights to match the new dataset size\n",
    "    windowed_labels = [train_labels[idx + SEQ_DIM - 1] for idx in range(0, len(train_labels) - SEQ_DIM, DATA_STEP)]\n",
    "    sample_weights = get_class_weights(np.array(windowed_labels))\n",
    "    \n",
    "    # num_samples = len(train_dataset)\n",
    "    \n",
    "    sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "    print(f\"Sample Weights Shape: {sample_weights.shape}\")\n",
    "    print(f\"Unique Weights: {np.unique(sample_weights)}\")\n",
    "    print(f\"Sampler Length: {len(sampler)}\")\n",
    "\n",
    "    # DataLoaders\n",
    "    trn_dl = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=sampler, drop_last=True)\n",
    "    val_dl = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=True)\n",
    "\n",
    "    return trn_dl, val_dl\n",
    "\n",
    "\n",
    "def train():\n",
    "    save_dir = \"saved_models\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # Initialize metrics\n",
    "    patience, trials, best_acc = 10, 0, 0\n",
    "    trn_dl, val_dl = load_data()\n",
    "\n",
    "    # Ensure input dimensions are valid\n",
    "    assert SEQ_DIM % 4 == 0, \"SEQ_DIM must be divisible by 4 for CNN operations\"\n",
    "    assert input_dim % 4 == 0, \"input_dim must be divisible by 4 for CNN operations\"\n",
    "\n",
    "    # Model initialization\n",
    "    model = CNN_BiLSTM_Attention(\n",
    "        input_dim=input_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        layer_dim=layer_dim,\n",
    "        dropout_rate=dropout_rate,\n",
    "        bidirectional=bidirectional,\n",
    "        output_dim=output_dim,\n",
    "        seq_dim=SEQ_DIM\n",
    "    ).to(device)\n",
    "    \n",
    "    # Print model summary\n",
    "    summary(model, input_size=(1, 1, input_dim, SEQ_DIM), device=device)\n",
    "\n",
    "    # Loss, optimizer, and scheduler\n",
    "    # class_weights = torch.tensor(class_weights).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-5)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=3, verbose=True)\n",
    "\n",
    "    checkpoint_filename = os.path.join(save_dir, \"checkpoint.pth\")\n",
    "    start_epoch = 1\n",
    "\n",
    "    # Load checkpoint if available\n",
    "    if os.path.exists(checkpoint_filename):\n",
    "        try:\n",
    "            checkpoint = torch.load(checkpoint_filename, map_location=device)\n",
    "            model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "            optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "            scheduler.load_state_dict(checkpoint[\"scheduler_state_dict\"])\n",
    "            start_epoch = checkpoint[\"epoch\"] + 1\n",
    "            best_acc = checkpoint[\"best_acc\"]\n",
    "            logging.info(f\"Resumed training from epoch {start_epoch}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to load checkpoint: {str(e)}. Starting fresh training.\")\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(start_epoch, EPOCHS_NUM + 1):\n",
    "        model.train()\n",
    "        epoch_loss, correct, total = 0, 0, 0\n",
    "\n",
    "        for i, (x_batch, y_batch) in tqdm(enumerate(trn_dl), total=len(trn_dl), desc=f\"Epoch {epoch}\"):\n",
    "            x_batch = x_batch.unsqueeze(1).float().to(device)  # Ensure correct shape\n",
    "            y_batch = y_batch.long().to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "\n",
    "            # Backpropagation\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Apply gradient clipping\n",
    "            optimizer.step()\n",
    "\n",
    "            # Metrics tracking\n",
    "            epoch_loss += loss.item() * x_batch.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == y_batch).sum().item()\n",
    "            total += y_batch.size(0)\n",
    "\n",
    "        # Compute training metrics\n",
    "        train_loss = epoch_loss / total\n",
    "        train_acc = correct / total\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss, correct, total = 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for x_val, y_val in val_dl:\n",
    "                x_val = x_val.unsqueeze(1).float().to(device)\n",
    "                y_val = y_val.long().to(device)\n",
    "\n",
    "                outputs = model(x_val)\n",
    "                loss = criterion(outputs, y_val)\n",
    "\n",
    "                val_loss += loss.item() * x_val.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct += (predicted == y_val).sum().item()\n",
    "                total += y_val.size(0)\n",
    "\n",
    "        val_loss /= len(val_dl.dataset)\n",
    "        val_acc = correct / total\n",
    "\n",
    "        # Learning rate scheduler\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        logging.info(\n",
    "            f\"Epoch {epoch:3d} | Validation Loss: {val_loss:.4f}, \"\n",
    "            f\"Validation Acc.: {val_acc:.2%}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2%}\"\n",
    "        )\n",
    "        print(f\"Epoch {epoch:3d} | Validation Loss: {val_loss:.4f}, \"\n",
    "            f\"Validation Acc.: {val_acc:.2%}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2%}\")\n",
    "        if val_acc > best_acc:\n",
    "            trials = 0\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), os.path.join(save_dir, \"lstm_classifier_best.pth\"))\n",
    "            logging.info(f\"Epoch {epoch}: Best model saved with accuracy {best_acc:.2%}\")\n",
    "        else:\n",
    "            trials += 1\n",
    "            if trials >= patience:\n",
    "                logging.info(f\"Early stopping at epoch {epoch}\")\n",
    "                break\n",
    "\n",
    "        # Save checkpoint\n",
    "        torch.save({\n",
    "            \"epoch\": epoch,\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            \"scheduler_state_dict\": scheduler.state_dict(),\n",
    "            \"best_acc\": best_acc,\n",
    "        }, checkpoint_filename)\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # Logging\n",
    "        logging.info\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
