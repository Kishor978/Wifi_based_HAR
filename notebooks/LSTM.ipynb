{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(color_codes=True)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\") # to import from parent directory\n",
    "from dataset_loader import CSIDataset\n",
    "from utils import read_all_data, read_all_data_from_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_amplitudes, all_phases, all_labels = read_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1100x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_theme(color_codes=True)\n",
    "\n",
    "plt.figure(0, (11, 5))\n",
    "sns_plot = sns.countplot(all_labels, color=\"dodgerblue\", label=\"Compact\")\n",
    "\n",
    "# fig = sns_plot.get_figure()\n",
    "# fig.savefig(\"out.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distribution of lengths of time series activity data\n",
    "\n",
    "current_activity = None\n",
    "current_length = 0\n",
    "dist = {}\n",
    "\n",
    "for activity in all_labels:\n",
    "    if current_activity is None:\n",
    "        current_activity = activity\n",
    "        current_length = 1\n",
    "        continue\n",
    "\n",
    "    if activity == current_activity:\n",
    "        current_length += 1\n",
    "    else:\n",
    "        if not(current_activity in dist):\n",
    "            dist[current_activity] = []\n",
    "\n",
    "        dist[current_activity].append(current_length)\n",
    "\n",
    "        current_length = 1\n",
    "        current_activity = activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 7 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 7, figsize=(14, 5), sharey=True, sharex=True, dpi=100)\n",
    "i = 0\n",
    "for key in dist:\n",
    "    sns.histplot(dist[key], color=\"dodgerblue\", kde=True, ax=axes[i])\n",
    "    axes[i].set_xlabel(key)  # Set axis label for each subplot\n",
    "    i += 1\n",
    "\n",
    "plt.xlim(0, 1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CSIDataset([\n",
    "    \"../dataset/bedroom_lviv/1\",\n",
    "    \"../dataset/bedroom_lviv/2\",\n",
    "    \"../dataset/bedroom_lviv/3\",\n",
    "    \"../dataset/vitalnia_lviv/1/\",\n",
    "    \"../dataset/vitalnia_lviv/2/\",\n",
    "    \"../dataset/vitalnia_lviv/3/\",\n",
    "    \"../dataset/vitalnia_lviv/4/\"\n",
    "])\n",
    "\n",
    "val_dataset = CSIDataset([\n",
    "    \"../dataset/bedroom_lviv/4\",\n",
    "    \"../dataset/vitalnia_lviv/5/\"\n",
    "])\n",
    "\n",
    "trn_dl = DataLoader(train_dataset, batch_size=16, shuffle=False, num_workers=1)\n",
    "val_dl = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CyclicLR(_LRScheduler):\n",
    "\n",
    "    def __init__(self, optimizer, schedule, last_epoch=-1):\n",
    "        assert callable(schedule)\n",
    "        self.schedule = schedule\n",
    "        super().__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        return [self.schedule(self.last_epoch, lr) for lr in self.base_lrs]\n",
    "\n",
    "def cosine(t_max, eta_min=0):\n",
    "    def scheduler(epoch, base_lr):\n",
    "        t = epoch % t_max\n",
    "        return eta_min + (base_lr - eta_min)*(1 + np.cos(np.pi*t/t_max))/2\n",
    "\n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    \"\"\"Very simple implementation of LSTM-based time-series classifier.\"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "        self.rnn = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=False)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.batch_size = None\n",
    "        self.hidden = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0, c0 = self.init_hidden(x)\n",
    "        out, (hn, cn) = self.rnn(x.double(), (h0.double(), c0.double()))\n",
    "        # out = self.fc(out[:, -1, :].double())\n",
    "        out = self.fc(out[:, -1, :].double())\n",
    "        return out\n",
    "\n",
    "    def init_hidden(self, x):\n",
    "        h0 = torch.zeros(self.layer_dim, x.size(1), self.hidden_dim)\n",
    "        c0 = torch.zeros(self.layer_dim, x.size(1), self.hidden_dim)\n",
    "        # return [t.cuda() for t in (h0, c0)]\n",
    "        return [t for t in (h0, c0)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[ 0.1067,  0.1190,  0.1256,  ..., -0.9905,  0.3325, -0.0684],\n",
      "         [ 0.1089,  0.1222,  0.1268,  ..., -0.9993,  0.3281, -0.0785],\n",
      "         [ 0.1018,  0.1148,  0.1237,  ..., -1.0053,  0.3462, -0.0831],\n",
      "         ...,\n",
      "         [ 0.1213,  0.1291,  0.1398,  ..., -0.8901,  0.5428, -0.1321],\n",
      "         [ 0.1191,  0.1273,  0.1359,  ..., -0.8913,  0.2063, -0.0576],\n",
      "         [ 0.1221,  0.1359,  0.1407,  ..., -1.0975, -0.0969, -0.1210]],\n",
      "\n",
      "        [[ 0.1089,  0.1222,  0.1268,  ..., -0.9993,  0.3281, -0.0785],\n",
      "         [ 0.1018,  0.1148,  0.1237,  ..., -1.0053,  0.3462, -0.0831],\n",
      "         [ 0.1114,  0.1244,  0.1290,  ..., -1.0092,  0.3600, -0.0845],\n",
      "         ...,\n",
      "         [ 0.1191,  0.1273,  0.1359,  ..., -0.8913,  0.2063, -0.0576],\n",
      "         [ 0.1221,  0.1359,  0.1407,  ..., -1.0975, -0.0969, -0.1210],\n",
      "         [ 0.1149,  0.1274,  0.1373,  ..., -1.1007,  0.0471, -0.0737]],\n",
      "\n",
      "        [[ 0.1018,  0.1148,  0.1237,  ..., -1.0053,  0.3462, -0.0831],\n",
      "         [ 0.1114,  0.1244,  0.1290,  ..., -1.0092,  0.3600, -0.0845],\n",
      "         [ 0.1107,  0.1210,  0.1293,  ..., -1.0068,  0.3741, -0.0908],\n",
      "         ...,\n",
      "         [ 0.1221,  0.1359,  0.1407,  ..., -1.0975, -0.0969, -0.1210],\n",
      "         [ 0.1149,  0.1274,  0.1373,  ..., -1.1007,  0.0471, -0.0737],\n",
      "         [ 0.1186,  0.1245,  0.1366,  ..., -0.8085,  0.2051,  0.1152]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1156,  0.1267,  0.1354,  ..., -0.8828,  0.2875, -0.0517],\n",
      "         [ 0.1161,  0.1271,  0.1360,  ..., -0.8897,  0.2225, -0.0552],\n",
      "         [ 0.1166,  0.1275,  0.1366,  ..., -0.8438,  0.2935, -0.0218],\n",
      "         ...,\n",
      "         [ 0.1107,  0.1212,  0.1303,  ..., -0.6324, -0.0464,  0.4506],\n",
      "         [ 0.1100,  0.1210,  0.1288,  ..., -0.6567, -0.0395,  0.3679],\n",
      "         [ 0.1100,  0.1239,  0.1274,  ..., -0.0445,  0.4687,  0.3349]],\n",
      "\n",
      "        [[ 0.1161,  0.1271,  0.1360,  ..., -0.8897,  0.2225, -0.0552],\n",
      "         [ 0.1166,  0.1275,  0.1366,  ..., -0.8438,  0.2935, -0.0218],\n",
      "         [ 0.1170,  0.1278,  0.1371,  ..., -0.9136,  0.0946, -0.0319],\n",
      "         ...,\n",
      "         [ 0.1100,  0.1210,  0.1288,  ..., -0.6567, -0.0395,  0.3679],\n",
      "         [ 0.1100,  0.1239,  0.1274,  ..., -0.0445,  0.4687,  0.3349],\n",
      "         [ 0.1089,  0.1219,  0.1255,  ..., -0.0538,  0.4670,  0.1321]],\n",
      "\n",
      "        [[ 0.1166,  0.1275,  0.1366,  ..., -0.8438,  0.2935, -0.0218],\n",
      "         [ 0.1170,  0.1278,  0.1371,  ..., -0.9136,  0.0946, -0.0319],\n",
      "         [ 0.1175,  0.1281,  0.1376,  ..., -0.8345,  0.2883, -0.0288],\n",
      "         ...,\n",
      "         [ 0.1100,  0.1239,  0.1274,  ..., -0.0445,  0.4687,  0.3349],\n",
      "         [ 0.1089,  0.1219,  0.1255,  ..., -0.0538,  0.4670,  0.1321],\n",
      "         [ 0.1015,  0.1133,  0.1229,  ..., -0.4231,  0.2623,  0.2289]]],\n",
      "       dtype=torch.float64), tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])]\n"
     ]
    }
   ],
   "source": [
    "for i in trn_dl:\n",
    "    print(i)\n",
    "    break\n",
    "# trn_dl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start model training\n",
      "out:  tensor([[-0.0169,  0.0425,  0.0101, -0.0369, -0.0061, -0.0261,  0.0258],\n",
      "        [-0.0141,  0.0427,  0.0023, -0.0396, -0.0078, -0.0188,  0.0316],\n",
      "        [-0.0126,  0.0428, -0.0027, -0.0403, -0.0086, -0.0145,  0.0342],\n",
      "        [-0.0119,  0.0428, -0.0058, -0.0403, -0.0091, -0.0121,  0.0355],\n",
      "        [-0.0116,  0.0431, -0.0080, -0.0400, -0.0095, -0.0108,  0.0359],\n",
      "        [-0.0116,  0.0433, -0.0094, -0.0395, -0.0098, -0.0100,  0.0361],\n",
      "        [-0.0116,  0.0433, -0.0101, -0.0391, -0.0100, -0.0096,  0.0362],\n",
      "        [-0.0116,  0.0433, -0.0106, -0.0387, -0.0100, -0.0093,  0.0364],\n",
      "        [-0.0117,  0.0432, -0.0108, -0.0384, -0.0100, -0.0091,  0.0366],\n",
      "        [-0.0117,  0.0432, -0.0108, -0.0383, -0.0100, -0.0090,  0.0367],\n",
      "        [-0.0118,  0.0432, -0.0108, -0.0381, -0.0099, -0.0089,  0.0368],\n",
      "        [-0.0118,  0.0432, -0.0108, -0.0381, -0.0099, -0.0089,  0.0369],\n",
      "        [-0.0118,  0.0433, -0.0108, -0.0380, -0.0098, -0.0088,  0.0369],\n",
      "        [-0.0118,  0.0433, -0.0108, -0.0380, -0.0098, -0.0088,  0.0370],\n",
      "        [-0.0119,  0.0433, -0.0108, -0.0380, -0.0097, -0.0088,  0.0370],\n",
      "        [-0.0119,  0.0433, -0.0107, -0.0380, -0.0097, -0.0088,  0.0370]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "out:  tensor([[ 0.0519,  0.0196, -0.0134, -0.0587, -0.0211, -0.0453,  0.0009],\n",
      "        [ 0.1392,  0.0034, -0.0381, -0.0742, -0.0267, -0.0478, -0.0113],\n",
      "        [ 0.2182, -0.0103, -0.0576, -0.0847, -0.0292, -0.0508, -0.0236],\n",
      "        [ 0.2812, -0.0214, -0.0726, -0.0914, -0.0305, -0.0538, -0.0339],\n",
      "        [ 0.3283, -0.0299, -0.0840, -0.0954, -0.0313, -0.0566, -0.0419],\n",
      "        [ 0.3622, -0.0362, -0.0923, -0.0978, -0.0317, -0.0589, -0.0477],\n",
      "        [ 0.3859, -0.0407, -0.0982, -0.0990, -0.0319, -0.0608, -0.0519],\n",
      "        [ 0.4022, -0.0439, -0.1024, -0.0997, -0.0319, -0.0622, -0.0547],\n",
      "        [ 0.4133, -0.0461, -0.1052, -0.1001, -0.0318, -0.0634, -0.0567],\n",
      "        [ 0.4207, -0.0475, -0.1071, -0.1003, -0.0317, -0.0642, -0.0580],\n",
      "        [ 0.4257, -0.0485, -0.1083, -0.1003, -0.0316, -0.0649, -0.0588],\n",
      "        [ 0.4289, -0.0492, -0.1092, -0.1004, -0.0315, -0.0653, -0.0594],\n",
      "        [ 0.4311, -0.0496, -0.1097, -0.1004, -0.0314, -0.0657, -0.0597],\n",
      "        [ 0.4325, -0.0499, -0.1100, -0.1004, -0.0313, -0.0659, -0.0599],\n",
      "        [ 0.4333, -0.0501, -0.1102, -0.1004, -0.0312, -0.0661, -0.0601],\n",
      "        [ 0.4339, -0.0502, -0.1104, -0.1004, -0.0312, -0.0662, -0.0602]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "out:  tensor([[ 0.1240, -0.0092, -0.0510, -0.0877, -0.0475, -0.0683, -0.0264],\n",
      "        [ 0.3869, -0.0787, -0.1494, -0.1554, -0.0956, -0.1064, -0.0885],\n",
      "        [ 0.7967, -0.1846, -0.2977, -0.2549, -0.1655, -0.1662, -0.1857],\n",
      "        [ 1.3927, -0.3380, -0.5135, -0.3996, -0.2675, -0.2545, -0.3249],\n",
      "        [ 2.1956, -0.5419, -0.8045, -0.5977, -0.4073, -0.3745, -0.5050],\n",
      "        [ 3.1360, -0.7736, -1.1444, -0.8344, -0.5749, -0.5144, -0.7038],\n",
      "        [ 4.0252, -0.9844, -1.4650, -1.0642, -0.7377, -0.6438, -0.8811],\n",
      "        [ 4.6847, -1.1350, -1.7026, -1.2400, -0.8620, -0.7362, -1.0089],\n",
      "        [ 5.0890, -1.2233, -1.8477, -1.3512, -0.9408, -0.7900, -1.0876],\n",
      "        [ 5.3161, -1.2701, -1.9282, -1.4156, -0.9867, -0.8182, -1.1325],\n",
      "        [ 5.4452, -1.2948, -1.9731, -1.4532, -1.0137, -0.8327, -1.1582],\n",
      "        [ 5.5241, -1.3089, -1.9999, -1.4768, -1.0306, -0.8407, -1.1739],\n",
      "        [ 5.5781, -1.3181, -2.0180, -1.4934, -1.0425, -0.8458, -1.1845],\n",
      "        [ 5.6172, -1.3247, -2.0310, -1.5057, -1.0512, -0.8493, -1.1920],\n",
      "        [ 5.6454, -1.3293, -2.0404, -1.5147, -1.0576, -0.8516, -1.1972],\n",
      "        [ 5.6650, -1.3324, -2.0470, -1.5210, -1.0621, -0.8529, -1.2007]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[ 0.0913,  0.0242, -0.0567, -0.0949, -0.0579, -0.0801, -0.0352],\n",
      "        [ 0.2488,  0.0196, -0.1427, -0.1574, -0.1118, -0.1276, -0.0950],\n",
      "        [ 0.4248,  0.0229, -0.2382, -0.2233, -0.1710, -0.1836, -0.1639],\n",
      "        [ 0.6014,  0.0316, -0.3366, -0.2885, -0.2321, -0.2427, -0.2342],\n",
      "        [ 0.7685,  0.0435, -0.4325, -0.3499, -0.2918, -0.3010, -0.3008],\n",
      "        [ 0.9207,  0.0569, -0.5220, -0.4057, -0.3477, -0.3556, -0.3614],\n",
      "        [ 1.0557,  0.0704, -0.6029, -0.4551, -0.3985, -0.4050, -0.4147],\n",
      "        [ 1.1730,  0.0832, -0.6742, -0.4977, -0.4435, -0.4483, -0.4606],\n",
      "        [ 1.2735,  0.0948, -0.7359, -0.5340, -0.4826, -0.4855, -0.4995],\n",
      "        [ 1.3586,  0.1050, -0.7886, -0.5646, -0.5161, -0.5169, -0.5321],\n",
      "        [ 1.4301,  0.1138, -0.8330, -0.5901, -0.5445, -0.5432, -0.5592],\n",
      "        [ 1.4897,  0.1213, -0.8701, -0.6113, -0.5683, -0.5649, -0.5815],\n",
      "        [ 1.5392,  0.1276, -0.9010, -0.6288, -0.5881, -0.5828, -0.5999],\n",
      "        [ 1.5801,  0.1328, -0.9266, -0.6433, -0.6046, -0.5974, -0.6150],\n",
      "        [ 1.6139,  0.1371, -0.9477, -0.6552, -0.6182, -0.6094, -0.6274],\n",
      "        [ 1.6417,  0.1407, -0.9651, -0.6649, -0.6295, -0.6193, -0.6375]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[ 0.0677,  0.0607, -0.0649, -0.1061, -0.0720, -0.0979, -0.0483],\n",
      "        [ 0.1715,  0.1144, -0.1461, -0.1711, -0.1353, -0.1619, -0.1141],\n",
      "        [ 0.2615,  0.1898, -0.2204, -0.2281, -0.1958, -0.2280, -0.1781],\n",
      "        [ 0.3267,  0.2706, -0.2808, -0.2726, -0.2474, -0.2866, -0.2312],\n",
      "        [ 0.3676,  0.3440, -0.3254, -0.3042, -0.2872, -0.3331, -0.2705],\n",
      "        [ 0.3894,  0.4035, -0.3552, -0.3247, -0.3154, -0.3667, -0.2969],\n",
      "        [ 0.3983,  0.4474, -0.3734, -0.3369, -0.3338, -0.3891, -0.3129],\n",
      "        [ 0.3999,  0.4773, -0.3833, -0.3434, -0.3449, -0.4029, -0.3216],\n",
      "        [ 0.3978,  0.4960, -0.3879, -0.3465, -0.3508, -0.4106, -0.3256],\n",
      "        [ 0.3945,  0.5067, -0.3895, -0.3475, -0.3536, -0.4143, -0.3269],\n",
      "        [ 0.3913,  0.5121, -0.3894, -0.3476, -0.3546, -0.4158, -0.3268],\n",
      "        [ 0.3886,  0.5145, -0.3888, -0.3473, -0.3547, -0.4162, -0.3262],\n",
      "        [ 0.3868,  0.5151, -0.3881, -0.3469, -0.3544, -0.4159, -0.3255],\n",
      "        [ 0.3856,  0.5149, -0.3874, -0.3466, -0.3541, -0.4156, -0.3249],\n",
      "        [ 0.3849,  0.5144, -0.3870, -0.3464, -0.3538, -0.4152, -0.3245],\n",
      "        [ 0.3846,  0.5139, -0.3867, -0.3462, -0.3536, -0.4150, -0.3242]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[ 0.0832,  0.0900, -0.0959, -0.1340, -0.0985, -0.1244, -0.0745],\n",
      "        [ 0.2293,  0.2070, -0.2381, -0.2520, -0.2130, -0.2409, -0.1916],\n",
      "        [ 0.3894,  0.3932, -0.4091, -0.3908, -0.3552, -0.3918, -0.3370],\n",
      "        [ 0.5460,  0.6314, -0.5979, -0.5405, -0.5157, -0.5640, -0.4972],\n",
      "        [ 0.6873,  0.8954, -0.7908, -0.6893, -0.6817, -0.7409, -0.6587],\n",
      "        [ 0.8057,  1.1565, -0.9728, -0.8260, -0.8385, -0.9062, -0.8087],\n",
      "        [ 0.8985,  1.3908, -1.1314, -0.9422, -0.9744, -1.0475, -0.9379],\n",
      "        [ 0.9670,  1.5854, -1.2603, -1.0344, -1.0838, -1.1598, -1.0419],\n",
      "        [ 1.0156,  1.7379, -1.3595, -1.1038, -1.1669, -1.2442, -1.1216],\n",
      "        [ 1.0493,  1.8528, -1.4330, -1.1544, -1.2278, -1.3054, -1.1804],\n",
      "        [ 1.0723,  1.9373, -1.4861, -1.1903, -1.2715, -1.3489, -1.2229],\n",
      "        [ 1.0880,  1.9987, -1.5241, -1.2157, -1.3026, -1.3794, -1.2533],\n",
      "        [ 1.0988,  2.0430, -1.5511, -1.2337, -1.3246, -1.4008, -1.2750],\n",
      "        [ 1.1062,  2.0750, -1.5704, -1.2463, -1.3402, -1.4159, -1.2905],\n",
      "        [ 1.1114,  2.0981, -1.5842, -1.2554, -1.3514, -1.4266, -1.3016],\n",
      "        [ 1.1151,  2.1148, -1.5941, -1.2619, -1.3595, -1.4343, -1.3096]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[ 0.0860,  0.1275, -0.1216, -0.1588, -0.1224, -0.1496, -0.0993],\n",
      "        [ 0.2421,  0.3445, -0.3218, -0.3304, -0.2916, -0.3253, -0.2722],\n",
      "        [ 0.4166,  0.7239, -0.5961, -0.5604, -0.5319, -0.5827, -0.5150],\n",
      "        [ 0.5837,  1.2573, -0.9349, -0.8363, -0.8351, -0.9075, -0.8139],\n",
      "        [ 0.7181,  1.8772, -1.2992, -1.1237, -1.1627, -1.2544, -1.1330],\n",
      "        [ 0.8061,  2.4690, -1.6263, -1.3750, -1.4543, -1.5592, -1.4196],\n",
      "        [ 0.8542,  2.9380, -1.8703, -1.5591, -1.6686, -1.7806, -1.6362],\n",
      "        [ 0.8775,  3.2604, -2.0280, -1.6772, -1.8056, -1.9199, -1.7793],\n",
      "        [ 0.8884,  3.4643, -2.1221, -1.7477, -1.8871, -2.0008, -1.8671],\n",
      "        [ 0.8936,  3.5893, -2.1771, -1.7890, -1.9350, -2.0467, -1.9198],\n",
      "        [ 0.8965,  3.6660, -2.2097, -1.8135, -1.9636, -2.0733, -1.9515],\n",
      "        [ 0.8984,  3.7137, -2.2295, -1.8283, -1.9813, -2.0891, -1.9712],\n",
      "        [ 0.8997,  3.7442, -2.2420, -1.8376, -1.9925, -2.0989, -1.9837],\n",
      "        [ 0.9006,  3.7640, -2.2500, -1.8435, -1.9998, -2.1052, -1.9918],\n",
      "        [ 0.9013,  3.7772, -2.2552, -1.8474, -2.0047, -2.1093, -1.9971],\n",
      "        [ 0.9018,  3.7862, -2.2587, -1.8499, -2.0080, -2.1121, -2.0008]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[ 0.0872,  0.1549, -0.1393, -0.1758, -0.1391, -0.1670, -0.1164],\n",
      "        [ 0.2451,  0.4480, -0.3819, -0.3869, -0.3489, -0.3856, -0.3299],\n",
      "        [ 0.4156,  0.9811, -0.7341, -0.6868, -0.6653, -0.7227, -0.6469],\n",
      "        [ 0.5594,  1.7469, -1.1813, -1.0570, -1.0750, -1.1558, -1.0493],\n",
      "        [ 0.6413,  2.6146, -1.6447, -1.4318, -1.4997, -1.5968, -1.4677],\n",
      "        [ 0.6623,  3.3774, -2.0160, -1.7302, -1.8376, -1.9404, -1.8112],\n",
      "        [ 0.6523,  3.9156, -2.2523, -1.9228, -2.0529, -2.1532, -2.0403],\n",
      "        [ 0.6355,  4.2447, -2.3834, -2.0322, -2.1741, -2.2680, -2.1750],\n",
      "        [ 0.6214,  4.4338, -2.4534, -2.0915, -2.2398, -2.3271, -2.2506],\n",
      "        [ 0.6119,  4.5416, -2.4915, -2.1240, -2.2761, -2.3581, -2.2935],\n",
      "        [ 0.6059,  4.6043, -2.5134, -2.1424, -2.2969, -2.3751, -2.3186],\n",
      "        [ 0.6023,  4.6420, -2.5265, -2.1534, -2.3095, -2.3849, -2.3340],\n",
      "        [ 0.6002,  4.6654, -2.5347, -2.1601, -2.3173, -2.3908, -2.3437],\n",
      "        [ 0.5989,  4.6805, -2.5400, -2.1644, -2.3223, -2.3945, -2.3500],\n",
      "        [ 0.5981,  4.6903, -2.5434, -2.1673, -2.3256, -2.3969, -2.3542],\n",
      "        [ 0.5976,  4.6970, -2.5458, -2.1691, -2.3279, -2.3985, -2.3570]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[ 0.0884,  0.1792, -0.1551, -0.1907, -0.1538, -0.1823, -0.1314],\n",
      "        [ 0.2482,  0.5421, -0.4375, -0.4387, -0.4018, -0.4410, -0.3829],\n",
      "        [ 0.4139,  1.2165, -0.8639, -0.8052, -0.7904, -0.8524, -0.7701],\n",
      "        [ 0.5322,  2.1834, -1.4081, -1.2607, -1.2934, -1.3774, -1.2647],\n",
      "        [ 0.5660,  3.2246, -1.9380, -1.6991, -1.7816, -1.8752, -1.7531],\n",
      "        [ 0.5394,  4.0577, -2.3140, -2.0153, -2.1282, -2.2187, -2.1163],\n",
      "        [ 0.4985,  4.5855, -2.5224, -2.1976, -2.3246, -2.4057, -2.3335],\n",
      "        [ 0.4656,  4.8792, -2.6257, -2.2914, -2.4254, -2.4972, -2.4500],\n",
      "        [ 0.4443,  5.0364, -2.6770, -2.3389, -2.4770, -2.5417, -2.5117],\n",
      "        [ 0.4317,  5.1216, -2.7039, -2.3638, -2.5048, -2.5647, -2.5457],\n",
      "        [ 0.4242,  5.1700, -2.7191, -2.3778, -2.5207, -2.5776, -2.5656],\n",
      "        [ 0.4201,  5.1992, -2.7284, -2.3863, -2.5307, -2.5855, -2.5780],\n",
      "        [ 0.4177,  5.2177, -2.7345, -2.3919, -2.5374, -2.5907, -2.5861],\n",
      "        [ 0.4163,  5.2299, -2.7387, -2.3957, -2.5419, -2.5943, -2.5917],\n",
      "        [ 0.4155,  5.2382, -2.7416, -2.3983, -2.5450, -2.5968, -2.5956],\n",
      "        [ 0.4150,  5.2440, -2.7436, -2.4002, -2.5473, -2.5985, -2.5983]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[ 0.0891,  0.2023, -0.1699, -0.2048, -0.1677, -0.1968, -0.1455],\n",
      "        [ 0.2497,  0.6340, -0.4917, -0.4891, -0.4534, -0.4950, -0.4344],\n",
      "        [ 0.4088,  1.4514, -0.9948, -0.9237, -0.9158, -0.9816, -0.8937],\n",
      "        [ 0.4977,  2.6047, -1.6290, -1.4596, -1.5044, -1.5891, -1.4742],\n",
      "        [ 0.4865,  3.7670, -2.1993, -1.9423, -2.0323, -2.1193, -2.0103],\n",
      "        [ 0.4264,  4.6079, -2.5568, -2.2555, -2.3681, -2.4455, -2.3702],\n",
      "        [ 0.3698,  5.0885, -2.7332, -2.4175, -2.5406, -2.6061, -2.5651],\n",
      "        [ 0.3323,  5.3350, -2.8147, -2.4942, -2.6239, -2.6801, -2.6625],\n",
      "        [ 0.3108,  5.4607, -2.8547, -2.5315, -2.6660, -2.7162, -2.7126],\n",
      "        [ 0.2994,  5.5282, -2.8766, -2.5514, -2.6895, -2.7358, -2.7406],\n",
      "        [ 0.2935,  5.5672, -2.8900, -2.5632, -2.7039, -2.7479, -2.7576],\n",
      "        [ 0.2905,  5.5914, -2.8988, -2.5708, -2.7134, -2.7560, -2.7688],\n",
      "        [ 0.2890,  5.6074, -2.9049, -2.5761, -2.7201, -2.7618, -2.7764],\n",
      "        [ 0.2883,  5.6185, -2.9093, -2.5798, -2.7249, -2.7660, -2.7819],\n",
      "        [ 0.2879,  5.6264, -2.9125, -2.5826, -2.7285, -2.7691, -2.7858],\n",
      "        [ 0.2878,  5.6322, -2.9148, -2.5847, -2.7311, -2.7715, -2.7888]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[ 0.0894,  0.2248, -0.1842, -0.2184, -0.1812, -0.2108, -0.1592],\n",
      "        [ 0.2497,  0.7260, -0.5459, -0.5395, -0.5052, -0.5489, -0.4859],\n",
      "        [ 0.3986,  1.6857, -1.1255, -1.0426, -1.0412, -1.1099, -1.0170],\n",
      "        [ 0.4546,  3.0060, -1.8393, -1.6514, -1.7053, -1.7888, -1.6748],\n",
      "        [ 0.4042,  4.2439, -2.4290, -2.1609, -2.2545, -2.3337, -2.2400],\n",
      "        [ 0.3224,  5.0552, -2.7591, -2.4588, -2.5709, -2.6369, -2.5846],\n",
      "        [ 0.2601,  5.4783, -2.9083, -2.5990, -2.7211, -2.7749, -2.7559],\n",
      "        [ 0.2239,  5.6832, -2.9754, -2.6621, -2.7914, -2.8368, -2.8375],\n",
      "        [ 0.2054,  5.7861, -3.0095, -2.6931, -2.8276, -2.8680, -2.8795],\n",
      "        [ 0.1968,  5.8425, -3.0296, -2.7106, -2.8489, -2.8863, -2.9038],\n",
      "        [ 0.1931,  5.8764, -3.0429, -2.7218, -2.8628, -2.8984, -2.9193],\n",
      "        [ 0.1917,  5.8985, -3.0522, -2.7296, -2.8725, -2.9069, -2.9298],\n",
      "        [ 0.1915,  5.9136, -3.0590, -2.7353, -2.8796, -2.9133, -2.9373],\n",
      "        [ 0.1918,  5.9244, -3.0642, -2.7395, -2.8849, -2.9180, -2.9428],\n",
      "        [ 0.1921,  5.9321, -3.0676, -2.7425, -2.8887, -2.9214, -2.9465],\n",
      "        [ 0.1926,  5.9380, -3.0705, -2.7450, -2.8917, -2.9243, -2.9496]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[ 0.0894,  0.2471, -0.1983, -0.2318, -0.1945, -0.2247, -0.1726],\n",
      "        [ 0.2482,  0.8193, -0.6007, -0.5905, -0.5577, -0.6034, -0.5380],\n",
      "        [ 0.3839,  1.9222, -1.2579, -1.1633, -1.1682, -1.2388, -1.1419],\n",
      "        [ 0.4052,  3.3915, -2.0416, -1.8379, -1.8985, -1.9793, -1.8690],\n",
      "        [ 0.3221,  4.6671, -2.6342, -2.3592, -2.4549, -2.5262, -2.4482],\n",
      "        [ 0.2256,  5.4242, -2.9306, -2.6326, -2.7450, -2.8020, -2.7675],\n",
      "        [ 0.1584,  5.7870, -3.0515, -2.7484, -2.8708, -2.9171, -2.9110],\n",
      "        [ 0.1209,  5.9554, -3.1028, -2.7976, -2.9267, -2.9666, -2.9753],\n",
      "        [ 0.1042,  6.0415, -3.1316, -2.8238, -2.9572, -2.9932, -3.0101],\n",
      "        [ 0.0988,  6.0911, -3.1518, -2.8410, -2.9774, -3.0107, -3.0325],\n",
      "        [ 0.0989,  6.1228, -3.1676, -2.8538, -2.9924, -3.0238, -3.0486],\n",
      "        [ 0.1013,  6.1443, -3.1803, -2.8637, -3.0040, -3.0338, -3.0606],\n",
      "        [ 0.1045,  6.1595, -3.1904, -2.8715, -3.0132, -3.0417, -3.0697],\n",
      "        [ 0.1076,  6.1705, -3.1984, -2.8775, -3.0203, -3.0477, -3.0766],\n",
      "        [ 0.1105,  6.1787, -3.2046, -2.8822, -3.0258, -3.0524, -3.0818],\n",
      "        [ 0.1128,  6.1847, -3.2094, -2.8859, -3.0301, -3.0560, -3.0857]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[ 0.0890,  0.2693, -0.2123, -0.2451, -0.2077, -0.2385, -0.1859],\n",
      "        [ 0.2453,  0.9142, -0.6566, -0.6426, -0.6113, -0.6589, -0.5911],\n",
      "        [ 0.3650,  2.1612, -1.3921, -1.2861, -1.2968, -1.3687, -1.2686],\n",
      "        [ 0.3513,  3.7601, -2.2355, -2.0183, -2.0840, -2.1612, -2.0564],\n",
      "        [ 0.2426,  5.0419, -2.8188, -2.5392, -2.6365, -2.7005, -2.6373],\n",
      "        [ 0.1429,  5.7398, -3.0882, -2.7904, -2.9031, -2.9522, -2.9331],\n",
      "        [ 0.0848,  6.0572, -3.1984, -2.8945, -3.0164, -3.0553, -3.0620],\n",
      "        [ 0.0577,  6.2035, -3.2500, -2.9413, -3.0693, -3.1022, -3.1215],\n",
      "        [ 0.0470,  6.2786, -3.2796, -2.9668, -3.0987, -3.1280, -3.1534],\n",
      "        [ 0.0438,  6.3215, -3.2992, -2.9830, -3.1173, -3.1443, -3.1727],\n",
      "        [ 0.0437,  6.3480, -3.3129, -2.9941, -3.1300, -3.1554, -3.1853],\n",
      "        [ 0.0449,  6.3652, -3.3228, -3.0019, -3.1390, -3.1630, -3.1938],\n",
      "        [ 0.0464,  6.3766, -3.3299, -3.0075, -3.1455, -3.1684, -3.1997],\n",
      "        [ 0.0478,  6.3843, -3.3352, -3.0115, -3.1502, -3.1722, -3.2038],\n",
      "        [ 0.0491,  6.3897, -3.3390, -3.0145, -3.1536, -3.1749, -3.2067],\n",
      "        [ 0.0502,  6.3935, -3.3418, -3.0166, -3.1562, -3.1769, -3.2088]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[ 0.0883,  0.2915, -0.2262, -0.2584, -0.2210, -0.2522, -0.1992],\n",
      "        [ 0.2411,  1.0111, -0.7138, -0.6958, -0.6661, -0.7155, -0.6453],\n",
      "        [ 0.3423,  2.4015, -1.5276, -1.4105, -1.4265, -1.4991, -1.3966],\n",
      "        [ 0.2944,  4.1095, -2.4198, -2.1913, -2.2609, -2.3340, -2.2361],\n",
      "        [ 0.1665,  5.3727, -2.9848, -2.7021, -2.8006, -2.8584, -2.8085],\n",
      "        [ 0.0662,  6.0062, -3.2261, -2.9288, -3.0411, -3.0851, -3.0768],\n",
      "        [ 0.0134,  6.2815, -3.3232, -3.0196, -3.1398, -3.1752, -3.1885],\n",
      "        [-0.0088,  6.4075, -3.3704, -3.0616, -3.1865, -3.2169, -3.2399],\n",
      "        [-0.0166,  6.4725, -3.3986, -3.0853, -3.2128, -3.2403, -3.2677],\n",
      "        [-0.0182,  6.5093, -3.4172, -3.1003, -3.2295, -3.2548, -3.2844],\n",
      "        [-0.0175,  6.5314, -3.4299, -3.1103, -3.2405, -3.2642, -3.2949],\n",
      "        [-0.0162,  6.5451, -3.4388, -3.1170, -3.2481, -3.2704, -3.3017],\n",
      "        [-0.0147,  6.5539, -3.4449, -3.1216, -3.2534, -3.2745, -3.3062],\n",
      "        [-0.0134,  6.5596, -3.4492, -3.1248, -3.2571, -3.2772, -3.3092],\n",
      "        [-0.0123,  6.5633, -3.4522, -3.1270, -3.2597, -3.2791, -3.3113],\n",
      "        [-0.0115,  6.5659, -3.4544, -3.1285, -3.2616, -3.2804, -3.3127]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[ 8.7375e-02,  3.1384e-01, -2.4022e-01, -2.7170e-01, -2.3429e-01,\n",
      "         -2.6606e-01, -2.1259e-01],\n",
      "        [ 2.3562e-01,  1.1101e+00, -7.7230e-01, -7.5039e-01, -7.2238e-01,\n",
      "         -7.7343e-01, -7.0083e-01],\n",
      "        [ 3.1619e-01,  2.6424e+00, -1.6641e+00, -1.5361e+00, -1.5571e+00,\n",
      "         -1.6297e+00, -1.5257e+00],\n",
      "        [ 2.3613e-01,  4.4388e+00, -2.5944e+00, -2.3565e+00, -2.4292e+00,\n",
      "         -2.4982e+00, -2.4078e+00],\n",
      "        [ 9.4983e-02,  5.6647e+00, -3.1350e+00, -2.8500e+00, -2.9492e+00,\n",
      "         -3.0022e+00, -2.9637e+00],\n",
      "        [-2.8047e-03,  6.2358e+00, -3.3512e+00, -3.0536e+00, -3.1646e+00,\n",
      "         -3.2055e+00, -3.2050e+00],\n",
      "        [-4.9705e-02,  6.4755e+00, -3.4380e+00, -3.1338e+00, -3.2507e+00,\n",
      "         -3.2847e+00, -3.3018e+00],\n",
      "        [-6.7972e-02,  6.5845e+00, -3.4815e+00, -3.1715e+00, -3.2918e+00,\n",
      "         -3.3218e+00, -3.3463e+00],\n",
      "        [-7.3674e-02,  6.6403e+00, -3.5076e+00, -3.1929e+00, -3.3150e+00,\n",
      "         -3.3423e+00, -3.3700e+00],\n",
      "        [-7.4479e-02,  6.6710e+00, -3.5244e+00, -3.2060e+00, -3.3293e+00,\n",
      "         -3.3545e+00, -3.3838e+00],\n",
      "        [-7.3606e-02,  6.6889e+00, -3.5355e+00, -3.2144e+00, -3.3385e+00,\n",
      "         -3.3620e+00, -3.3922e+00],\n",
      "        [-7.2326e-02,  6.6995e+00, -3.5428e+00, -3.2199e+00, -3.3447e+00,\n",
      "         -3.3667e+00, -3.3974e+00],\n",
      "        [-7.1105e-02,  6.7060e+00, -3.5477e+00, -3.2234e+00, -3.3489e+00,\n",
      "         -3.3697e+00, -3.4007e+00],\n",
      "        [-7.0082e-02,  6.7101e+00, -3.5510e+00, -3.2257e+00, -3.3517e+00,\n",
      "         -3.3716e+00, -3.4028e+00],\n",
      "        [-6.9276e-02,  6.7127e+00, -3.5533e+00, -3.2273e+00, -3.3537e+00,\n",
      "         -3.3728e+00, -3.4043e+00],\n",
      "        [-6.8662e-02,  6.7144e+00, -3.5549e+00, -3.2283e+00, -3.3551e+00,\n",
      "         -3.3736e+00, -3.4053e+00]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[ 0.0862,  0.3363, -0.2543, -0.2852, -0.2477, -0.2800, -0.2261],\n",
      "        [ 0.2290,  1.2114, -0.8324, -0.8064, -0.7802, -0.8327, -0.7578],\n",
      "        [ 0.2871,  2.8830, -1.8012, -1.6626, -1.6881, -1.7602, -1.6554],\n",
      "        [ 0.1777,  4.7472, -2.7593, -2.5133, -2.5887, -2.6538, -2.5712],\n",
      "        [ 0.0282,  5.9227, -3.2718, -2.9847, -3.0839, -3.1336, -3.1045],\n",
      "        [-0.0650,  6.4357, -3.4658, -3.1674, -3.2758, -3.3155, -3.3202],\n",
      "        [-0.1064,  6.6450, -3.5441, -3.2383, -3.3512, -3.3852, -3.4042],\n",
      "        [-0.1215,  6.7394, -3.5839, -3.2720, -3.3871, -3.4178, -3.4423],\n",
      "        [-0.1259,  6.7867, -3.6073, -3.2906, -3.4071, -3.4352, -3.4622],\n",
      "        [-0.1263,  6.8120, -3.6219, -3.3017, -3.4192, -3.4452, -3.4733],\n",
      "        [-0.1255,  6.8261, -3.6310, -3.3085, -3.4269, -3.4510, -3.4798],\n",
      "        [-0.1245,  6.8343, -3.6370, -3.3127, -3.4318, -3.4544, -3.4837],\n",
      "        [-0.1235,  6.8392, -3.6408, -3.3153, -3.4351, -3.4565, -3.4862],\n",
      "        [-0.1227,  6.8422, -3.6433, -3.3170, -3.4374, -3.4578, -3.4877],\n",
      "        [-0.1221,  6.8441, -3.6450, -3.3181, -3.4389, -3.4586, -3.4888],\n",
      "        [-0.1217,  6.8453, -3.6462, -3.3188, -3.4400, -3.4592, -3.4894]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[ 0.0849,  0.3591, -0.2686, -0.2988, -0.2614, -0.2941, -0.2397],\n",
      "        [ 0.2212,  1.3149, -0.8941, -0.8640, -0.8396, -0.8935, -0.8163],\n",
      "        [ 0.2554,  3.1224, -1.9383, -1.7896, -1.8191, -1.8903, -1.7856],\n",
      "        [ 0.1200,  5.0348, -2.9146, -2.6617, -2.7393, -2.8010, -2.7260],\n",
      "        [-0.0337,  6.1513, -3.3971, -3.1080, -3.2063, -3.2540, -3.2326],\n",
      "        [-0.1214,  6.6112, -3.5718, -3.2717, -3.3769, -3.4165, -3.4246],\n",
      "        [-0.1579,  6.7945, -3.6425, -3.3346, -3.4428, -3.4779, -3.4973],\n",
      "        [-0.1707,  6.8759, -3.6784, -3.3641, -3.4741, -3.5061, -3.5297],\n",
      "        [-0.1742,  6.9158, -3.6988, -3.3799, -3.4913, -3.5206, -3.5461],\n",
      "        [-0.1745,  6.9365, -3.7111, -3.3890, -3.5014, -3.5284, -3.5550],\n",
      "        [-0.1739,  6.9478, -3.7186, -3.3944, -3.5077, -3.5328, -3.5600],\n",
      "        [-0.1731,  6.9542, -3.7233, -3.3976, -3.5117, -3.5353, -3.5629],\n",
      "        [-0.1723,  6.9579, -3.7263, -3.3996, -3.5144, -3.5368, -3.5647],\n",
      "        [-0.1718,  6.9602, -3.7282, -3.4009, -3.5162, -3.5377, -3.5659],\n",
      "        [-0.1713,  6.9616, -3.7295, -3.4017, -3.5175, -3.5382, -3.5666],\n",
      "        [-0.1710,  6.9625, -3.7304, -3.4022, -3.5183, -3.5386, -3.5671]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[ 0.0833,  0.3821, -0.2831, -0.3126, -0.2752, -0.3085, -0.2535],\n",
      "        [ 0.2124,  1.4210, -0.9577, -0.9233, -0.9007, -0.9558, -0.8765],\n",
      "        [ 0.2216,  3.3597, -2.0751, -1.9166, -1.9499, -2.0199, -1.9158],\n",
      "        [ 0.0637,  5.3021, -3.0607, -2.8018, -2.8812, -2.9400, -2.8725],\n",
      "        [-0.0912,  6.3546, -3.5125, -3.2213, -3.3181, -3.3648, -3.3495],\n",
      "        [-0.1729,  6.7666, -3.6702, -3.3680, -3.4693, -3.5099, -3.5199],\n",
      "        [-0.2052,  6.9274, -3.7341, -3.4236, -3.5271, -3.5638, -3.5827],\n",
      "        [-0.2162,  6.9975, -3.7659, -3.4491, -3.5543, -3.5878, -3.6100],\n",
      "        [-0.2192,  7.0309, -3.7835, -3.4623, -3.5689, -3.5996, -3.6234],\n",
      "        [-0.2196,  7.0479, -3.7936, -3.4696, -3.5774, -3.6057, -3.6304],\n",
      "        [-0.2192,  7.0570, -3.7997, -3.4739, -3.5826, -3.6089, -3.6343],\n",
      "        [-0.2186,  7.0621, -3.8034, -3.4764, -3.5859, -3.6107, -3.6365],\n",
      "        [-0.2182,  7.0651, -3.8058, -3.4779, -3.5881, -3.6118, -3.6378],\n",
      "        [-0.2178,  7.0669, -3.8073, -3.4788, -3.5896, -3.6124, -3.6386],\n",
      "        [-0.2175,  7.0680, -3.8082, -3.4794, -3.5905, -3.6127, -3.6391],\n",
      "        [-0.2175,  7.0684, -3.8085, -3.4795, -3.5909, -3.6126, -3.6392]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[ 0.0816,  0.4055, -0.2978, -0.3266, -0.2893, -0.3230, -0.2675],\n",
      "        [ 0.2024,  1.5295, -1.0230, -0.9843, -0.9636, -1.0198, -0.9384],\n",
      "        [ 0.1861,  3.5943, -2.2110, -2.0431, -2.0798, -2.1484, -2.0455],\n",
      "        [ 0.0093,  5.5497, -3.1981, -2.9339, -3.0145, -3.0710, -3.0105],\n",
      "        [-0.1445,  6.5362, -3.6195, -3.3261, -3.4204, -3.4673, -3.4565],\n",
      "        [-0.2203,  6.9053, -3.7622, -3.4575, -3.5546, -3.5967, -3.6074],\n",
      "        [-0.2491,  7.0464, -3.8196, -3.5063, -3.6052, -3.6437, -3.6616],\n",
      "        [-0.2587,  7.1067, -3.8475, -3.5281, -3.6288, -3.6639, -3.6845],\n",
      "        [-0.2615,  7.1348, -3.8624, -3.5390, -3.6413, -3.6733, -3.6953],\n",
      "        [-0.2620,  7.1489, -3.8708, -3.5449, -3.6484, -3.6780, -3.7008],\n",
      "        [-0.2619,  7.1564, -3.8756, -3.5482, -3.6527, -3.6804, -3.7037],\n",
      "        [-0.2616,  7.1605, -3.8786, -3.5502, -3.6554, -3.6817, -3.7054],\n",
      "        [-0.2614,  7.1630, -3.8804, -3.5514, -3.6572, -3.6824, -3.7063],\n",
      "        [-0.2612,  7.1645, -3.8815, -3.5521, -3.6584, -3.6828, -3.7069],\n",
      "        [-0.2611,  7.1654, -3.8822, -3.5525, -3.6591, -3.6830, -3.7073],\n",
      "        [-0.2618,  7.1659, -3.8820, -3.5525, -3.6592, -3.6829, -3.7070]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[ 0.0751,  0.4034, -0.2954, -0.3249, -0.2878, -0.3211, -0.2655],\n",
      "        [ 0.1763,  1.4723, -0.9842, -0.9513, -0.9298, -0.9842, -0.9031],\n",
      "        [ 0.1509,  3.4905, -2.1494, -1.9951, -2.0282, -2.0966, -1.9915],\n",
      "        [-0.0290,  5.5127, -3.1884, -2.9340, -3.0122, -3.0698, -3.0034],\n",
      "        [-0.1866,  6.5779, -3.6585, -3.3697, -3.4618, -3.5104, -3.4952],\n",
      "        [-0.2639,  6.9804, -3.8207, -3.5181, -3.6115, -3.6565, -3.6641],\n",
      "        [-0.2923,  7.1327, -3.8855, -3.5728, -3.6672, -3.7090, -3.7241],\n",
      "        [-0.3012,  7.1964, -3.9164, -3.5965, -3.6926, -3.7309, -3.7488],\n",
      "        [-0.3033,  7.2253, -3.9324, -3.6081, -3.7058, -3.7407, -3.7602],\n",
      "        [-0.3034,  7.2393, -3.9411, -3.6141, -3.7132, -3.7453, -3.7657],\n",
      "        [-0.3032,  7.2466, -3.9460, -3.6175, -3.7176, -3.7475, -3.7685],\n",
      "        [-0.3029,  7.2506, -3.9488, -3.6194, -3.7203, -3.7486, -3.7701],\n",
      "        [-0.3027,  7.2524, -3.9502, -3.6203, -3.7218, -3.7490, -3.7707],\n",
      "        [-0.3029,  7.2533, -3.9508, -3.6206, -3.7225, -3.7490, -3.7708],\n",
      "        [-0.3032,  7.2538, -3.9509, -3.6204, -3.7227, -3.7489, -3.7706],\n",
      "        [-0.3035,  7.2544, -3.9511, -3.6205, -3.7230, -3.7490, -3.7706]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[ 0.0776,  0.4543, -0.3288, -0.3562, -0.3191, -0.3537, -0.2972],\n",
      "        [ 0.1792,  1.7577, -1.1623, -1.1142, -1.0974, -1.1553, -1.0701],\n",
      "        [ 0.1106,  4.0593, -2.4841, -2.2982, -2.3409, -2.4062, -2.3074],\n",
      "        [-0.0941,  5.9967, -3.4542, -3.1804, -3.2615, -3.3155, -3.2678],\n",
      "        [-0.2408,  6.8508, -3.8174, -3.5186, -3.6061, -3.6552, -3.6506],\n",
      "        [-0.3053,  7.1464, -3.9343, -3.6236, -3.7115, -3.7576, -3.7681],\n",
      "        [-0.3283,  7.2548, -3.9800, -3.6606, -3.7505, -3.7927, -3.8079],\n",
      "        [-0.3361,  7.2993, -4.0009, -3.6761, -3.7682, -3.8064, -3.8237],\n",
      "        [-0.3387,  7.3194, -4.0114, -3.6834, -3.7773, -3.8122, -3.8307],\n",
      "        [-0.3397,  7.3293, -4.0169, -3.6872, -3.7824, -3.8148, -3.8340],\n",
      "        [-0.3401,  7.3345, -4.0200, -3.6893, -3.7854, -3.8160, -3.8356],\n",
      "        [-0.3404,  7.3375, -4.0217, -3.6906, -3.7872, -3.8166, -3.8364],\n",
      "        [-0.3407,  7.3392, -4.0228, -3.6913, -3.7884, -3.8168, -3.8369],\n",
      "        [-0.3409,  7.3403, -4.0234, -3.6917, -3.7891, -3.8170, -3.8371],\n",
      "        [-0.3410,  7.3410, -4.0238, -3.6920, -3.7897, -3.8170, -3.8372],\n",
      "        [-0.3411,  7.3415, -4.0241, -3.6921, -3.7900, -3.8170, -3.8372]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[ 0.0753,  0.4786, -0.3443, -0.3710, -0.3339, -0.3689, -0.3119],\n",
      "        [ 0.1660,  1.8721, -1.2324, -1.1796, -1.1649, -1.2233, -1.1364],\n",
      "        [ 0.0721,  4.2784, -2.6133, -2.4193, -2.4647, -2.5285, -2.4321],\n",
      "        [-0.1420,  6.1894, -3.5670, -3.2892, -3.3696, -3.4235, -3.3809],\n",
      "        [-0.2840,  6.9824, -3.9040, -3.6027, -3.6862, -3.7372, -3.7341],\n",
      "        [-0.3437,  7.2482, -4.0102, -3.6967, -3.7802, -3.8284, -3.8380],\n",
      "        [-0.3647,  7.3439, -4.0508, -3.7288, -3.8146, -3.8586, -3.8721],\n",
      "        [-0.3720,  7.3825, -4.0688, -3.7418, -3.8301, -3.8698, -3.8852],\n",
      "        [-0.3747,  7.3998, -4.0776, -3.7479, -3.8379, -3.8743, -3.8908],\n",
      "        [-0.3759,  7.4083, -4.0821, -3.7510, -3.8423, -3.8762, -3.8933],\n",
      "        [-0.3767,  7.4128, -4.0845, -3.7527, -3.8448, -3.8770, -3.8945],\n",
      "        [-0.3773,  7.4154, -4.0858, -3.7537, -3.8463, -3.8773, -3.8950],\n",
      "        [-0.3784,  7.4170, -4.0861, -3.7541, -3.8469, -3.8775, -3.8948],\n",
      "        [-0.3799,  7.4179, -4.0856, -3.7539, -3.8468, -3.8773, -3.8943],\n",
      "        [-0.3819,  7.4186, -4.0846, -3.7534, -3.8462, -3.8771, -3.8934],\n",
      "        [-0.3841,  7.4191, -4.0834, -3.7527, -3.8454, -3.8770, -3.8925]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[ 0.0728,  0.5033, -0.3599, -0.3859, -0.3490, -0.3844, -0.3268],\n",
      "        [ 0.1518,  1.9880, -1.3038, -1.2462, -1.2334, -1.2923, -1.2039],\n",
      "        [ 0.0333,  4.4906, -2.7392, -2.5376, -2.5854, -2.6477, -2.5540],\n",
      "        [-0.1877,  6.3663, -3.6725, -3.3911, -3.4702, -3.5245, -3.4864],\n",
      "        [-0.3246,  7.1018, -3.9853, -3.6813, -3.7606, -3.8138, -3.8115],\n",
      "        [-0.3800,  7.3413, -4.0818, -3.7655, -3.8447, -3.8951, -3.9034],\n",
      "        [-0.3993,  7.4259, -4.1178, -3.7934, -3.8752, -3.9209, -3.9326],\n",
      "        [-0.4063,  7.4597, -4.1332, -3.8044, -3.8887, -3.9300, -3.9434],\n",
      "        [-0.4092,  7.4752, -4.1408, -3.8097, -3.8958, -3.9337, -3.9480],\n",
      "        [-0.4103,  7.4828, -4.1448, -3.8126, -3.8998, -3.9353, -3.9503],\n",
      "        [-0.4109,  7.4870, -4.1472, -3.8144, -3.9023, -3.9360, -3.9515],\n",
      "        [-0.4112,  7.4893, -4.1486, -3.8156, -3.9039, -3.9363, -3.9521],\n",
      "        [-0.4115,  7.4909, -4.1495, -3.8163, -3.9049, -3.9363, -3.9524],\n",
      "        [-0.4120,  7.4918, -4.1498, -3.8165, -3.9055, -3.9362, -3.9524],\n",
      "        [-0.4124,  7.4922, -4.1499, -3.8165, -3.9057, -3.9359, -3.9522],\n",
      "        [-0.4127,  7.4923, -4.1499, -3.8164, -3.9058, -3.9358, -3.9520]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[ 7.0137e-02,  5.2816e-01, -3.7581e-01, -4.0107e-01, -3.6425e-01,\n",
      "         -4.0006e-01, -3.4199e-01],\n",
      "        [ 1.3669e-01,  2.1047e+00, -1.3760e+00, -1.3137e+00, -1.3029e+00,\n",
      "         -1.3621e+00, -1.2723e+00],\n",
      "        [-5.4880e-03,  4.6952e+00, -2.8611e+00, -2.6524e+00, -2.7023e+00,\n",
      "         -2.7634e+00, -2.6726e+00],\n",
      "        [-2.3121e-01,  6.5283e+00, -3.7712e+00, -3.4864e+00, -3.5636e+00,\n",
      "         -3.6189e+00, -3.5845e+00],\n",
      "        [-3.6288e-01,  7.2104e+00, -4.0616e+00, -3.7550e+00, -3.8300e+00,\n",
      "         -3.8855e+00, -3.8834e+00],\n",
      "        [-4.1438e-01,  7.4268e+00, -4.1493e+00, -3.8304e+00, -3.9055e+00,\n",
      "         -3.9579e+00, -3.9647e+00],\n",
      "        [-4.3225e-01,  7.5020e+00, -4.1813e+00, -3.8547e+00, -3.9327e+00,\n",
      "         -3.9799e+00, -3.9899e+00],\n",
      "        [-4.3889e-01,  7.5316e+00, -4.1947e+00, -3.8640e+00, -3.9446e+00,\n",
      "         -3.9873e+00, -3.9988e+00],\n",
      "        [-4.4193e-01,  7.5447e+00, -4.2008e+00, -3.8681e+00, -3.9506e+00,\n",
      "         -3.9899e+00, -4.0023e+00],\n",
      "        [-4.4373e-01,  7.5512e+00, -4.2037e+00, -3.8702e+00, -3.9538e+00,\n",
      "         -3.9908e+00, -4.0037e+00],\n",
      "        [-4.4498e-01,  7.5547e+00, -4.2052e+00, -3.8714e+00, -3.9556e+00,\n",
      "         -3.9911e+00, -4.0042e+00],\n",
      "        [-4.4593e-01,  7.5568e+00, -4.2060e+00, -3.8720e+00, -3.9567e+00,\n",
      "         -3.9911e+00, -4.0043e+00],\n",
      "        [-4.4667e-01,  7.5581e+00, -4.2064e+00, -3.8724e+00, -3.9574e+00,\n",
      "         -3.9910e+00, -4.0043e+00],\n",
      "        [-4.4708e-01,  7.5590e+00, -4.2068e+00, -3.8728e+00, -3.9579e+00,\n",
      "         -3.9911e+00, -4.0043e+00],\n",
      "        [-4.4753e-01,  7.5597e+00, -4.2069e+00, -3.8730e+00, -3.9583e+00,\n",
      "         -3.9911e+00, -4.0042e+00],\n",
      "        [-4.4777e-01,  7.5604e+00, -4.2072e+00, -3.8733e+00, -3.9586e+00,\n",
      "         -3.9911e+00, -4.0043e+00]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[ 0.0672,  0.5459, -0.3873, -0.4121, -0.3755, -0.4115, -0.3529],\n",
      "        [ 0.1221,  2.2000, -1.4363, -1.3703, -1.3611, -1.4202, -1.3291],\n",
      "        [-0.0405,  4.8727, -2.9700, -2.7551, -2.8066, -2.8663, -2.7782],\n",
      "        [-0.2699,  6.6734, -3.8635, -3.5753, -3.6498, -3.7062, -3.6749],\n",
      "        [-0.3975,  7.3110, -4.1352, -3.8260, -3.8961, -3.9539, -3.9517],\n",
      "        [-0.4458,  7.5080, -4.2154, -3.8941, -3.9645, -4.0187, -4.0242],\n",
      "        [-0.4622,  7.5750, -4.2439, -3.9153, -3.9890, -4.0376, -4.0461],\n",
      "        [-0.4682,  7.6008, -4.2556, -3.9232, -3.9997, -4.0433, -4.0536],\n",
      "        [-0.4711,  7.6121, -4.2607, -3.9267, -4.0050, -4.0451, -4.0564],\n",
      "        [-0.4731,  7.6174, -4.2629, -3.9282, -4.0077, -4.0454, -4.0572],\n",
      "        [-0.4746,  7.6203, -4.2639, -3.9289, -4.0092, -4.0452, -4.0572],\n",
      "        [-0.4759,  7.6219, -4.2642, -3.9291, -4.0099, -4.0450, -4.0569],\n",
      "        [-0.4771,  7.6228, -4.2641, -3.9291, -4.0102, -4.0447, -4.0565],\n",
      "        [-0.4780,  7.6235, -4.2640, -3.9290, -4.0103, -4.0444, -4.0561],\n",
      "        [-0.4788,  7.6239, -4.2638, -3.9288, -4.0104, -4.0443, -4.0557],\n",
      "        [-0.4795,  7.6242, -4.2635, -3.9287, -4.0103, -4.0441, -4.0554]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[ 0.0643,  0.5788, -0.4082, -0.4320, -0.3954, -0.4320, -0.3729],\n",
      "        [ 0.1041,  2.3263, -1.5140, -1.4433, -1.4360, -1.4956, -1.4032],\n",
      "        [-0.0816,  5.0364, -3.0662, -2.8475, -2.9005, -2.9605, -2.8742],\n",
      "        [-0.3138,  6.7777, -3.9286, -3.6400, -3.7134, -3.7719, -3.7412],\n",
      "        [-0.4370,  7.3834, -4.1887, -3.8791, -3.9469, -4.0075, -4.0030],\n",
      "        [-0.4845,  7.5708, -4.2651, -3.9438, -4.0114, -4.0692, -4.0706],\n",
      "        [-0.5027,  7.6353, -4.2912, -3.9636, -4.0338, -4.0873, -4.0899],\n",
      "        [-0.5115,  7.6606, -4.3006, -3.9703, -4.0429, -4.0927, -4.0956],\n",
      "        [-0.5162,  7.6724, -4.3046, -3.9733, -4.0473, -4.0946, -4.0977],\n",
      "        [-0.5192,  7.6785, -4.3062, -3.9747, -4.0495, -4.0952, -4.0983],\n",
      "        [-0.5203,  7.6820, -4.3076, -3.9758, -4.0512, -4.0954, -4.0988],\n",
      "        [-0.5215,  7.6840, -4.3081, -3.9764, -4.0521, -4.0954, -4.0988],\n",
      "        [-0.5224,  7.6852, -4.3083, -3.9767, -4.0525, -4.0953, -4.0986],\n",
      "        [-0.5229,  7.6861, -4.3086, -3.9770, -4.0529, -4.0952, -4.0986],\n",
      "        [-0.5223,  7.6868, -4.3095, -3.9775, -4.0537, -4.0953, -4.0990],\n",
      "        [-0.5211,  7.6872, -4.3108, -3.9781, -4.0547, -4.0954, -4.0997]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[ 0.0612,  0.6044, -0.4246, -0.4477, -0.4113, -0.4482, -0.3886],\n",
      "        [ 0.0868,  2.4574, -1.5968, -1.5199, -1.5149, -1.5745, -1.4811],\n",
      "        [-0.1189,  5.2583, -3.2012, -2.9737, -3.0284, -3.0872, -3.0050],\n",
      "        [-0.3496,  6.9381, -4.0316, -3.7377, -3.8066, -3.8670, -3.8404],\n",
      "        [-0.4688,  7.4828, -4.2627, -3.9496, -4.0119, -4.0750, -4.0701],\n",
      "        [-0.5143,  7.6453, -4.3271, -4.0033, -4.0666, -4.1261, -4.1257],\n",
      "        [-0.5322,  7.7003, -4.3480, -4.0188, -4.0851, -4.1401, -4.1406],\n",
      "        [-0.5408,  7.7221, -4.3553, -4.0240, -4.0927, -4.1441, -4.1448],\n",
      "        [-0.5461,  7.7322, -4.3579, -4.0259, -4.0961, -4.1452, -4.1458],\n",
      "        [-0.5498,  7.7374, -4.3586, -4.0267, -4.0977, -4.1454, -4.1457],\n",
      "        [-0.5524,  7.7405, -4.3587, -4.0270, -4.0985, -4.1453, -4.1453],\n",
      "        [-0.5543,  7.7423, -4.3586, -4.0271, -4.0988, -4.1451, -4.1448],\n",
      "        [-0.5553,  7.7436, -4.3587, -4.0273, -4.0992, -4.1450, -4.1446],\n",
      "        [-0.5544,  7.7446, -4.3600, -4.0280, -4.1003, -4.1451, -4.1453],\n",
      "        [-0.5525,  7.7453, -4.3619, -4.0290, -4.1017, -4.1453, -4.1463],\n",
      "        [-0.5502,  7.7455, -4.3638, -4.0301, -4.1031, -4.1454, -4.1474]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[ 0.0572,  0.6155, -0.4322, -0.4551, -0.4187, -0.4557, -0.3959],\n",
      "        [ 0.0709,  2.5184, -1.6374, -1.5586, -1.5541, -1.6135, -1.5199],\n",
      "        [-0.1493,  5.3662, -3.2719, -3.0419, -3.0967, -3.1553, -3.0747],\n",
      "        [-0.3817,  7.0270, -4.0955, -3.7999, -3.8660, -3.9282, -3.9021],\n",
      "        [-0.4957,  7.5536, -4.3224, -4.0066, -4.0651, -4.1297, -4.1246],\n",
      "        [-0.5363,  7.7078, -4.3861, -4.0586, -4.1184, -4.1780, -4.1781],\n",
      "        [-0.5506,  7.7586, -4.4074, -4.0736, -4.1371, -4.1905, -4.1927],\n",
      "        [-0.5567,  7.7781, -4.4155, -4.0789, -4.1451, -4.1937, -4.1971],\n",
      "        [-0.5600,  7.7868, -4.4189, -4.0812, -4.1491, -4.1944, -4.1984],\n",
      "        [-0.5623,  7.7912, -4.4203, -4.0822, -4.1512, -4.1943, -4.1986],\n",
      "        [-0.5640,  7.7937, -4.4209, -4.0828, -4.1523, -4.1941, -4.1984],\n",
      "        [-0.5653,  7.7952, -4.4211, -4.0831, -4.1530, -4.1938, -4.1981],\n",
      "        [-0.5663,  7.7962, -4.4211, -4.0832, -4.1533, -4.1936, -4.1978],\n",
      "        [-0.5672,  7.7969, -4.4210, -4.0832, -4.1536, -4.1934, -4.1975],\n",
      "        [-0.5678,  7.7974, -4.4209, -4.0833, -4.1537, -4.1932, -4.1972],\n",
      "        [-0.5683,  7.7977, -4.4208, -4.0832, -4.1538, -4.1931, -4.1970]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[ 0.0546,  0.6562, -0.4581, -0.4796, -0.4436, -0.4812, -0.4205],\n",
      "        [ 0.0505,  2.6905, -1.7448, -1.6581, -1.6568, -1.7162, -1.6212],\n",
      "        [-0.1902,  5.5886, -3.4049, -3.1667, -3.2232, -3.2817, -3.2050],\n",
      "        [-0.4193,  7.1583, -4.1802, -3.8809, -3.9429, -4.0077, -3.9837],\n",
      "        [-0.5265,  7.6337, -4.3847, -4.0661, -4.1204, -4.1870, -4.1811],\n",
      "        [-0.5639,  7.7705, -4.4411, -4.1113, -4.1676, -4.2286, -4.2270],\n",
      "        [-0.5774,  7.8154, -4.4596, -4.1241, -4.1842, -4.2388, -4.2391],\n",
      "        [-0.5833,  7.8326, -4.4665, -4.1285, -4.1913, -4.2412, -4.2425],\n",
      "        [-0.5868,  7.8403, -4.4693, -4.1304, -4.1949, -4.2415, -4.2434],\n",
      "        [-0.5895,  7.8443, -4.4703, -4.1311, -4.1966, -4.2413, -4.2432],\n",
      "        [-0.5923,  7.8465, -4.4699, -4.1311, -4.1971, -4.2409, -4.2423],\n",
      "        [-0.5941,  7.8480, -4.4696, -4.1312, -4.1975, -4.2405, -4.2418],\n",
      "        [-0.5952,  7.8491, -4.4695, -4.1312, -4.1978, -4.2403, -4.2415],\n",
      "        [-0.5959,  7.8498, -4.4696, -4.1314, -4.1980, -4.2401, -4.2412],\n",
      "        [-0.5963,  7.8503, -4.4697, -4.1315, -4.1983, -4.2400, -4.2411],\n",
      "        [-0.5965,  7.8507, -4.4698, -4.1316, -4.1985, -4.2399, -4.2410]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[ 0.0511,  0.6824, -0.4751, -0.4958, -0.4600, -0.4980, -0.4367],\n",
      "        [ 0.0319,  2.8056, -1.8184, -1.7269, -1.7274, -1.7867, -1.6909],\n",
      "        [-0.2240,  5.7435, -3.5018, -3.2586, -3.3154, -3.3742, -3.3001],\n",
      "        [-0.4517,  7.2561, -4.2486, -3.9465, -4.0051, -4.0720, -4.0489],\n",
      "        [-0.5549,  7.7001, -4.4398, -4.1189, -4.1696, -4.2381, -4.2308],\n",
      "        [-0.5906,  7.8265, -4.4917, -4.1601, -4.2132, -4.2757, -4.2721],\n",
      "        [-0.6036,  7.8677, -4.5086, -4.1716, -4.2285, -4.2846, -4.2827],\n",
      "        [-0.6094,  7.8836, -4.5148, -4.1756, -4.2352, -4.2865, -4.2855],\n",
      "        [-0.6128,  7.8908, -4.5174, -4.1772, -4.2384, -4.2867, -4.2861],\n",
      "        [-0.6151,  7.8946, -4.5184, -4.1780, -4.2402, -4.2864, -4.2861],\n",
      "        [-0.6168,  7.8967, -4.5187, -4.1784, -4.2412, -4.2860, -4.2857],\n",
      "        [-0.6181,  7.8981, -4.5188, -4.1786, -4.2417, -4.2857, -4.2854],\n",
      "        [-0.6192,  7.8990, -4.5188, -4.1787, -4.2420, -4.2854, -4.2850],\n",
      "        [-0.6200,  7.8996, -4.5186, -4.1787, -4.2422, -4.2852, -4.2847],\n",
      "        [-0.6207,  7.9000, -4.5185, -4.1787, -4.2423, -4.2850, -4.2844],\n",
      "        [-0.6212,  7.9004, -4.5184, -4.1787, -4.2424, -4.2849, -4.2842]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[ 0.0475,  0.7089, -0.4923, -0.5123, -0.4766, -0.5150, -0.4532],\n",
      "        [ 0.0129,  2.9199, -1.8921, -1.7957, -1.7979, -1.8571, -1.7607],\n",
      "        [-0.2571,  5.8843, -3.5909, -3.3431, -3.4002, -3.4595, -3.3876],\n",
      "        [-0.4825,  7.3455, -4.3128, -4.0085, -4.0634, -4.1327, -4.1098],\n",
      "        [-0.5817,  7.7630, -4.4933, -4.1703, -4.2174, -4.2878, -4.2790],\n",
      "        [-0.6156,  7.8803, -4.5415, -4.2082, -4.2579, -4.3218, -4.3165],\n",
      "        [-0.6280,  7.9182, -4.5569, -4.2185, -4.2721, -4.3295, -4.3256],\n",
      "        [-0.6338,  7.9328, -4.5625, -4.2219, -4.2782, -4.3309, -4.3279],\n",
      "        [-0.6379,  7.9393, -4.5642, -4.2231, -4.2810, -4.3308, -4.3279],\n",
      "        [-0.6405,  7.9428, -4.5649, -4.2236, -4.2825, -4.3303, -4.3276],\n",
      "        [-0.6423,  7.9449, -4.5651, -4.2239, -4.2833, -4.3299, -4.3271],\n",
      "        [-0.6435,  7.9462, -4.5652, -4.2240, -4.2839, -4.3296, -4.3268],\n",
      "        [-0.6452,  7.9471, -4.5647, -4.2239, -4.2839, -4.3293, -4.3261],\n",
      "        [-0.6470,  7.9476, -4.5638, -4.2236, -4.2836, -4.3289, -4.3252],\n",
      "        [-0.6484,  7.9482, -4.5631, -4.2233, -4.2834, -4.3287, -4.3246],\n",
      "        [-0.6504,  7.9485, -4.5619, -4.2228, -4.2828, -4.3285, -4.3236]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[ 3.8555e-02,  6.4781e-01, -4.5167e-01, -4.7454e-01, -4.3907e-01,\n",
      "         -4.7596e-01, -4.1478e-01],\n",
      "        [ 1.3511e-03,  2.6078e+00, -1.6938e+00, -1.6178e+00, -1.6147e+00,\n",
      "         -1.6735e+00, -1.5770e+00],\n",
      "        [-2.6499e-01,  5.5201e+00, -3.3826e+00, -3.1596e+00, -3.2148e+00,\n",
      "         -3.2755e+00, -3.1899e+00],\n",
      "        [-5.0660e-01,  7.2140e+00, -4.2484e+00, -3.9575e+00, -4.0191e+00,\n",
      "         -4.0881e+00, -4.0524e+00],\n",
      "        [-6.1702e-01,  7.7515e+00, -4.4943e+00, -4.1805e+00, -4.2288e+00,\n",
      "         -4.3036e+00, -4.2858e+00],\n",
      "        [-6.5493e-01,  7.9085e+00, -4.5648e+00, -4.2380e+00, -4.2848e+00,\n",
      "         -4.3560e+00, -4.3419e+00],\n",
      "        [-6.6767e-01,  7.9593e+00, -4.5881e+00, -4.2545e+00, -4.3041e+00,\n",
      "         -4.3694e+00, -4.3568e+00],\n",
      "        [-6.7342e-01,  7.9781e+00, -4.5965e+00, -4.2600e+00, -4.3120e+00,\n",
      "         -4.3726e+00, -4.3607e+00],\n",
      "        [-6.7634e-01,  7.9864e+00, -4.5999e+00, -4.2622e+00, -4.3160e+00,\n",
      "         -4.3731e+00, -4.3618e+00],\n",
      "        [-6.7796e-01,  7.9905e+00, -4.6015e+00, -4.2633e+00, -4.3182e+00,\n",
      "         -4.3729e+00, -4.3621e+00],\n",
      "        [-6.7930e-01,  7.9928e+00, -4.6023e+00, -4.2639e+00, -4.3194e+00,\n",
      "         -4.3726e+00, -4.3619e+00],\n",
      "        [-6.8037e-01,  7.9942e+00, -4.6025e+00, -4.2642e+00, -4.3201e+00,\n",
      "         -4.3723e+00, -4.3615e+00],\n",
      "        [-6.8067e-01,  7.9952e+00, -4.6030e+00, -4.2645e+00, -4.3208e+00,\n",
      "         -4.3721e+00, -4.3615e+00],\n",
      "        [-6.8096e-01,  7.9959e+00, -4.6032e+00, -4.2647e+00, -4.3212e+00,\n",
      "         -4.3719e+00, -4.3614e+00],\n",
      "        [-6.8125e-01,  7.9962e+00, -4.6033e+00, -4.2647e+00, -4.3214e+00,\n",
      "         -4.3717e+00, -4.3612e+00],\n",
      "        [-6.8149e-01,  7.9965e+00, -4.6033e+00, -4.2648e+00, -4.3216e+00,\n",
      "         -4.3716e+00, -4.3610e+00]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[ 0.0341,  0.7267, -0.5012, -0.5214, -0.4863, -0.5249, -0.4621],\n",
      "        [-0.0335,  2.9626, -1.9132, -1.8201, -1.8233, -1.8831, -1.7843],\n",
      "        [-0.3243,  5.9567, -3.6391, -3.3971, -3.4546, -3.5164, -3.4399],\n",
      "        [-0.5487,  7.4360, -4.3866, -4.0858, -4.1382, -4.2121, -4.1822],\n",
      "        [-0.6445,  7.8587, -4.5771, -4.2562, -4.2979, -4.3745, -4.3574],\n",
      "        [-0.6766,  7.9771, -4.6286, -4.2968, -4.3397, -4.4106, -4.3964],\n",
      "        [-0.6882,  8.0151, -4.6449, -4.3077, -4.3541, -4.4188, -4.4058],\n",
      "        [-0.6938,  8.0294, -4.6507, -4.3112, -4.3602, -4.4204, -4.4080],\n",
      "        [-0.6972,  8.0359, -4.6528, -4.3125, -4.3631, -4.4203, -4.4082],\n",
      "        [-0.6994,  8.0392, -4.6535, -4.3130, -4.3647, -4.4197, -4.4078],\n",
      "        [-0.7011,  8.0411, -4.6537, -4.3133, -4.3655, -4.4193, -4.4074],\n",
      "        [-0.7022,  8.0423, -4.6537, -4.3134, -4.3660, -4.4189, -4.4070],\n",
      "        [-0.7032,  8.0432, -4.6536, -4.3135, -4.3663, -4.4186, -4.4066],\n",
      "        [-0.7042,  8.0437, -4.6533, -4.3134, -4.3664, -4.4183, -4.4061],\n",
      "        [-0.7050,  8.0441, -4.6531, -4.3133, -4.3664, -4.4181, -4.4057],\n",
      "        [-0.7056,  8.0444, -4.6528, -4.3132, -4.3664, -4.4180, -4.4054]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[ 0.0312,  0.8136, -0.5574, -0.5745, -0.5397, -0.5797, -0.5154],\n",
      "        [-0.0672,  3.3187, -2.1374, -2.0260, -2.0351, -2.0949, -1.9952],\n",
      "        [-0.3726,  6.3138, -3.8534, -3.5952, -3.6521, -3.7160, -3.6483],\n",
      "        [-0.5815,  7.5988, -4.4951, -4.1858, -4.2300, -4.3074, -4.2819],\n",
      "        [-0.6650,  7.9405, -4.6471, -4.3195, -4.3563, -4.4330, -4.4174],\n",
      "        [-0.6929,  8.0339, -4.6866, -4.3494, -4.3893, -4.4589, -4.4458],\n",
      "        [-0.7039,  8.0637, -4.6985, -4.3570, -4.4007, -4.4640, -4.4519],\n",
      "        [-0.7092,  8.0752, -4.7028, -4.3593, -4.4057, -4.4645, -4.4529],\n",
      "        [-0.7125,  8.0803, -4.7042, -4.3601, -4.4081, -4.4640, -4.4526],\n",
      "        [-0.7148,  8.0830, -4.7047, -4.3604, -4.4093, -4.4633, -4.4520],\n",
      "        [-0.7165,  8.0846, -4.7048, -4.3605, -4.4100, -4.4628, -4.4515],\n",
      "        [-0.7178,  8.0857, -4.7047, -4.3606, -4.4104, -4.4625, -4.4510],\n",
      "        [-0.7191,  8.0865, -4.7044, -4.3606, -4.4106, -4.4622, -4.4505],\n",
      "        [-0.7203,  8.0870, -4.7040, -4.3604, -4.4106, -4.4619, -4.4499],\n",
      "        [-0.7213,  8.0875, -4.7035, -4.3603, -4.4105, -4.4617, -4.4495],\n",
      "        [-0.7221,  8.0877, -4.7031, -4.3600, -4.4104, -4.4615, -4.4491]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[ 0.0259,  0.8750, -0.5965, -0.6114, -0.5771, -0.6181, -0.5527],\n",
      "        [-0.0947,  3.5372, -2.2766, -2.1548, -2.1671, -2.2268, -2.1269],\n",
      "        [-0.4082,  6.5114, -3.9773, -3.7109, -3.7664, -3.8321, -3.7688],\n",
      "        [-0.6094,  7.6942, -4.5656, -4.2520, -4.2913, -4.3709, -4.3463],\n",
      "        [-0.6875,  7.9989, -4.7001, -4.3694, -4.4027, -4.4804, -4.4639],\n",
      "        [-0.7135,  8.0814, -4.7344, -4.3949, -4.4319, -4.5021, -4.4877],\n",
      "        [-0.7239,  8.1078, -4.7448, -4.4012, -4.4421, -4.5060, -4.4925],\n",
      "        [-0.7293,  8.1180, -4.7484, -4.4030, -4.4465, -4.5062, -4.4930],\n",
      "        [-0.7327,  8.1228, -4.7496, -4.4036, -4.4487, -4.5056, -4.4925],\n",
      "        [-0.7351,  8.1253, -4.7499, -4.4038, -4.4498, -4.5050, -4.4919],\n",
      "        [-0.7368,  8.1268, -4.7498, -4.4038, -4.4504, -4.5044, -4.4912],\n",
      "        [-0.7382,  8.1278, -4.7496, -4.4037, -4.4508, -4.5040, -4.4907],\n",
      "        [-0.7392,  8.1281, -4.7492, -4.4035, -4.4508, -4.5034, -4.4901],\n",
      "        [-0.7395,  8.1287, -4.7495, -4.4036, -4.4512, -4.5033, -4.4899],\n",
      "        [-0.7399,  8.1291, -4.7496, -4.4037, -4.4514, -4.5032, -4.4897],\n",
      "        [-0.7403,  8.1293, -4.7494, -4.4037, -4.4514, -4.5029, -4.4895]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[ 0.0182,  0.9238, -0.6261, -0.6395, -0.6060, -0.6481, -0.5814],\n",
      "        [-0.1276,  3.7426, -2.4038, -2.2729, -2.2890, -2.3488, -2.2482],\n",
      "        [-0.4464,  6.7011, -4.0943, -3.8208, -3.8741, -3.9429, -3.8826],\n",
      "        [-0.6385,  7.7855, -4.6325, -4.3154, -4.3496, -4.4319, -4.4069],\n",
      "        [-0.7102,  8.0548, -4.7510, -4.4176, -4.4477, -4.5263, -4.5085],\n",
      "        [-0.7340,  8.1270, -4.7809, -4.4391, -4.4735, -4.5443, -4.5284],\n",
      "        [-0.7433,  8.1502, -4.7902, -4.4442, -4.4827, -4.5471, -4.5322],\n",
      "        [-0.7477,  8.1591, -4.7936, -4.4457, -4.4869, -4.5468, -4.5325],\n",
      "        [-0.7500,  8.1633, -4.7952, -4.4464, -4.4892, -4.5461, -4.5323],\n",
      "        [-0.7518,  8.1655, -4.7959, -4.4468, -4.4904, -4.5455, -4.5318],\n",
      "        [-0.7534,  8.1666, -4.7959, -4.4468, -4.4910, -4.5449, -4.5311],\n",
      "        [-0.7544,  8.1673, -4.7958, -4.4468, -4.4914, -4.5443, -4.5306],\n",
      "        [-0.7552,  8.1677, -4.7956, -4.4466, -4.4916, -4.5439, -4.5301],\n",
      "        [-0.7560,  8.1681, -4.7955, -4.4466, -4.4917, -4.5437, -4.5297],\n",
      "        [-0.7564,  8.1684, -4.7955, -4.4465, -4.4918, -4.5435, -4.5294],\n",
      "        [-0.7566,  8.1686, -4.7956, -4.4466, -4.4920, -4.5434, -4.5293]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[ 0.0207,  0.8751, -0.6008, -0.6156, -0.5818, -0.6222, -0.5570],\n",
      "        [-0.1134,  3.6220, -2.3504, -2.2238, -2.2370, -2.2950, -2.1964],\n",
      "        [-0.4425,  6.6594, -4.0993, -3.8251, -3.8775, -3.9449, -3.8839],\n",
      "        [-0.6467,  7.8050, -4.6704, -4.3507, -4.3831, -4.4658, -4.4405],\n",
      "        [-0.7239,  8.0889, -4.7947, -4.4587, -4.4863, -4.5655, -4.5473],\n",
      "        [-0.7494,  8.1643, -4.8255, -4.4810, -4.5129, -4.5841, -4.5677],\n",
      "        [-0.7595,  8.1885, -4.8350, -4.4865, -4.5223, -4.5872, -4.5715],\n",
      "        [-0.7644,  8.1979, -4.8384, -4.4881, -4.5266, -4.5870, -4.5718],\n",
      "        [-0.7675,  8.2020, -4.8395, -4.4885, -4.5286, -4.5862, -4.5711],\n",
      "        [-0.7697,  8.2041, -4.8399, -4.4885, -4.5297, -4.5854, -4.5703],\n",
      "        [-0.7712,  8.2053, -4.8399, -4.4885, -4.5304, -4.5848, -4.5697],\n",
      "        [-0.7723,  8.2061, -4.8399, -4.4885, -4.5307, -4.5843, -4.5691],\n",
      "        [-0.7732,  8.2066, -4.8398, -4.4884, -4.5309, -4.5839, -4.5686],\n",
      "        [-0.7739,  8.2069, -4.8396, -4.4884, -4.5310, -4.5837, -4.5682],\n",
      "        [-0.7744,  8.2072, -4.8395, -4.4883, -4.5311, -4.5834, -4.5679],\n",
      "        [-0.7749,  8.2074, -4.8394, -4.4883, -4.5312, -4.5833, -4.5676]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[ 0.0185,  0.9102, -0.6260, -0.6395, -0.6056, -0.6461, -0.5806],\n",
      "        [-0.1280,  3.7165, -2.4189, -2.2876, -2.3013, -2.3589, -2.2609],\n",
      "        [-0.4621,  6.7273, -4.1555, -3.8778, -3.9295, -3.9971, -3.9378],\n",
      "        [-0.6668,  7.8481, -4.7142, -4.3924, -4.4232, -4.5065, -4.4809],\n",
      "        [-0.7436,  8.1280, -4.8373, -4.4994, -4.5249, -4.6051, -4.5855],\n",
      "        [-0.7691,  8.2029, -4.8680, -4.5218, -4.5514, -4.6237, -4.6055],\n",
      "        [-0.7792,  8.2268, -4.8773, -4.5272, -4.5607, -4.6267, -4.6090],\n",
      "        [-0.7842,  8.2362, -4.8809, -4.5289, -4.5650, -4.6266, -4.6092],\n",
      "        [-0.7871,  8.2404, -4.8822, -4.5294, -4.5671, -4.6259, -4.6086],\n",
      "        [-0.7891,  8.2425, -4.8827, -4.5296, -4.5683, -4.6252, -4.6079],\n",
      "        [-0.7904,  8.2439, -4.8830, -4.5297, -4.5691, -4.6247, -4.6074],\n",
      "        [-0.7915,  8.2446, -4.8830, -4.5296, -4.5694, -4.6242, -4.6069],\n",
      "        [-0.7923,  8.2450, -4.8828, -4.5296, -4.5696, -4.6238, -4.6064],\n",
      "        [-0.7930,  8.2453, -4.8827, -4.5295, -4.5697, -4.6235, -4.6060],\n",
      "        [-0.7937,  8.2455, -4.8825, -4.5295, -4.5697, -4.6233, -4.6057],\n",
      "        [-0.7941,  8.2458, -4.8825, -4.5295, -4.5698, -4.6233, -4.6055]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[ 0.0137,  0.9414, -0.6470, -0.6595, -0.6259, -0.6667, -0.6006],\n",
      "        [-0.1486,  3.8281, -2.4946, -2.3582, -2.3734, -2.4309, -2.3329],\n",
      "        [-0.4879,  6.8266, -4.2265, -3.9448, -3.9950, -4.0642, -4.0062],\n",
      "        [-0.6889,  7.9081, -4.7672, -4.4426, -4.4700, -4.5552, -4.5288],\n",
      "        [-0.7629,  8.1733, -4.8841, -4.5437, -4.5664, -4.6478, -4.6267],\n",
      "        [-0.7876,  8.2435, -4.9126, -4.5642, -4.5913, -4.6646, -4.6448],\n",
      "        [-0.7977,  8.2658, -4.9211, -4.5689, -4.6000, -4.6669, -4.6476],\n",
      "        [-0.8028,  8.2744, -4.9241, -4.5702, -4.6039, -4.6665, -4.6473],\n",
      "        [-0.8059,  8.2784, -4.9252, -4.5705, -4.6058, -4.6657, -4.6466],\n",
      "        [-0.8080,  8.2805, -4.9257, -4.5707, -4.6070, -4.6651, -4.6459],\n",
      "        [-0.8094,  8.2816, -4.9257, -4.5707, -4.6076, -4.6644, -4.6452],\n",
      "        [-0.8105,  8.2823, -4.9256, -4.5706, -4.6079, -4.6639, -4.6446],\n",
      "        [-0.8113,  8.2827, -4.9256, -4.5705, -4.6081, -4.6636, -4.6442],\n",
      "        [-0.8119,  8.2831, -4.9255, -4.5704, -4.6083, -4.6633, -4.6438],\n",
      "        [-0.8124,  8.2833, -4.9254, -4.5704, -4.6083, -4.6631, -4.6435],\n",
      "        [-0.8128,  8.2835, -4.9253, -4.5703, -4.6084, -4.6629, -4.6432]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[ 0.0088,  0.9735, -0.6687, -0.6801, -0.6468, -0.6880, -0.6213],\n",
      "        [-0.1695,  3.9399, -2.5708, -2.4293, -2.4460, -2.5033, -2.4055],\n",
      "        [-0.5131,  6.9223, -4.2960, -4.0105, -4.0590, -4.1299, -4.0730],\n",
      "        [-0.7111,  7.9610, -4.8156, -4.4888, -4.5137, -4.6001, -4.5730],\n",
      "        [-0.7834,  8.2145, -4.9275, -4.5853, -4.6058, -4.6882, -4.6655],\n",
      "        [-0.8074,  8.2819, -4.9550, -4.6051, -4.6298, -4.7042, -4.6825],\n",
      "        [-0.8171,  8.3035, -4.9634, -4.6096, -4.6383, -4.7064, -4.6851],\n",
      "        [-0.8220,  8.3119, -4.9664, -4.6109, -4.6422, -4.7061, -4.6848],\n",
      "        [-0.8248,  8.3157, -4.9676, -4.6112, -4.6442, -4.7053, -4.6841],\n",
      "        [-0.8267,  8.3177, -4.9680, -4.6113, -4.6453, -4.7045, -4.6834],\n",
      "        [-0.8280,  8.3188, -4.9682, -4.6113, -4.6459, -4.7039, -4.6827],\n",
      "        [-0.8290,  8.3195, -4.9683, -4.6113, -4.6463, -4.7035, -4.6822],\n",
      "        [-0.8297,  8.3199, -4.9682, -4.6113, -4.6466, -4.7031, -4.6818],\n",
      "        [-0.8303,  8.3202, -4.9682, -4.6112, -4.6467, -4.7029, -4.6814],\n",
      "        [-0.8307,  8.3205, -4.9683, -4.6113, -4.6469, -4.7028, -4.6812],\n",
      "        [-0.8308,  8.3209, -4.9685, -4.6115, -4.6471, -4.7028, -4.6812]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[ 3.7149e-03,  1.0064e+00, -6.9116e-01, -7.0138e-01, -6.6844e-01,\n",
      "         -7.0988e-01, -6.4261e-01],\n",
      "        [-1.9056e-01,  4.0518e+00, -2.6475e+00, -2.5010e+00, -2.5190e+00,\n",
      "         -2.5762e+00, -2.4786e+00],\n",
      "        [-5.3776e-01,  7.0147e+00, -4.3642e+00, -4.0748e+00, -4.1215e+00,\n",
      "         -4.1942e+00, -4.1384e+00],\n",
      "        [-7.3280e-01,  8.0148e+00, -4.8653e+00, -4.5361e+00, -4.5581e+00,\n",
      "         -4.6460e+00, -4.6179e+00],\n",
      "        [-8.0230e-01,  8.2565e+00, -4.9724e+00, -4.6281e+00, -4.6461e+00,\n",
      "         -4.7295e+00, -4.7055e+00],\n",
      "        [-8.2550e-01,  8.3205e+00, -4.9986e+00, -4.6466e+00, -4.6690e+00,\n",
      "         -4.7443e+00, -4.7211e+00],\n",
      "        [-8.3503e-01,  8.3409e+00, -5.0065e+00, -4.6508e+00, -4.6771e+00,\n",
      "         -4.7462e+00, -4.7232e+00],\n",
      "        [-8.3991e-01,  8.3488e+00, -5.0093e+00, -4.6518e+00, -4.6808e+00,\n",
      "         -4.7457e+00, -4.7227e+00],\n",
      "        [-8.4261e-01,  8.3526e+00, -5.0105e+00, -4.6522e+00, -4.6828e+00,\n",
      "         -4.7450e+00, -4.7221e+00],\n",
      "        [-8.4451e-01,  8.3544e+00, -5.0109e+00, -4.6522e+00, -4.6838e+00,\n",
      "         -4.7442e+00, -4.7212e+00],\n",
      "        [-8.4571e-01,  8.3556e+00, -5.0112e+00, -4.6523e+00, -4.6845e+00,\n",
      "         -4.7436e+00, -4.7207e+00],\n",
      "        [-8.4676e-01,  8.3561e+00, -5.0111e+00, -4.6522e+00, -4.6849e+00,\n",
      "         -4.7431e+00, -4.7201e+00],\n",
      "        [-8.4732e-01,  8.3568e+00, -5.0113e+00, -4.6523e+00, -4.6853e+00,\n",
      "         -4.7429e+00, -4.7198e+00],\n",
      "        [-8.4756e-01,  8.3573e+00, -5.0117e+00, -4.6525e+00, -4.6856e+00,\n",
      "         -4.7430e+00, -4.7197e+00],\n",
      "        [-8.4787e-01,  8.3576e+00, -5.0119e+00, -4.6527e+00, -4.6858e+00,\n",
      "         -4.7430e+00, -4.7196e+00],\n",
      "        [-8.4820e-01,  8.3578e+00, -5.0120e+00, -4.6528e+00, -4.6860e+00,\n",
      "         -4.7430e+00, -4.7195e+00]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[-0.0137,  1.1512, -0.7795, -0.7848, -0.7538, -0.7980, -0.7276],\n",
      "        [-0.2544,  4.4562, -2.8911, -2.7273, -2.7518, -2.8106, -2.7127],\n",
      "        [-0.5920,  7.2712, -4.5156, -4.2171, -4.2577, -4.3368, -4.2847],\n",
      "        [-0.7654,  8.1130, -4.9354, -4.6023, -4.6186, -4.7089, -4.6800],\n",
      "        [-0.8246,  8.3098, -5.0223, -4.6749, -4.6905, -4.7741, -4.7486],\n",
      "        [-0.8447,  8.3622, -5.0437, -4.6891, -4.7095, -4.7851, -4.7603],\n",
      "        [-0.8532,  8.3793, -5.0502, -4.6922, -4.7165, -4.7861, -4.7615],\n",
      "        [-0.8573,  8.3863, -5.0529, -4.6931, -4.7199, -4.7856, -4.7611],\n",
      "        [-0.8599,  8.3896, -5.0540, -4.6935, -4.7217, -4.7849, -4.7603],\n",
      "        [-0.8616,  8.3914, -5.0545, -4.6937, -4.7228, -4.7843, -4.7597],\n",
      "        [-0.8628,  8.3923, -5.0546, -4.6936, -4.7234, -4.7837, -4.7590],\n",
      "        [-0.8640,  8.3925, -5.0542, -4.6932, -4.7235, -4.7830, -4.7582],\n",
      "        [-0.8649,  8.3927, -5.0538, -4.6929, -4.7236, -4.7825, -4.7575],\n",
      "        [-0.8656,  8.3929, -5.0536, -4.6927, -4.7236, -4.7821, -4.7571],\n",
      "        [-0.8660,  8.3930, -5.0535, -4.6926, -4.7237, -4.7819, -4.7567],\n",
      "        [-0.8664,  8.3931, -5.0535, -4.6925, -4.7237, -4.7817, -4.7564]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[-7.2097e-03,  1.0754e+00, -7.3827e-01, -7.4608e-01, -7.1387e-01,\n",
      "         -7.5586e-01, -6.8744e-01],\n",
      "        [-2.3339e-01,  4.2764e+00, -2.8024e+00, -2.6458e+00, -2.6664e+00,\n",
      "         -2.7235e+00, -2.6265e+00],\n",
      "        [-5.8575e-01,  7.1906e+00, -4.4968e+00, -4.2001e+00, -4.2428e+00,\n",
      "         -4.3189e+00, -4.2651e+00],\n",
      "        [-7.7345e-01,  8.1171e+00, -4.9632e+00, -4.6291e+00, -4.6454e+00,\n",
      "         -4.7359e+00, -4.7062e+00],\n",
      "        [-8.3886e-01,  8.3371e+00, -5.0612e+00, -4.7124e+00, -4.7258e+00,\n",
      "         -4.8108e+00, -4.7841e+00],\n",
      "        [-8.6080e-01,  8.3954e+00, -5.0851e+00, -4.7290e+00, -4.7469e+00,\n",
      "         -4.8239e+00, -4.7975e+00],\n",
      "        [-8.6997e-01,  8.4142e+00, -5.0923e+00, -4.7327e+00, -4.7544e+00,\n",
      "         -4.8253e+00, -4.7990e+00],\n",
      "        [-8.7472e-01,  8.4215e+00, -5.0949e+00, -4.7335e+00, -4.7578e+00,\n",
      "         -4.8247e+00, -4.7983e+00],\n",
      "        [-8.7754e-01,  8.4248e+00, -5.0958e+00, -4.7337e+00, -4.7596e+00,\n",
      "         -4.8238e+00, -4.7973e+00],\n",
      "        [-8.7937e-01,  8.4265e+00, -5.0962e+00, -4.7336e+00, -4.7606e+00,\n",
      "         -4.8230e+00, -4.7965e+00],\n",
      "        [-8.8064e-01,  8.4274e+00, -5.0963e+00, -4.7336e+00, -4.7612e+00,\n",
      "         -4.8224e+00, -4.7958e+00],\n",
      "        [-8.8157e-01,  8.4280e+00, -5.0963e+00, -4.7335e+00, -4.7616e+00,\n",
      "         -4.8219e+00, -4.7952e+00],\n",
      "        [-8.8228e-01,  8.4284e+00, -5.0963e+00, -4.7335e+00, -4.7618e+00,\n",
      "         -4.8216e+00, -4.7948e+00],\n",
      "        [-8.8283e-01,  8.4286e+00, -5.0962e+00, -4.7334e+00, -4.7619e+00,\n",
      "         -4.8213e+00, -4.7944e+00],\n",
      "        [-8.8327e-01,  8.4288e+00, -5.0962e+00, -4.7333e+00, -4.7620e+00,\n",
      "         -4.8211e+00, -4.7941e+00],\n",
      "        [-8.8362e-01,  8.4289e+00, -5.0961e+00, -4.7333e+00, -4.7621e+00,\n",
      "         -4.8210e+00, -4.7939e+00]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[-0.0130,  1.1113, -0.7630, -0.7696, -0.7377, -0.7800, -0.7110],\n",
      "        [-0.2550,  4.3886, -2.8806, -2.7188, -2.7407, -2.7978, -2.7011],\n",
      "        [-0.6091,  7.2815, -4.5661, -4.2652, -4.3052, -4.3836, -4.3307],\n",
      "        [-0.7923,  8.1722, -5.0161, -4.6788, -4.6914, -4.7836, -4.7532],\n",
      "        [-0.8553,  8.3789, -5.1078, -4.7562, -4.7669, -4.8528, -4.8251],\n",
      "        [-0.8768,  8.4331, -5.1296, -4.7710, -4.7865, -4.8642, -4.8368],\n",
      "        [-0.8860,  8.4504, -5.1360, -4.7740, -4.7934, -4.8652, -4.8376],\n",
      "        [-0.8909,  8.4571, -5.1381, -4.7745, -4.7965, -4.8643, -4.8366],\n",
      "        [-0.8939,  8.4602, -5.1388, -4.7745, -4.7981, -4.8633, -4.8354],\n",
      "        [-0.8958,  8.4617, -5.1390, -4.7743, -4.7991, -4.8624, -4.8345],\n",
      "        [-0.8971,  8.4626, -5.1391, -4.7742, -4.7996, -4.8618, -4.8337],\n",
      "        [-0.8981,  8.4631, -5.1391, -4.7741, -4.7999, -4.8613, -4.8331],\n",
      "        [-0.8989,  8.4635, -5.1390, -4.7740, -4.8001, -4.8609, -4.8326],\n",
      "        [-0.8994,  8.4637, -5.1389, -4.7740, -4.8003, -4.8607, -4.8322],\n",
      "        [-0.8999,  8.4638, -5.1388, -4.7739, -4.8003, -4.8604, -4.8319],\n",
      "        [-0.9003,  8.4639, -5.1387, -4.7738, -4.8004, -4.8603, -4.8316]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[-0.0190,  1.1483, -0.7886, -0.7938, -0.7624, -0.8049, -0.7353],\n",
      "        [-0.2768,  4.5008, -2.9591, -2.7921, -2.8152, -2.8724, -2.7762],\n",
      "        [-0.6320,  7.3553, -4.6251, -4.3211, -4.3593, -4.4391, -4.3868],\n",
      "        [-0.8127,  8.2138, -5.0592, -4.7202, -4.7311, -4.8240, -4.7925],\n",
      "        [-0.8741,  8.4149, -5.1492, -4.7960, -4.8050, -4.8916, -4.8623],\n",
      "        [-0.8949,  8.4681, -5.1712, -4.8109, -4.8244, -4.9030, -4.8738],\n",
      "        [-0.9037,  8.4852, -5.1777, -4.8140, -4.8313, -4.9041, -4.8747],\n",
      "        [-0.9083,  8.4919, -5.1800, -4.8147, -4.8345, -4.9033, -4.8738],\n",
      "        [-0.9111,  8.4950, -5.1809, -4.8147, -4.8362, -4.9023, -4.8727],\n",
      "        [-0.9127,  8.4967, -5.1815, -4.8148, -4.8373, -4.9017, -4.8720],\n",
      "        [-0.9138,  8.4975, -5.1816, -4.8147, -4.8379, -4.9010, -4.8713],\n",
      "        [-0.9147,  8.4979, -5.1816, -4.8146, -4.8382, -4.9005, -4.8707],\n",
      "        [-0.9154,  8.4982, -5.1816, -4.8145, -4.8384, -4.9002, -4.8702],\n",
      "        [-0.9159,  8.4984, -5.1815, -4.8144, -4.8385, -4.8999, -4.8698],\n",
      "        [-0.9164,  8.4985, -5.1814, -4.8143, -4.8386, -4.8997, -4.8695],\n",
      "        [-0.9167,  8.4986, -5.1813, -4.8143, -4.8386, -4.8995, -4.8692]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[-0.0253,  1.1864, -0.8150, -0.8188, -0.7878, -0.8306, -0.7604],\n",
      "        [-0.2987,  4.6128, -3.0377, -2.8657, -2.8899, -2.9472, -2.8515],\n",
      "        [-0.6546,  7.4339, -4.6876, -4.3801, -4.4159, -4.4975, -4.4459],\n",
      "        [-0.8318,  8.2605, -5.1065, -4.7651, -4.7734, -4.8674, -4.8350],\n",
      "        [-0.8913,  8.4528, -5.1929, -4.8376, -4.8443, -4.9317, -4.9011],\n",
      "        [-0.9115,  8.5038, -5.2140, -4.8517, -4.8629, -4.9424, -4.9118],\n",
      "        [-0.9202,  8.5202, -5.2202, -4.8546, -4.8697, -4.9432, -4.9124],\n",
      "        [-0.9248,  8.5266, -5.2224, -4.8551, -4.8727, -4.9424, -4.9114],\n",
      "        [-0.9275,  8.5295, -5.2233, -4.8551, -4.8744, -4.9414, -4.9103],\n",
      "        [-0.9292,  8.5310, -5.2236, -4.8550, -4.8753, -4.9406, -4.9094],\n",
      "        [-0.9303,  8.5317, -5.2237, -4.8549, -4.8759, -4.9400, -4.9086],\n",
      "        [-0.9312,  8.5322, -5.2237, -4.8548, -4.8762, -4.9395, -4.9080],\n",
      "        [-0.9319,  8.5325, -5.2236, -4.8547, -4.8764, -4.9391, -4.9076],\n",
      "        [-0.9324,  8.5327, -5.2236, -4.8546, -4.8765, -4.9389, -4.9072],\n",
      "        [-0.9329,  8.5328, -5.2235, -4.8546, -4.8766, -4.9387, -4.9069],\n",
      "        [-0.9332,  8.5329, -5.2234, -4.8545, -4.8767, -4.9385, -4.9067]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[-0.0318,  1.2255, -0.8421, -0.8446, -0.8140, -0.8570, -0.7863],\n",
      "        [-0.3207,  4.7244, -3.1165, -2.9394, -2.9646, -3.0221, -2.9270],\n",
      "        [-0.6768,  7.5101, -4.7490, -4.4381, -4.4713, -4.5548, -4.5039],\n",
      "        [-0.8505,  8.3060, -5.1533, -4.8096, -4.8153, -4.9103, -4.8771],\n",
      "        [-0.9083,  8.4903, -5.2364, -4.8789, -4.8834, -4.9715, -4.9398],\n",
      "        [-0.9280,  8.5391, -5.2566, -4.8923, -4.9013, -4.9815, -4.9497],\n",
      "        [-0.9365,  8.5548, -5.2626, -4.8949, -4.9078, -4.9822, -4.9501],\n",
      "        [-0.9410,  8.5609, -5.2647, -4.8954, -4.9108, -4.9813, -4.9489],\n",
      "        [-0.9437,  8.5637, -5.2654, -4.8953, -4.9124, -4.9804, -4.9478],\n",
      "        [-0.9454,  8.5651, -5.2657, -4.8952, -4.9133, -4.9795, -4.9468],\n",
      "        [-0.9466,  8.5659, -5.2658, -4.8951, -4.9138, -4.9789, -4.9461],\n",
      "        [-0.9474,  8.5663, -5.2659, -4.8950, -4.9142, -4.9784, -4.9455],\n",
      "        [-0.9481,  8.5666, -5.2658, -4.8949, -4.9144, -4.9781, -4.9450],\n",
      "        [-0.9486,  8.5668, -5.2658, -4.8948, -4.9145, -4.9778, -4.9447],\n",
      "        [-0.9489,  8.5669, -5.2657, -4.8948, -4.9146, -4.9776, -4.9444],\n",
      "        [-0.9493,  8.5670, -5.2657, -4.8947, -4.9147, -4.9775, -4.9441]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[-0.0387,  1.2655, -0.8701, -0.8711, -0.8409, -0.8842, -0.8129],\n",
      "        [-0.3429,  4.8355, -3.1953, -3.0131, -3.0392, -3.0969, -3.0025],\n",
      "        [-0.6988,  7.5839, -4.8092, -4.4951, -4.5257, -4.6109, -4.5606],\n",
      "        [-0.8690,  8.3505, -5.1996, -4.8536, -4.8567, -4.9527, -4.9186],\n",
      "        [-0.9251,  8.5271, -5.2795, -4.9199, -4.9222, -5.0111, -4.9782],\n",
      "        [-0.9443,  8.5739, -5.2989, -4.9326, -4.9395, -5.0205, -4.9873],\n",
      "        [-0.9526,  8.5890, -5.3047, -4.9351, -4.9458, -5.0210, -4.9875],\n",
      "        [-0.9570,  8.5949, -5.3066, -4.9355, -4.9487, -5.0201, -4.9863],\n",
      "        [-0.9597,  8.5976, -5.3074, -4.9354, -4.9502, -5.0191, -4.9851],\n",
      "        [-0.9614,  8.5989, -5.3077, -4.9352, -4.9511, -5.0182, -4.9841],\n",
      "        [-0.9625,  8.5996, -5.3078, -4.9351, -4.9516, -5.0176, -4.9834],\n",
      "        [-0.9634,  8.6001, -5.3078, -4.9350, -4.9520, -5.0171, -4.9828],\n",
      "        [-0.9640,  8.6003, -5.3078, -4.9349, -4.9522, -5.0168, -4.9823],\n",
      "        [-0.9645,  8.6005, -5.3077, -4.9348, -4.9523, -5.0165, -4.9819],\n",
      "        [-0.9649,  8.6006, -5.3077, -4.9347, -4.9524, -5.0163, -4.9816],\n",
      "        [-0.9652,  8.6006, -5.3076, -4.9347, -4.9524, -5.0162, -4.9814]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[-0.0457,  1.3066, -0.8988, -0.8983, -0.8686, -0.9121, -0.8403],\n",
      "        [-0.3651,  4.9459, -3.2738, -3.0867, -3.1135, -3.1716, -3.0778],\n",
      "        [-0.7205,  7.6554, -4.8682, -4.5510, -4.5789, -4.6659, -4.6161],\n",
      "        [-0.8873,  8.3941, -5.2454, -4.8971, -4.8977, -4.9946, -4.9597],\n",
      "        [-0.9417,  8.5635, -5.3222, -4.9607, -4.9607, -5.0503, -5.0163],\n",
      "        [-0.9604,  8.6084, -5.3409, -4.9728, -4.9774, -5.0591, -5.0247],\n",
      "        [-0.9686,  8.6229, -5.3464, -4.9750, -4.9835, -5.0595, -5.0247],\n",
      "        [-0.9729,  8.6285, -5.3483, -4.9753, -4.9863, -5.0585, -5.0234],\n",
      "        [-0.9755,  8.6311, -5.3490, -4.9752, -4.9878, -5.0575, -5.0222],\n",
      "        [-0.9772,  8.6324, -5.3493, -4.9750, -4.9886, -5.0567, -5.0212],\n",
      "        [-0.9784,  8.6331, -5.3494, -4.9748, -4.9892, -5.0561, -5.0204],\n",
      "        [-0.9792,  8.6335, -5.3494, -4.9747, -4.9895, -5.0556, -5.0198],\n",
      "        [-0.9798,  8.6337, -5.3494, -4.9746, -4.9897, -5.0552, -5.0193],\n",
      "        [-0.9803,  8.6338, -5.3493, -4.9745, -4.9898, -5.0550, -5.0190],\n",
      "        [-0.9807,  8.6339, -5.3493, -4.9745, -4.9899, -5.0548, -5.0187],\n",
      "        [-0.9810,  8.6340, -5.3492, -4.9744, -4.9900, -5.0546, -5.0184]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[-0.0531,  1.3485, -0.9283, -0.9261, -0.8970, -0.9406, -0.8683],\n",
      "        [-0.3873,  5.0554, -3.3519, -3.1599, -3.1875, -3.2459, -3.1529],\n",
      "        [-0.7420,  7.7247, -4.9261, -4.6058, -4.6309, -4.7197, -4.6703],\n",
      "        [-0.9053,  8.4367, -5.2905, -4.9401, -4.9381, -5.0359, -5.0002],\n",
      "        [-0.9581,  8.5994, -5.3645, -5.0011, -4.9989, -5.0891, -5.0540],\n",
      "        [-0.9764,  8.6425, -5.3825, -5.0125, -5.0150, -5.0975, -5.0618],\n",
      "        [-0.9844,  8.6564, -5.3878, -5.0146, -5.0209, -5.0977, -5.0616],\n",
      "        [-0.9887,  8.6619, -5.3897, -5.0148, -5.0236, -5.0967, -5.0602],\n",
      "        [-0.9913,  8.6643, -5.3903, -5.0147, -5.0250, -5.0956, -5.0590],\n",
      "        [-0.9929,  8.6655, -5.3906, -5.0145, -5.0259, -5.0948, -5.0580],\n",
      "        [-0.9941,  8.6662, -5.3907, -5.0143, -5.0264, -5.0942, -5.0572],\n",
      "        [-0.9949,  8.6665, -5.3907, -5.0142, -5.0267, -5.0937, -5.0566],\n",
      "        [-0.9955,  8.6667, -5.3906, -5.0141, -5.0269, -5.0933, -5.0561],\n",
      "        [-0.9960,  8.6669, -5.3906, -5.0140, -5.0271, -5.0931, -5.0557],\n",
      "        [-0.9964,  8.6670, -5.3905, -5.0139, -5.0271, -5.0929, -5.0554],\n",
      "        [-0.9967,  8.6670, -5.3905, -5.0139, -5.0272, -5.0927, -5.0552]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[-0.0607,  1.3913, -0.9584, -0.9547, -0.9260, -0.9699, -0.8970],\n",
      "        [-0.4096,  5.1637, -3.4294, -3.2326, -3.2608, -3.3198, -3.2275],\n",
      "        [-0.7632,  7.7918, -4.9826, -4.6595, -4.6818, -4.7722, -4.7232],\n",
      "        [-0.9231,  8.4784, -5.3349, -4.9825, -4.9780, -5.0766, -5.0401],\n",
      "        [-0.9744,  8.6347, -5.4063, -5.0410, -5.0366, -5.1275, -5.0913],\n",
      "        [-0.9922,  8.6762, -5.4237, -5.0519, -5.0522, -5.1354, -5.0986],\n",
      "        [-1.0001,  8.6896, -5.4288, -5.0539, -5.0579, -5.1355, -5.0982],\n",
      "        [-1.0044,  8.6948, -5.4305, -5.0540, -5.0605, -5.1344, -5.0967],\n",
      "        [-1.0069,  8.6971, -5.4312, -5.0538, -5.0619, -5.1334, -5.0954],\n",
      "        [-1.0086,  8.6983, -5.4314, -5.0536, -5.0628, -5.1325, -5.0944],\n",
      "        [-1.0097,  8.6989, -5.4315, -5.0534, -5.0633, -5.1319, -5.0936],\n",
      "        [-1.0100,  8.6997, -5.4321, -5.0537, -5.0639, -5.1318, -5.0934],\n",
      "        [-1.0101,  8.7003, -5.4326, -5.0540, -5.0643, -5.1318, -5.0934],\n",
      "        [-1.0108,  8.7001, -5.4323, -5.0538, -5.0644, -5.1314, -5.0929],\n",
      "        [-1.0114,  8.6999, -5.4320, -5.0534, -5.0643, -5.1310, -5.0924],\n",
      "        [-1.0118,  8.6999, -5.4317, -5.0532, -5.0643, -5.1307, -5.0920]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[-0.0686,  1.4349, -0.9891, -0.9838, -0.9556, -0.9997, -0.9262],\n",
      "        [-0.4318,  5.2705, -3.5062, -3.3047, -3.3333, -3.3929, -3.3014],\n",
      "        [-0.7841,  7.8567, -5.0379, -4.7120, -4.7314, -4.8235, -4.7748],\n",
      "        [-0.9408,  8.5192, -5.3786, -5.0242, -5.0172, -5.1167, -5.0793],\n",
      "        [-0.9906,  8.6696, -5.4475, -5.0805, -5.0738, -5.1654, -5.1281],\n",
      "        [-1.0080,  8.7094, -5.4643, -5.0909, -5.0889, -5.1728, -5.1348],\n",
      "        [-1.0158,  8.7223, -5.4693, -5.0927, -5.0945, -5.1729, -5.1343],\n",
      "        [-1.0199,  8.7274, -5.4709, -5.0927, -5.0970, -5.1717, -5.1328],\n",
      "        [-1.0225,  8.7296, -5.4715, -5.0925, -5.0984, -5.1707, -5.1314],\n",
      "        [-1.0241,  8.7307, -5.4717, -5.0922, -5.0992, -5.1698, -5.1304],\n",
      "        [-1.0252,  8.7313, -5.4718, -5.0921, -5.0997, -5.1692, -5.1296],\n",
      "        [-1.0260,  8.7316, -5.4718, -5.0919, -5.1000, -5.1687, -5.1290],\n",
      "        [-1.0266,  8.7318, -5.4717, -5.0918, -5.1002, -5.1683, -5.1285],\n",
      "        [-1.0271,  8.7319, -5.4717, -5.0917, -5.1003, -5.1681, -5.1281],\n",
      "        [-1.0274,  8.7320, -5.4716, -5.0916, -5.1004, -5.1679, -5.1278],\n",
      "        [-1.0277,  8.7320, -5.4716, -5.0916, -5.1005, -5.1677, -5.1275]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[-0.0767,  1.4791, -1.0204, -1.0134, -0.9858, -1.0300, -0.9561],\n",
      "        [-0.4540,  5.3758, -3.5820, -3.3759, -3.4049, -3.4651, -3.3744],\n",
      "        [-0.8048,  7.9195, -5.0917, -4.7633, -4.7797, -4.8734, -4.8250],\n",
      "        [-0.9582,  8.5591, -5.4215, -5.0653, -5.0558, -5.1561, -5.1178],\n",
      "        [-1.0067,  8.7038, -5.4881, -5.1194, -5.1105, -5.2028, -5.1644],\n",
      "        [-1.0237,  8.7423, -5.5043, -5.1293, -5.1252, -5.2097, -5.1706],\n",
      "        [-1.0313,  8.7547, -5.5091, -5.1310, -5.1305, -5.2097, -5.1699],\n",
      "        [-1.0354,  8.7595, -5.5107, -5.1310, -5.1330, -5.2085, -5.1683],\n",
      "        [-1.0379,  8.7617, -5.5112, -5.1307, -5.1343, -5.2074, -5.1670],\n",
      "        [-1.0395,  8.7627, -5.5114, -5.1304, -5.1351, -5.2066, -5.1659],\n",
      "        [-1.0406,  8.7633, -5.5115, -5.1302, -5.1356, -5.2059, -5.1651],\n",
      "        [-1.0414,  8.7636, -5.5115, -5.1300, -5.1359, -5.2055, -5.1645],\n",
      "        [-1.0420,  8.7637, -5.5114, -5.1299, -5.1361, -5.2051, -5.1640],\n",
      "        [-1.0425,  8.7638, -5.5114, -5.1298, -5.1362, -5.2048, -5.1636],\n",
      "        [-1.0429,  8.7639, -5.5113, -5.1298, -5.1363, -5.2046, -5.1633],\n",
      "        [-1.0431,  8.7639, -5.5113, -5.1297, -5.1364, -5.2045, -5.1630]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[-0.0851,  1.5240, -1.0522, -1.0435, -1.0164, -1.0607, -0.9863],\n",
      "        [-0.4761,  5.4792, -3.6567, -3.4461, -3.4753, -3.5362, -3.4464],\n",
      "        [-0.8253,  7.9801, -5.1441, -4.8133, -4.8268, -4.9220, -4.8739],\n",
      "        [-0.9755,  8.5981, -5.4636, -5.1056, -5.0937, -5.1946, -5.1556],\n",
      "        [-1.0226,  8.7376, -5.5280, -5.1577, -5.1466, -5.2395, -5.2001],\n",
      "        [-1.0392,  8.7746, -5.5436, -5.1672, -5.1608, -5.2461, -5.2058],\n",
      "        [-1.0467,  8.7866, -5.5483, -5.1687, -5.1660, -5.2459, -5.2050],\n",
      "        [-1.0508,  8.7913, -5.5498, -5.1686, -5.1684, -5.2447, -5.2033],\n",
      "        [-1.0533,  8.7933, -5.5503, -5.1683, -5.1697, -5.2436, -5.2019],\n",
      "        [-1.0549,  8.7943, -5.5505, -5.1680, -5.1705, -5.2428, -5.2009],\n",
      "        [-1.0560,  8.7949, -5.5505, -5.1678, -5.1710, -5.2421, -5.2000],\n",
      "        [-1.0568,  8.7951, -5.5505, -5.1676, -5.1713, -5.2416, -5.1994],\n",
      "        [-1.0574,  8.7953, -5.5504, -5.1675, -5.1714, -5.2413, -5.1989],\n",
      "        [-1.0578,  8.7954, -5.5504, -5.1674, -5.1716, -5.2410, -5.1985],\n",
      "        [-1.0582,  8.7954, -5.5503, -5.1673, -5.1716, -5.2408, -5.1982],\n",
      "        [-1.0585,  8.7954, -5.5503, -5.1672, -5.1717, -5.2406, -5.1979]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[-0.0937,  1.5693, -1.0844, -1.0739, -1.0474, -1.0919, -1.0170],\n",
      "        [-0.4980,  5.5805, -3.7301, -3.5151, -3.5445, -3.6062, -3.5172],\n",
      "        [-0.8454,  8.0387, -5.1951, -4.8620, -4.8725, -4.9693, -4.9212],\n",
      "        [-0.9926,  8.6362, -5.5047, -5.1451, -5.1307, -5.2324, -5.1925],\n",
      "        [-1.0385,  8.7707, -5.5670, -5.1953, -5.1820, -5.2755, -5.2351],\n",
      "        [-1.0547,  8.8065, -5.5822, -5.2044, -5.1958, -5.2817, -5.2403],\n",
      "        [-1.0621,  8.8181, -5.5867, -5.2058, -5.2008, -5.2815, -5.2394],\n",
      "        [-1.0661,  8.8226, -5.5881, -5.2056, -5.2032, -5.2803, -5.2377],\n",
      "        [-1.0686,  8.8245, -5.5886, -5.2053, -5.2045, -5.2792, -5.2363],\n",
      "        [-1.0701,  8.8255, -5.5888, -5.2050, -5.2052, -5.2783, -5.2352],\n",
      "        [-1.0712,  8.8260, -5.5888, -5.2047, -5.2057, -5.2776, -5.2343],\n",
      "        [-1.0720,  8.8262, -5.5888, -5.2046, -5.2060, -5.2771, -5.2337],\n",
      "        [-1.0726,  8.8264, -5.5887, -5.2044, -5.2061, -5.2768, -5.2332],\n",
      "        [-1.0731,  8.8264, -5.5887, -5.2043, -5.2063, -5.2765, -5.2328],\n",
      "        [-1.0734,  8.8265, -5.5886, -5.2042, -5.2063, -5.2763, -5.2325],\n",
      "        [-1.0737,  8.8265, -5.5885, -5.2042, -5.2064, -5.2761, -5.2322]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[-0.1025,  1.6149, -1.1168, -1.1046, -1.0787, -1.1233, -1.0480],\n",
      "        [-0.5198,  5.6796, -3.8020, -3.5828, -3.6122, -3.6747, -3.5867],\n",
      "        [-0.8654,  8.0952, -5.2445, -4.9093, -4.9169, -5.0151, -4.9671],\n",
      "        [-1.0095,  8.6733, -5.5448, -5.1837, -5.1670, -5.2693, -5.2286],\n",
      "        [-1.0542,  8.8033, -5.6052, -5.2322, -5.2167, -5.3107, -5.2693],\n",
      "        [-1.0701,  8.8379, -5.6200, -5.2409, -5.2301, -5.3167, -5.2742],\n",
      "        [-1.0774,  8.8491, -5.6243, -5.2421, -5.2350, -5.3163, -5.2731],\n",
      "        [-1.0813,  8.8534, -5.6257, -5.2420, -5.2373, -5.3151, -5.2714],\n",
      "        [-1.0838,  8.8553, -5.6262, -5.2416, -5.2385, -5.3140, -5.2699],\n",
      "        [-1.0853,  8.8562, -5.6263, -5.2413, -5.2393, -5.3131, -5.2688],\n",
      "        [-1.0864,  8.8566, -5.6263, -5.2410, -5.2397, -5.3125, -5.2680],\n",
      "        [-1.0872,  8.8569, -5.6262, -5.2408, -5.2400, -5.3120, -5.2673],\n",
      "        [-1.0878,  8.8570, -5.6262, -5.2407, -5.2402, -5.3116, -5.2668],\n",
      "        [-1.0883,  8.8570, -5.6261, -5.2405, -5.2403, -5.3113, -5.2664],\n",
      "        [-1.0886,  8.8571, -5.6261, -5.2405, -5.2404, -5.3111, -5.2661],\n",
      "        [-1.0889,  8.8571, -5.6260, -5.2404, -5.2404, -5.3109, -5.2658]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0])\n",
      "out:  tensor([[ 0.0559,  1.5112, -1.1709, -1.1546, -1.1218, -1.1636, -1.0982],\n",
      "        [ 0.2253,  5.1254, -4.0253, -3.7703, -3.7679, -3.8090, -3.7918],\n",
      "        [ 0.5878,  6.9341, -5.6592, -5.2082, -5.1729, -5.2267, -5.3525],\n",
      "        [ 0.8005,  7.2294, -6.0710, -5.5450, -5.4854, -5.5296, -5.7328],\n",
      "        [ 0.8911,  7.2560, -6.1668, -5.6201, -5.5532, -5.5872, -5.8200],\n",
      "        [ 0.9284,  7.2520, -6.1909, -5.6396, -5.5701, -5.5983, -5.8438],\n",
      "        [ 0.9460,  7.2476, -6.1986, -5.6463, -5.5756, -5.6003, -5.8526],\n",
      "        [ 0.9559,  7.2446, -6.2020, -5.6495, -5.5780, -5.6005, -5.8571],\n",
      "        [ 0.9624,  7.2426, -6.2042, -5.6515, -5.5793, -5.6003, -5.8599],\n",
      "        [ 0.9672,  7.2411, -6.2057, -5.6530, -5.5802, -5.6002, -5.8619],\n",
      "        [ 0.9708,  7.2400, -6.2070, -5.6542, -5.5809, -5.6001, -5.8635],\n",
      "        [ 0.9737,  7.2392, -6.2081, -5.6553, -5.5815, -5.6000, -5.8647],\n",
      "        [ 0.9762,  7.2385, -6.2090, -5.6562, -5.5820, -5.6000, -5.8658],\n",
      "        [ 0.9782,  7.2379, -6.2098, -5.6570, -5.5825, -5.6001, -5.8668],\n",
      "        [ 0.9800,  7.2374, -6.2106, -5.6577, -5.5829, -5.6002, -5.8676],\n",
      "        [ 0.9815,  7.2370, -6.2112, -5.6583, -5.5833, -5.6003, -5.8682]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "out:  tensor([[ 0.2495,  1.2545, -1.1304, -1.1160, -1.0724, -1.1106, -1.0545],\n",
      "        [ 1.0444,  4.2921, -4.0638, -3.7990, -3.7570, -3.7591, -3.7870],\n",
      "        [ 2.0099,  5.7347, -5.8865, -5.4141, -5.3346, -5.2834, -5.5137],\n",
      "        [ 2.4332,  5.8749, -6.3005, -5.7950, -5.6786, -5.5864, -5.9146],\n",
      "        [ 2.5545,  5.8600, -6.3734, -5.8746, -5.7389, -5.6334, -5.9875],\n",
      "        [ 2.5901,  5.8471, -6.3881, -5.8948, -5.7498, -5.6414, -6.0025],\n",
      "        [ 2.6039,  5.8413, -6.3935, -5.9032, -5.7528, -5.6440, -6.0078],\n",
      "        [ 2.6114,  5.8390, -6.3972, -5.9087, -5.7546, -5.6458, -6.0111],\n",
      "        [ 2.6163,  5.8384, -6.4004, -5.9131, -5.7560, -5.6478, -6.0137],\n",
      "        [ 2.6200,  5.8390, -6.4033, -5.9170, -5.7574, -5.6499, -6.0161],\n",
      "        [ 2.6227,  5.8401, -6.4056, -5.9203, -5.7586, -5.6520, -6.0182],\n",
      "        [ 2.6246,  5.8410, -6.4072, -5.9228, -5.7595, -5.6536, -6.0197],\n",
      "        [ 2.6258,  5.8416, -6.4082, -5.9243, -5.7600, -5.6545, -6.0207],\n",
      "        [ 2.6266,  5.8419, -6.4087, -5.9253, -5.7603, -5.6550, -6.0212],\n",
      "        [ 2.6271,  5.8420, -6.4090, -5.9258, -5.7604, -5.6553, -6.0215],\n",
      "        [ 2.6274,  5.8420, -6.4091, -5.9261, -5.7604, -5.6554, -6.0216]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "out:  tensor([[ 0.3895,  1.1047, -1.1279, -1.1123, -1.0618, -1.0984, -1.0470],\n",
      "        [ 1.6238,  3.7488, -4.1115, -3.8422, -3.7733, -3.7564, -3.7990],\n",
      "        [ 2.9383,  4.9145, -5.9911, -5.5307, -5.4263, -5.3261, -5.5833],\n",
      "        [ 3.4390,  4.9753, -6.3941, -5.9112, -5.7792, -5.6329, -5.9990],\n",
      "        [ 3.5644,  4.9496, -6.4622, -5.9857, -5.8398, -5.6819, -6.0752],\n",
      "        [ 3.5994,  4.9364, -6.4768, -6.0043, -5.8538, -5.6923, -6.0925],\n",
      "        [ 3.6129,  4.9311, -6.4822, -6.0116, -5.8595, -5.6964, -6.0994],\n",
      "        [ 3.6199,  4.9287, -6.4853, -6.0156, -5.8627, -5.6988, -6.1034],\n",
      "        [ 3.6241,  4.9272, -6.4872, -6.0180, -5.8646, -5.7002, -6.1058],\n",
      "        [ 3.6266,  4.9263, -6.4884, -6.0195, -5.8656, -5.7010, -6.1072],\n",
      "        [ 3.6281,  4.9257, -6.4890, -6.0203, -5.8662, -5.7015, -6.1079],\n",
      "        [ 3.6290,  4.9253, -6.4894, -6.0207, -5.8665, -5.7018, -6.1083],\n",
      "        [ 3.6295,  4.9250, -6.4896, -6.0210, -5.8667, -5.7019, -6.1085],\n",
      "        [ 3.6299,  4.9248, -6.4898, -6.0211, -5.8668, -5.7020, -6.1087],\n",
      "        [ 3.6301,  4.9247, -6.4898, -6.0212, -5.8669, -5.7021, -6.1087],\n",
      "        [ 3.6302,  4.9247, -6.4899, -6.0213, -5.8669, -5.7021, -6.1088]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "out:  tensor([[ 0.5069,  1.0135, -1.1544, -1.1359, -1.0784, -1.1136, -1.0668],\n",
      "        [ 2.1027,  3.3699, -4.2181, -3.9418, -3.8415, -3.8088, -3.8670],\n",
      "        [ 3.6493,  4.2649, -6.0937, -5.6564, -5.5035, -5.3674, -5.6232],\n",
      "        [ 4.1692,  4.2525, -6.4633, -6.0284, -5.8464, -5.6623, -5.9866],\n",
      "        [ 4.2863,  4.2170, -6.5216, -6.1010, -5.9095, -5.7108, -6.0440],\n",
      "        [ 4.3174,  4.2029, -6.5344, -6.1204, -5.9253, -5.7218, -6.0568],\n",
      "        [ 4.3291,  4.1979, -6.5395, -6.1288, -5.9318, -5.7264, -6.0626],\n",
      "        [ 4.3349,  4.1958, -6.5424, -6.1333, -5.9353, -5.7289, -6.0660],\n",
      "        [ 4.3379,  4.1947, -6.5442, -6.1357, -5.9373, -5.7302, -6.0679],\n",
      "        [ 4.3395,  4.1940, -6.5452, -6.1369, -5.9384, -5.7308, -6.0688],\n",
      "        [ 4.3404,  4.1936, -6.5458, -6.1376, -5.9390, -5.7311, -6.0693],\n",
      "        [ 4.3408,  4.1933, -6.5461, -6.1379, -5.9393, -5.7312, -6.0695],\n",
      "        [ 4.3410,  4.1932, -6.5463, -6.1381, -5.9394, -5.7313, -6.0696],\n",
      "        [ 4.3412,  4.1931, -6.5464, -6.1382, -5.9396, -5.7314, -6.0697],\n",
      "        [ 4.3413,  4.1931, -6.5464, -6.1383, -5.9396, -5.7314, -6.0698],\n",
      "        [ 4.3413,  4.1931, -6.5465, -6.1383, -5.9397, -5.7314, -6.0698]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "out:  tensor([[ 0.5955,  0.9635, -1.1905, -1.1686, -1.1046, -1.1389, -1.0959],\n",
      "        [ 2.4427,  3.1279, -4.3301, -4.0470, -3.9119, -3.8687, -3.9407],\n",
      "        [ 4.1071,  3.8227, -6.1997, -5.7767, -5.5496, -5.3921, -5.6497],\n",
      "        [ 4.6235,  3.7625, -6.5774, -6.1558, -5.8805, -5.6705, -5.9836],\n",
      "        [ 4.7350,  3.7213, -6.6489, -6.2335, -5.9444, -5.7161, -6.0390],\n",
      "        [ 4.7639,  3.7067, -6.6688, -6.2554, -5.9618, -5.7268, -6.0529],\n",
      "        [ 4.7745,  3.7017, -6.6775, -6.2649, -5.9693, -5.7313, -6.0595],\n",
      "        [ 4.7794,  3.6997, -6.6822, -6.2698, -5.9732, -5.7336, -6.0632],\n",
      "        [ 4.7819,  3.6987, -6.6849, -6.2723, -5.9753, -5.7348, -6.0651],\n",
      "        [ 4.7831,  3.6982, -6.6863, -6.2736, -5.9764, -5.7354, -6.0660],\n",
      "        [ 4.7837,  3.6979, -6.6871, -6.2743, -5.9770, -5.7358, -6.0665],\n",
      "        [ 4.7840,  3.6978, -6.6876, -6.2746, -5.9774, -5.7359, -6.0668],\n",
      "        [ 4.7842,  3.6977, -6.6878, -6.2748, -5.9776, -5.7360, -6.0669],\n",
      "        [ 4.7843,  3.6976, -6.6880, -6.2750, -5.9777, -5.7361, -6.0670],\n",
      "        [ 4.7843,  3.6976, -6.6881, -6.2751, -5.9778, -5.7362, -6.0670],\n",
      "        [ 4.7844,  3.6976, -6.6882, -6.2751, -5.9778, -5.7362, -6.0671]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "out:  tensor([[ 0.6629,  0.9366, -1.2277, -1.2023, -1.1329, -1.1669, -1.1276],\n",
      "        [ 2.6801,  2.9719, -4.4268, -4.1380, -3.9717, -3.9242, -4.0114],\n",
      "        [ 4.3872,  3.5193, -6.2647, -5.8544, -5.5526, -5.3954, -5.6700],\n",
      "        [ 4.8784,  3.4175, -6.6295, -6.2261, -5.8449, -5.6471, -5.9734],\n",
      "        [ 4.9790,  3.3655, -6.6971, -6.3031, -5.8928, -5.6852, -6.0184],\n",
      "        [ 5.0043,  3.3473, -6.7151, -6.3248, -5.9030, -5.6940, -6.0289],\n",
      "        [ 5.0133,  3.3407, -6.7230, -6.3341, -5.9069, -5.6982, -6.0342],\n",
      "        [ 5.0172,  3.3380, -6.7271, -6.3389, -5.9089, -5.7005, -6.0372],\n",
      "        [ 5.0190,  3.3366, -6.7293, -6.3414, -5.9098, -5.7017, -6.0388],\n",
      "        [ 5.0198,  3.3358, -6.7305, -6.3427, -5.9103, -5.7023, -6.0396],\n",
      "        [ 5.0202,  3.3354, -6.7311, -6.3433, -5.9105, -5.7026, -6.0401],\n",
      "        [ 5.0203,  3.3352, -6.7315, -6.3437, -5.9106, -5.7028, -6.0403],\n",
      "        [ 5.0204,  3.3350, -6.7316, -6.3438, -5.9106, -5.7029, -6.0404],\n",
      "        [ 5.0205,  3.3350, -6.7317, -6.3439, -5.9107, -5.7029, -6.0405],\n",
      "        [ 5.0205,  3.3349, -6.7318, -6.3440, -5.9107, -5.7029, -6.0405],\n",
      "        [ 5.0205,  3.3349, -6.7319, -6.3441, -5.9107, -5.7030, -6.0406]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "out:  tensor([[ 0.7193,  0.9204, -1.2643, -1.2356, -1.1614, -1.1952, -1.1591],\n",
      "        [ 2.8647,  2.8583, -4.5087, -4.2155, -4.0237, -3.9731, -4.0722],\n",
      "        [ 4.5848,  3.2925, -6.2939, -5.8969, -5.5375, -5.3847, -5.6661],\n",
      "        [ 5.0529,  3.1622, -6.6296, -6.2436, -5.7894, -5.6031, -5.9290],\n",
      "        [ 5.1473,  3.1080, -6.6881, -6.3117, -5.8273, -5.6317, -5.9635],\n",
      "        [ 5.1711,  3.0916, -6.7035, -6.3306, -5.8360, -5.6386, -5.9719],\n",
      "        [ 5.1794,  3.0865, -6.7104, -6.3387, -5.8397, -5.6423, -5.9763],\n",
      "        [ 5.1829,  3.0846, -6.7140, -6.3428, -5.8416, -5.6443, -5.9788],\n",
      "        [ 5.1845,  3.0838, -6.7159, -6.3448, -5.8424, -5.6453, -5.9801],\n",
      "        [ 5.1852,  3.0833, -6.7169, -6.3458, -5.8428, -5.6458, -5.9807],\n",
      "        [ 5.1856,  3.0831, -6.7173, -6.3463, -5.8430, -5.6460, -5.9809],\n",
      "        [ 5.1858,  3.0830, -6.7176, -6.3466, -5.8431, -5.6461, -5.9811],\n",
      "        [ 5.1859,  3.0830, -6.7177, -6.3467, -5.8432, -5.6462, -5.9812],\n",
      "        [ 5.1859,  3.0829, -6.7178, -6.3468, -5.8432, -5.6462, -5.9812],\n",
      "        [ 5.1860,  3.0829, -6.7179, -6.3468, -5.8432, -5.6463, -5.9813],\n",
      "        [ 5.1860,  3.0829, -6.7179, -6.3469, -5.8432, -5.6463, -5.9813]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "out:  tensor([[ 0.7695,  0.9102, -1.3000, -1.2682, -1.1901, -1.2235, -1.1904],\n",
      "        [ 3.0190,  2.7734, -4.5815, -4.2863, -4.0760, -4.0204, -4.1314],\n",
      "        [ 4.7384,  3.1302, -6.3099, -5.9337, -5.5386, -5.3780, -5.6722],\n",
      "        [ 5.1846,  2.9942, -6.6183, -6.2667, -5.7730, -5.5755, -5.9150],\n",
      "        [ 5.2725,  2.9440, -6.6700, -6.3343, -5.8107, -5.6019, -5.9493],\n",
      "        [ 5.2944,  2.9293, -6.6837, -6.3539, -5.8201, -5.6088, -5.9586],\n",
      "        [ 5.3020,  2.9248, -6.6899, -6.3623, -5.8239, -5.6123, -5.9634],\n",
      "        [ 5.3052,  2.9231, -6.6932, -6.3664, -5.8257, -5.6142, -5.9660],\n",
      "        [ 5.3066,  2.9224, -6.6949, -6.3685, -5.8265, -5.6152, -5.9672],\n",
      "        [ 5.3072,  2.9221, -6.6957, -6.3695, -5.8269, -5.6156, -5.9678],\n",
      "        [ 5.3075,  2.9220, -6.6961, -6.3700, -5.8271, -5.6159, -5.9681],\n",
      "        [ 5.3077,  2.9219, -6.6964, -6.3702, -5.8272, -5.6160, -5.9683],\n",
      "        [ 5.3078,  2.9219, -6.6965, -6.3704, -5.8273, -5.6161, -5.9684],\n",
      "        [ 5.3078,  2.9218, -6.6966, -6.3705, -5.8273, -5.6161, -5.9684],\n",
      "        [ 5.3078,  2.9218, -6.6966, -6.3705, -5.8273, -5.6162, -5.9685],\n",
      "        [ 5.3079,  2.9219, -6.6967, -6.3706, -5.8274, -5.6163, -5.9686]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "out:  tensor([[ 0.9500,  1.0632, -1.5608, -1.5102, -1.4215, -1.4548, -1.4283],\n",
      "        [ 3.4358,  2.8485, -4.9922, -4.6789, -4.4271, -4.3555, -4.5046],\n",
      "        [ 4.9745,  2.9745, -6.3974, -6.0519, -5.6068, -5.4325, -5.7530],\n",
      "        [ 5.3164,  2.8443, -6.6156, -6.3022, -5.7738, -5.5641, -5.9210],\n",
      "        [ 5.3836,  2.8027, -6.6518, -6.3526, -5.8012, -5.5812, -5.9454],\n",
      "        [ 5.4014,  2.7902, -6.6622, -6.3682, -5.8084, -5.5858, -5.9530],\n",
      "        [ 5.4079,  2.7861, -6.6671, -6.3754, -5.8115, -5.5882, -5.9571],\n",
      "        [ 5.4106,  2.7845, -6.6698, -6.3791, -5.8130, -5.5895, -5.9593],\n",
      "        [ 5.4118,  2.7838, -6.6711, -6.3809, -5.8138, -5.5901, -5.9604],\n",
      "        [ 5.4124,  2.7835, -6.6718, -6.3818, -5.8141, -5.5904, -5.9610],\n",
      "        [ 5.4127,  2.7834, -6.6721, -6.3823, -5.8143, -5.5906, -5.9613],\n",
      "        [ 5.4129,  2.7833, -6.6723, -6.3826, -5.8144, -5.5907, -5.9615],\n",
      "        [ 5.4130,  2.7833, -6.6724, -6.3828, -5.8145, -5.5907, -5.9616],\n",
      "        [ 5.4130,  2.7833, -6.6725, -6.3828, -5.8145, -5.5907, -5.9616],\n",
      "        [ 5.4131,  2.7833, -6.6726, -6.3829, -5.8145, -5.5908, -5.9616],\n",
      "        [ 5.4131,  2.7833, -6.6726, -6.3830, -5.8146, -5.5908, -5.9617]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "out:  tensor([[ 0.8581,  0.8962, -1.3655, -1.3278, -1.2435, -1.2767, -1.2488],\n",
      "        [ 3.2728,  2.6389, -4.6979, -4.3990, -4.1654, -4.1021, -4.2306],\n",
      "        [ 4.9780,  2.8776, -6.3099, -5.9723, -5.5396, -5.3629, -5.6734],\n",
      "        [ 5.3921,  2.7315, -6.5694, -6.2695, -5.7441, -5.5269, -5.8813],\n",
      "        [ 5.4734,  2.6805, -6.6088, -6.3242, -5.7748, -5.5455, -5.9077],\n",
      "        [ 5.4941,  2.6651, -6.6190, -6.3398, -5.7822, -5.5496, -5.9146],\n",
      "        [ 5.5013,  2.6602, -6.6240, -6.3473, -5.7855, -5.5520, -5.9186],\n",
      "        [ 5.5043,  2.6584, -6.6267, -6.3513, -5.7873, -5.5535, -5.9209],\n",
      "        [ 5.5056,  2.6577, -6.6282, -6.3533, -5.7882, -5.5542, -5.9221],\n",
      "        [ 5.5062,  2.6574, -6.6290, -6.3544, -5.7887, -5.5546, -5.9227],\n",
      "        [ 5.5066,  2.6573, -6.6296, -6.3552, -5.7890, -5.5549, -5.9232],\n",
      "        [ 5.5068,  2.6572, -6.6298, -6.3555, -5.7891, -5.5550, -5.9234],\n",
      "        [ 5.5068,  2.6571, -6.6298, -6.3556, -5.7891, -5.5550, -5.9234],\n",
      "        [ 5.5069,  2.6570, -6.6298, -6.3556, -5.7891, -5.5549, -5.9234],\n",
      "        [ 5.5069,  2.6570, -6.6299, -6.3556, -5.7891, -5.5549, -5.9234],\n",
      "        [ 5.5069,  2.6570, -6.6299, -6.3557, -5.7891, -5.5549, -5.9234]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "out:  tensor([[ 0.9001,  0.8929, -1.3997, -1.3587, -1.2718, -1.3050, -1.2794],\n",
      "        [ 3.3845,  2.5839, -4.7534, -4.4498, -4.2088, -4.1426, -4.2777],\n",
      "        [ 5.0761,  2.7727, -6.3044, -5.9750, -5.5369, -5.3539, -5.6675],\n",
      "        [ 5.4752,  2.6223, -6.5368, -6.2464, -5.7230, -5.4981, -5.8530],\n",
      "        [ 5.5531,  2.5721, -6.5688, -6.2934, -5.7481, -5.5112, -5.8741],\n",
      "        [ 5.5728,  2.5575, -6.5765, -6.3071, -5.7538, -5.5139, -5.8797],\n",
      "        [ 5.5797,  2.5530, -6.5803, -6.3138, -5.7566, -5.5159, -5.8831],\n",
      "        [ 5.5825,  2.5514, -6.5825, -6.3175, -5.7582, -5.5172, -5.8852],\n",
      "        [ 5.5839,  2.5509, -6.5839, -6.3196, -5.7592, -5.5181, -5.8865],\n",
      "        [ 5.5845,  2.5507, -6.5846, -6.3206, -5.7596, -5.5185, -5.8871],\n",
      "        [ 5.5848,  2.5505, -6.5850, -6.3212, -5.7599, -5.5187, -5.8874],\n",
      "        [ 5.5849,  2.5504, -6.5852, -6.3214, -5.7600, -5.5188, -5.8876],\n",
      "        [ 5.5850,  2.5504, -6.5853, -6.3216, -5.7600, -5.5189, -5.8877],\n",
      "        [ 5.5851,  2.5503, -6.5853, -6.3217, -5.7601, -5.5189, -5.8877],\n",
      "        [ 5.5851,  2.5503, -6.5854, -6.3218, -5.7601, -5.5189, -5.8878],\n",
      "        [ 5.5852,  2.5503, -6.5854, -6.3218, -5.7601, -5.5189, -5.8878]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "out:  tensor([[ 1.0269,  0.9770, -1.5669, -1.5129, -1.4188, -1.4521, -1.4316],\n",
      "        [ 3.6483,  2.6005, -4.9894, -4.6724, -4.4095, -4.3338, -4.4903],\n",
      "        [ 5.2194,  2.6693, -6.3343, -6.0147, -5.5607, -5.3696, -5.6931],\n",
      "        [ 5.5628,  2.5292, -6.5145, -6.2297, -5.7059, -5.4753, -5.8322],\n",
      "        [ 5.6299,  2.4861, -6.5391, -6.2656, -5.7253, -5.4842, -5.8471],\n",
      "        [ 5.6472,  2.4741, -6.5460, -6.2773, -5.7308, -5.4869, -5.8522],\n",
      "        [ 5.6533,  2.4706, -6.5495, -6.2834, -5.7338, -5.4890, -5.8554],\n",
      "        [ 5.6557,  2.4694, -6.5515, -6.2866, -5.7354, -5.4902, -5.8572],\n",
      "        [ 5.6568,  2.4689, -6.5525, -6.2882, -5.7362, -5.4909, -5.8581],\n",
      "        [ 5.6573,  2.4687, -6.5529, -6.2889, -5.7365, -5.4912, -5.8586],\n",
      "        [ 5.6575,  2.4686, -6.5532, -6.2893, -5.7367, -5.4913, -5.8588],\n",
      "        [ 5.6576,  2.4685, -6.5533, -6.2895, -5.7368, -5.4914, -5.8589],\n",
      "        [ 5.6577,  2.4685, -6.5534, -6.2896, -5.7368, -5.4914, -5.8589],\n",
      "        [ 5.6577,  2.4684, -6.5534, -6.2897, -5.7368, -5.4914, -5.8589],\n",
      "        [ 5.6578,  2.4684, -6.5534, -6.2897, -5.7368, -5.4914, -5.8589],\n",
      "        [ 5.6578,  2.4684, -6.5535, -6.2897, -5.7368, -5.4914, -5.8589]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "out:  tensor([[ 0.9782,  0.8877, -1.4642, -1.4164, -1.3249, -1.3585, -1.3369],\n",
      "        [ 3.5797,  2.4886, -4.8521, -4.5344, -4.2826, -4.2145, -4.3584],\n",
      "        [ 5.2433,  2.6054, -6.2965, -5.9651, -5.5245, -5.3369, -5.6500],\n",
      "        [ 5.6195,  2.4589, -6.4901, -6.1913, -5.6802, -5.4521, -5.7991],\n",
      "        [ 5.6917,  2.4127, -6.5154, -6.2267, -5.6987, -5.4609, -5.8133],\n",
      "        [ 5.7100,  2.3999, -6.5220, -6.2379, -5.7038, -5.4635, -5.8180],\n",
      "        [ 5.7164,  2.3961, -6.5252, -6.2438, -5.7068, -5.4656, -5.8212],\n",
      "        [ 5.7190,  2.3948, -6.5270, -6.2470, -5.7085, -5.4669, -5.8230],\n",
      "        [ 5.7202,  2.3943, -6.5279, -6.2486, -5.7093, -5.4676, -5.8239],\n",
      "        [ 5.7207,  2.3940, -6.5283, -6.2493, -5.7096, -5.4679, -5.8243],\n",
      "        [ 5.7209,  2.3939, -6.5285, -6.2497, -5.7097, -5.4680, -5.8245],\n",
      "        [ 5.7211,  2.3938, -6.5285, -6.2499, -5.7098, -5.4680, -5.8246],\n",
      "        [ 5.7211,  2.3937, -6.5286, -6.2500, -5.7098, -5.4680, -5.8246],\n",
      "        [ 5.7212,  2.3937, -6.5286, -6.2500, -5.7098, -5.4681, -5.8246],\n",
      "        [ 5.7212,  2.3937, -6.5286, -6.2500, -5.7098, -5.4681, -5.8246],\n",
      "        [ 5.7212,  2.3936, -6.5286, -6.2501, -5.7098, -5.4681, -5.8246]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "out:  tensor([[ 1.0161,  0.8865, -1.4972, -1.4459, -1.3520, -1.3861, -1.3663],\n",
      "        [ 3.6681,  2.4451, -4.9008, -4.5739, -4.3169, -4.2504, -4.3966],\n",
      "        [ 5.3140,  2.5301, -6.2970, -5.9550, -5.5133, -5.3315, -5.6381],\n",
      "        [ 5.6771,  2.3826, -6.4757, -6.1606, -5.6506, -5.4345, -5.7704],\n",
      "        [ 5.7459,  2.3352, -6.4983, -6.1916, -5.6635, -5.4408, -5.7819],\n",
      "        [ 5.7635,  2.3220, -6.5038, -6.2015, -5.6669, -5.4428, -5.7859],\n",
      "        [ 5.7698,  2.3181, -6.5065, -6.2069, -5.6692, -5.4447, -5.7886],\n",
      "        [ 5.7724,  2.3168, -6.5080, -6.2097, -5.6705, -5.4460, -5.7901],\n",
      "        [ 5.7735,  2.3163, -6.5087, -6.2111, -5.6711, -5.4466, -5.7908],\n",
      "        [ 5.7740,  2.3161, -6.5091, -6.2118, -5.6714, -5.4469, -5.7911],\n",
      "        [ 5.7742,  2.3160, -6.5093, -6.2121, -5.6716, -5.4470, -5.7913],\n",
      "        [ 5.7744,  2.3159, -6.5093, -6.2123, -5.6716, -5.4471, -5.7913],\n",
      "        [ 5.7744,  2.3158, -6.5094, -6.2123, -5.6716, -5.4471, -5.7914],\n",
      "        [ 5.7745,  2.3158, -6.5094, -6.2124, -5.6716, -5.4471, -5.7914],\n",
      "        [ 5.7745,  2.3158, -6.5094, -6.2124, -5.6716, -5.4471, -5.7914],\n",
      "        [ 5.7745,  2.3158, -6.5094, -6.2124, -5.6716, -5.4471, -5.7914]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "out:  tensor([[ 1.0531,  0.8855, -1.5300, -1.4750, -1.3789, -1.4134, -1.3955],\n",
      "        [ 3.7499,  2.4024, -4.9477, -4.6114, -4.3490, -4.2847, -4.4329],\n",
      "        [ 5.3750,  2.4538, -6.2992, -5.9452, -5.4990, -5.3254, -5.6257],\n",
      "        [ 5.7235,  2.2989, -6.4653, -6.1331, -5.6182, -5.4155, -5.7428],\n",
      "        [ 5.7884,  2.2485, -6.4860, -6.1602, -5.6274, -5.4191, -5.7515],\n",
      "        [ 5.8052,  2.2347, -6.4912, -6.1691, -5.6301, -5.4208, -5.7545],\n",
      "        [ 5.8112,  2.2308, -6.4938, -6.1739, -5.6320, -5.4228, -5.7566],\n",
      "        [ 5.8137,  2.2296, -6.4953, -6.1765, -5.6332, -5.4241, -5.7577],\n",
      "        [ 5.8148,  2.2291, -6.4960, -6.1778, -5.6338, -5.4248, -5.7583],\n",
      "        [ 5.8153,  2.2289, -6.4963, -6.1784, -5.6340, -5.4251, -5.7585],\n",
      "        [ 5.8155,  2.2288, -6.4965, -6.1787, -5.6341, -5.4253, -5.7586],\n",
      "        [ 5.8156,  2.2287, -6.4966, -6.1788, -5.6342, -5.4253, -5.7587],\n",
      "        [ 5.8157,  2.2287, -6.4966, -6.1788, -5.6342, -5.4253, -5.7587],\n",
      "        [ 5.8157,  2.2287, -6.4966, -6.1789, -5.6342, -5.4254, -5.7587],\n",
      "        [ 5.8157,  2.2286, -6.4966, -6.1789, -5.6342, -5.4254, -5.7587],\n",
      "        [ 5.8157,  2.2286, -6.4966, -6.1789, -5.6342, -5.4253, -5.7587]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "out:  tensor([[ 1.0892,  0.8847, -1.5624, -1.5038, -1.4057, -1.4406, -1.4244],\n",
      "        [ 3.8261,  2.3606, -4.9932, -4.6474, -4.3809, -4.3176, -4.4680],\n",
      "        [ 5.4276,  2.3754, -6.3037, -5.9353, -5.4879, -5.3181, -5.6129],\n",
      "        [ 5.7615,  2.2108, -6.4603, -6.1062, -5.5960, -5.3951, -5.7152],\n",
      "        [ 5.8229,  2.1588, -6.4807, -6.1303, -5.6058, -5.3969, -5.7219],\n",
      "        [ 5.8388,  2.1448, -6.4860, -6.1385, -5.6088, -5.3984, -5.7243],\n",
      "        [ 5.8446,  2.1407, -6.4886, -6.1429, -5.6107, -5.4002, -5.7259],\n",
      "        [ 5.8469,  2.1394, -6.4900, -6.1452, -5.6117, -5.4014, -5.7267],\n",
      "        [ 5.8479,  2.1388, -6.4906, -6.1463, -5.6122, -5.4020, -5.7271],\n",
      "        [ 5.8484,  2.1386, -6.4909, -6.1468, -5.6124, -5.4022, -5.7273],\n",
      "        [ 5.8486,  2.1385, -6.4911, -6.1471, -5.6125, -5.4024, -5.7273],\n",
      "        [ 5.8487,  2.1384, -6.4912, -6.1472, -5.6125, -5.4024, -5.7274],\n",
      "        [ 5.8488,  2.1383, -6.4912, -6.1472, -5.6125, -5.4025, -5.7274],\n",
      "        [ 5.8488,  2.1383, -6.4912, -6.1473, -5.6125, -5.4025, -5.7274],\n",
      "        [ 5.8488,  2.1383, -6.4912, -6.1473, -5.6125, -5.4025, -5.7274],\n",
      "        [ 5.8488,  2.1382, -6.4912, -6.1473, -5.6125, -5.4025, -5.7274]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1])\n",
      "out:  tensor([[ 1.3033,  1.0874, -1.8960, -1.8132, -1.7010, -1.7343, -1.7278],\n",
      "        [ 4.0814,  2.5661, -5.3968, -5.0508, -4.7515, -4.6661, -4.8501],\n",
      "        [ 5.4055,  2.5431, -6.4599, -6.1256, -5.6628, -5.4747, -5.7829],\n",
      "        [ 5.6593,  2.4358, -6.5826, -6.2680, -5.7557, -5.5435, -5.8665],\n",
      "        [ 5.7075,  2.4038, -6.5991, -6.2916, -5.7655, -5.5491, -5.8750],\n",
      "        [ 5.7202,  2.3954, -6.6039, -6.3004, -5.7689, -5.5516, -5.8790],\n",
      "        [ 5.7246,  2.3932, -6.6064, -6.3052, -5.7710, -5.5537, -5.8817],\n",
      "        [ 5.7263,  2.3927, -6.6077, -6.3076, -5.7722, -5.5549, -5.8832],\n",
      "        [ 5.7270,  2.3925, -6.6084, -6.3088, -5.7727, -5.5554, -5.8839],\n",
      "        [ 5.7273,  2.3924, -6.6087, -6.3093, -5.7729, -5.5557, -5.8842],\n",
      "        [ 5.7274,  2.3924, -6.6088, -6.3096, -5.7730, -5.5558, -5.8844],\n",
      "        [ 5.7275,  2.3923, -6.6089, -6.3097, -5.7731, -5.5559, -5.8844],\n",
      "        [ 5.7276,  2.3923, -6.6089, -6.3098, -5.7731, -5.5560, -5.8845],\n",
      "        [ 5.7276,  2.3923, -6.6090, -6.3098, -5.7731, -5.5560, -5.8845],\n",
      "        [ 5.7276,  2.3923, -6.6090, -6.3099, -5.7731, -5.5560, -5.8845],\n",
      "        [ 5.7276,  2.3923, -6.6090, -6.3099, -5.7731, -5.5560, -5.8845]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[ 0.9484,  1.0224, -1.5713, -1.5161, -1.4253, -1.4594, -1.4378],\n",
      "        [ 3.2911,  2.9429, -5.0987, -4.7581, -4.5360, -4.4671, -4.5947],\n",
      "        [ 4.7217,  3.2450, -6.5661, -6.1819, -5.8114, -5.6327, -5.9060],\n",
      "        [ 5.0605,  3.1310, -6.7771, -6.4165, -5.9800, -5.7645, -6.0690],\n",
      "        [ 5.1306,  3.0846, -6.8042, -6.4540, -5.9990, -5.7735, -6.0830],\n",
      "        [ 5.1491,  3.0699, -6.8118, -6.4665, -6.0032, -5.7754, -6.0877],\n",
      "        [ 5.1556,  3.0651, -6.8166, -6.4738, -6.0058, -5.7775, -6.0920],\n",
      "        [ 5.1582,  3.0634, -6.8194, -6.4779, -6.0072, -5.7789, -6.0948],\n",
      "        [ 5.1594,  3.0626, -6.8210, -6.4800, -6.0080, -5.7797, -6.0963],\n",
      "        [ 5.1600,  3.0623, -6.8218, -6.4811, -6.0084, -5.7801, -6.0971],\n",
      "        [ 5.1603,  3.0621, -6.8223, -6.4817, -6.0086, -5.7804, -6.0976],\n",
      "        [ 5.1604,  3.0621, -6.8225, -6.4821, -6.0088, -5.7805, -6.0979],\n",
      "        [ 5.1605,  3.0621, -6.8227, -6.4823, -6.0089, -5.7807, -6.0981],\n",
      "        [ 5.1605,  3.0621, -6.8229, -6.4825, -6.0090, -5.7808, -6.0983],\n",
      "        [ 5.1605,  3.0622, -6.8230, -6.4827, -6.0092, -5.7809, -6.0985],\n",
      "        [ 5.1605,  3.0623, -6.8232, -6.4829, -6.0093, -5.7811, -6.0988]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[ 0.8375,  1.1137, -1.5630, -1.5087, -1.4251, -1.4604, -1.4337],\n",
      "        [ 2.8938,  3.3172, -5.1118, -4.7520, -4.5749, -4.5180, -4.6263],\n",
      "        [ 4.1949,  3.8507, -6.6711, -6.2203, -5.9537, -5.7931, -6.0439],\n",
      "        [ 4.5218,  3.8009, -6.9323, -6.4862, -6.1765, -5.9767, -6.2606],\n",
      "        [ 4.5924,  3.7660, -6.9745, -6.5338, -6.2107, -5.9983, -6.2888],\n",
      "        [ 4.6119,  3.7544, -6.9863, -6.5481, -6.2194, -6.0039, -6.2976],\n",
      "        [ 4.6189,  3.7528, -6.9942, -6.5574, -6.2255, -6.0098, -6.3060],\n",
      "        [ 4.6216,  3.7547, -7.0004, -6.5648, -6.2310, -6.0155, -6.3140],\n",
      "        [ 4.6226,  3.7564, -7.0041, -6.5693, -6.2346, -6.0191, -6.3190],\n",
      "        [ 4.6231,  3.7572, -7.0062, -6.5718, -6.2366, -6.0209, -6.3216],\n",
      "        [ 4.6234,  3.7578, -7.0077, -6.5734, -6.2381, -6.0219, -6.3233],\n",
      "        [ 4.6236,  3.7582, -7.0090, -6.5747, -6.2394, -6.0227, -6.3247],\n",
      "        [ 4.6238,  3.7587, -7.0103, -6.5758, -6.2405, -6.0233, -6.3259],\n",
      "        [ 4.6240,  3.7590, -7.0114, -6.5767, -6.2415, -6.0238, -6.3270],\n",
      "        [ 4.6241,  3.7592, -7.0123, -6.5773, -6.2423, -6.0242, -6.3278],\n",
      "        [ 4.6242,  3.7594, -7.0129, -6.5778, -6.2429, -6.0245, -6.3285]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[ 0.7633,  1.1956, -1.5747, -1.5203, -1.4418, -1.4782, -1.4483],\n",
      "        [ 2.6138,  3.6262, -5.1443, -4.7743, -4.6309, -4.5851, -4.6833],\n",
      "        [ 3.7885,  4.3368, -6.7160, -6.2370, -6.0512, -5.9106, -6.1512],\n",
      "        [ 4.0883,  4.3495, -6.9849, -6.5074, -6.3028, -6.1254, -6.3953],\n",
      "        [ 4.1513,  4.3332, -7.0336, -6.5611, -6.3506, -6.1605, -6.4339],\n",
      "        [ 4.1681,  4.3286, -7.0490, -6.5791, -6.3657, -6.1714, -6.4458],\n",
      "        [ 4.1741,  4.3293, -7.0570, -6.5885, -6.3735, -6.1775, -6.4525],\n",
      "        [ 4.1768,  4.3304, -7.0617, -6.5937, -6.3781, -6.1808, -6.4567],\n",
      "        [ 4.1782,  4.3312, -7.0646, -6.5966, -6.3809, -6.1827, -6.4594],\n",
      "        [ 4.1790,  4.3317, -7.0663, -6.5983, -6.3826, -6.1838, -6.4611],\n",
      "        [ 4.1794,  4.3320, -7.0674, -6.5993, -6.3836, -6.1844, -6.4621],\n",
      "        [ 4.1796,  4.3322, -7.0680, -6.5999, -6.3842, -6.1848, -6.4628],\n",
      "        [ 4.1798,  4.3323, -7.0685, -6.6003, -6.3846, -6.1851, -6.4633],\n",
      "        [ 4.1799,  4.3324, -7.0690, -6.6006, -6.3850, -6.1853, -6.4637],\n",
      "        [ 4.1800,  4.3325, -7.0694, -6.6010, -6.3854, -6.1855, -6.4641],\n",
      "        [ 4.1801,  4.3327, -7.0700, -6.6014, -6.3859, -6.1857, -6.4646]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[ 0.8435,  1.4980, -1.8881, -1.8111, -1.7305, -1.7677, -1.7397],\n",
      "        [ 2.6316,  4.0668, -5.5307, -5.1342, -4.9972, -4.9535, -5.0735],\n",
      "        [ 3.5940,  4.6580, -6.7996, -6.3161, -6.1580, -6.0364, -6.2948],\n",
      "        [ 3.8168,  4.6825, -6.9939, -6.5156, -6.3490, -6.2031, -6.4870],\n",
      "        [ 3.8622,  4.6779, -7.0274, -6.5557, -6.3868, -6.2332, -6.5208],\n",
      "        [ 3.8743,  4.6782, -7.0385, -6.5699, -6.3992, -6.2427, -6.5320],\n",
      "        [ 3.8790,  4.6803, -7.0448, -6.5775, -6.4059, -6.2472, -6.5384],\n",
      "        [ 3.8812,  4.6822, -7.0490, -6.5821, -6.4101, -6.2498, -6.5425],\n",
      "        [ 3.8824,  4.6835, -7.0518, -6.5849, -6.4128, -6.2516, -6.5450],\n",
      "        [ 3.8832,  4.6847, -7.0543, -6.5872, -6.4148, -6.2535, -6.5468],\n",
      "        [ 3.8839,  4.6860, -7.0571, -6.5896, -6.4168, -6.2558, -6.5485],\n",
      "        [ 3.8845,  4.6873, -7.0597, -6.5918, -6.4186, -6.2581, -6.5500],\n",
      "        [ 3.8849,  4.6881, -7.0615, -6.5933, -6.4198, -6.2596, -6.5510],\n",
      "        [ 3.8851,  4.6885, -7.0626, -6.5942, -6.4205, -6.2605, -6.5515],\n",
      "        [ 3.8852,  4.6887, -7.0631, -6.5946, -6.4209, -6.2609, -6.5517],\n",
      "        [ 3.8852,  4.6888, -7.0633, -6.5948, -6.4210, -6.2610, -6.5518]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[ 0.6895,  1.3121, -1.6201, -1.5642, -1.4907, -1.5281, -1.4949],\n",
      "        [ 2.3225,  3.9865, -5.2174, -4.8423, -4.7226, -4.6938, -4.7879],\n",
      "        [ 3.3401,  4.8371, -6.7390, -6.2490, -6.1089, -6.0112, -6.2647],\n",
      "        [ 3.6046,  4.8954, -6.9844, -6.4989, -6.3448, -6.2265, -6.5195],\n",
      "        [ 3.6604,  4.8942, -7.0245, -6.5474, -6.3879, -6.2652, -6.5627],\n",
      "        [ 3.6749,  4.8964, -7.0378, -6.5642, -6.4015, -6.2780, -6.5763],\n",
      "        [ 3.6802,  4.9007, -7.0462, -6.5737, -6.4092, -6.2851, -6.5840],\n",
      "        [ 3.6825,  4.9034, -7.0510, -6.5787, -6.4134, -6.2884, -6.5883],\n",
      "        [ 3.6836,  4.9045, -7.0532, -6.5810, -6.4153, -6.2897, -6.5902],\n",
      "        [ 3.6840,  4.9050, -7.0542, -6.5820, -6.4162, -6.2903, -6.5911],\n",
      "        [ 3.6843,  4.9053, -7.0547, -6.5825, -6.4167, -6.2906, -6.5915],\n",
      "        [ 3.6844,  4.9054, -7.0549, -6.5828, -6.4169, -6.2908, -6.5917],\n",
      "        [ 3.6844,  4.9054, -7.0551, -6.5829, -6.4171, -6.2909, -6.5919],\n",
      "        [ 3.6845,  4.9055, -7.0552, -6.5830, -6.4171, -6.2909, -6.5920],\n",
      "        [ 3.6845,  4.9055, -7.0552, -6.5831, -6.4172, -6.2910, -6.5920],\n",
      "        [ 3.6845,  4.9055, -7.0552, -6.5831, -6.4172, -6.2910, -6.5920]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[ 0.6700,  1.3606, -1.6502, -1.5929, -1.5209, -1.5586, -1.5242],\n",
      "        [ 2.2393,  4.1088, -5.2663, -4.8877, -4.7727, -4.7490, -4.8433],\n",
      "        [ 3.2042,  4.9833, -6.7664, -6.2673, -6.1349, -6.0482, -6.3089],\n",
      "        [ 3.4556,  5.0489, -7.0082, -6.5088, -6.3614, -6.2573, -6.5623],\n",
      "        [ 3.5089,  5.0496, -7.0477, -6.5554, -6.4009, -6.2945, -6.6048],\n",
      "        [ 3.5224,  5.0521, -7.0602, -6.5708, -6.4129, -6.3063, -6.6173],\n",
      "        [ 3.5269,  5.0556, -7.0672, -6.5787, -6.4189, -6.3117, -6.6237],\n",
      "        [ 3.5287,  5.0575, -7.0708, -6.5825, -6.4219, -6.3140, -6.6267],\n",
      "        [ 3.5295,  5.0584, -7.0725, -6.5843, -6.4233, -6.3149, -6.6281],\n",
      "        [ 3.5299,  5.0588, -7.0734, -6.5850, -6.4239, -6.3153, -6.6287],\n",
      "        [ 3.5301,  5.0590, -7.0738, -6.5855, -6.4242, -6.3155, -6.6290],\n",
      "        [ 3.5302,  5.0590, -7.0740, -6.5857, -6.4244, -6.3156, -6.6292],\n",
      "        [ 3.5302,  5.0591, -7.0742, -6.5858, -6.4245, -6.3157, -6.6293],\n",
      "        [ 3.5302,  5.0591, -7.0742, -6.5859, -6.4246, -6.3157, -6.6294],\n",
      "        [ 3.5303,  5.0591, -7.0743, -6.5859, -6.4246, -6.3157, -6.6294],\n",
      "        [ 3.5303,  5.0591, -7.0743, -6.5859, -6.4246, -6.3158, -6.6295]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[ 0.6553,  1.4054, -1.6814, -1.6224, -1.5518, -1.5898, -1.5543],\n",
      "        [ 2.1739,  4.2128, -5.3162, -4.9336, -4.8225, -4.8027, -4.8977],\n",
      "        [ 3.0936,  5.1010, -6.7966, -6.2872, -6.1614, -6.0821, -6.3502],\n",
      "        [ 3.3317,  5.1725, -7.0363, -6.5210, -6.3801, -6.2845, -6.6028],\n",
      "        [ 3.3821,  5.1749, -7.0759, -6.5655, -6.4166, -6.3198, -6.6454],\n",
      "        [ 3.3942,  5.1777, -7.0879, -6.5796, -6.4270, -6.3303, -6.6574],\n",
      "        [ 3.3979,  5.1808, -7.0941, -6.5863, -6.4319, -6.3346, -6.6630],\n",
      "        [ 3.3993,  5.1825, -7.0972, -6.5893, -6.4342, -6.3362, -6.6655],\n",
      "        [ 3.3999,  5.1832, -7.0987, -6.5907, -6.4352, -6.3368, -6.6666],\n",
      "        [ 3.4002,  5.1835, -7.0994, -6.5913, -6.4356, -6.3371, -6.6671],\n",
      "        [ 3.4003,  5.1837, -7.0997, -6.5916, -6.4359, -6.3372, -6.6674],\n",
      "        [ 3.4003,  5.1838, -7.0999, -6.5918, -6.4360, -6.3373, -6.6675],\n",
      "        [ 3.4004,  5.1838, -7.1001, -6.5919, -6.4361, -6.3373, -6.6676],\n",
      "        [ 3.4004,  5.1838, -7.1001, -6.5920, -6.4362, -6.3374, -6.6677],\n",
      "        [ 3.4004,  5.1838, -7.1002, -6.5920, -6.4362, -6.3374, -6.6677],\n",
      "        [ 3.4004,  5.1839, -7.1002, -6.5921, -6.4362, -6.3374, -6.6677]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[ 0.6438,  1.4477, -1.7132, -1.6524, -1.5831, -1.6213, -1.5848],\n",
      "        [ 2.1208,  4.3041, -5.3661, -4.9796, -4.8720, -4.8551, -4.9508],\n",
      "        [ 3.0014,  5.1991, -6.8269, -6.3090, -6.1894, -6.1148, -6.3887],\n",
      "        [ 3.2271,  5.2755, -7.0650, -6.5364, -6.4027, -6.3116, -6.6405],\n",
      "        [ 3.2742,  5.2800, -7.1051, -6.5795, -6.4377, -6.3457, -6.6838],\n",
      "        [ 3.2850,  5.2833, -7.1169, -6.5926, -6.4472, -6.3553, -6.6957],\n",
      "        [ 3.2878,  5.2863, -7.1225, -6.5984, -6.4514, -6.3589, -6.7009],\n",
      "        [ 3.2888,  5.2878, -7.1252, -6.6009, -6.4533, -6.3601, -6.7031],\n",
      "        [ 3.2892,  5.2885, -7.1265, -6.6020, -6.4541, -6.3605, -6.7041],\n",
      "        [ 3.2893,  5.2888, -7.1271, -6.6025, -6.4544, -6.3607, -6.7047],\n",
      "        [ 3.2892,  5.2890, -7.1273, -6.6028, -6.4547, -6.3608, -6.7050],\n",
      "        [ 3.2892,  5.2892, -7.1275, -6.6030, -6.4548, -6.3608, -6.7052],\n",
      "        [ 3.2891,  5.2893, -7.1276, -6.6031, -6.4549, -6.3609, -6.7054],\n",
      "        [ 3.2889,  5.2894, -7.1276, -6.6032, -6.4551, -6.3610, -6.7056],\n",
      "        [ 3.2888,  5.2895, -7.1277, -6.6033, -6.4552, -6.3610, -6.7058],\n",
      "        [ 3.2887,  5.2895, -7.1277, -6.6034, -6.4552, -6.3611, -6.7059]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[ 0.6346,  1.4880, -1.7454, -1.6828, -1.6148, -1.6530, -1.6155],\n",
      "        [ 2.0767,  4.3859, -5.4152, -5.0255, -4.9212, -4.9065, -5.0026],\n",
      "        [ 2.9234,  5.2827, -6.8561, -6.3319, -6.2187, -6.1469, -6.4240],\n",
      "        [ 3.1381,  5.3626, -7.0923, -6.5542, -6.4283, -6.3390, -6.6741],\n",
      "        [ 3.1820,  5.3693, -7.1331, -6.5966, -6.4632, -6.3725, -6.7185],\n",
      "        [ 3.1911,  5.3734, -7.1448, -6.6092, -6.4727, -6.3818, -6.7308],\n",
      "        [ 3.1931,  5.3766, -7.1500, -6.6145, -6.4769, -6.3852, -6.7361],\n",
      "        [ 3.1934,  5.3783, -7.1523, -6.6168, -6.4787, -6.3863, -6.7386],\n",
      "        [ 3.1934,  5.3792, -7.1534, -6.6178, -6.4796, -6.3867, -6.7398],\n",
      "        [ 3.1934,  5.3795, -7.1539, -6.6183, -6.4800, -6.3868, -6.7403],\n",
      "        [ 3.1934,  5.3797, -7.1542, -6.6186, -6.4802, -6.3869, -6.7406],\n",
      "        [ 3.1934,  5.3798, -7.1544, -6.6187, -6.4803, -6.3869, -6.7408],\n",
      "        [ 3.1934,  5.3799, -7.1546, -6.6189, -6.4804, -6.3869, -6.7409],\n",
      "        [ 3.1934,  5.3799, -7.1548, -6.6190, -6.4805, -6.3870, -6.7410],\n",
      "        [ 3.1934,  5.3800, -7.1550, -6.6191, -6.4807, -6.3870, -6.7412],\n",
      "        [ 3.1935,  5.3800, -7.1552, -6.6192, -6.4809, -6.3871, -6.7413]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[ 0.6269,  1.5268, -1.7776, -1.7133, -1.6464, -1.6847, -1.6462],\n",
      "        [ 2.0390,  4.4601, -5.4630, -5.0704, -4.9691, -4.9564, -5.0524],\n",
      "        [ 2.8565,  5.3547, -6.8837, -6.3550, -6.2475, -6.1776, -6.4559],\n",
      "        [ 3.0622,  5.4367, -7.1172, -6.5723, -6.4540, -6.3650, -6.7027],\n",
      "        [ 3.1034,  5.4450, -7.1582, -6.6138, -6.4888, -6.3977, -6.7472],\n",
      "        [ 3.1113,  5.4497, -7.1698, -6.6258, -6.4983, -6.4067, -6.7595],\n",
      "        [ 3.1127,  5.4530, -7.1747, -6.6308, -6.5024, -6.4099, -6.7648],\n",
      "        [ 3.1129,  5.4548, -7.1769, -6.6330, -6.5043, -6.4111, -6.7673],\n",
      "        [ 3.1128,  5.4556, -7.1779, -6.6340, -6.5052, -6.4115, -6.7685],\n",
      "        [ 3.1128,  5.4560, -7.1786, -6.6345, -6.5057, -6.4116, -6.7691],\n",
      "        [ 3.1128,  5.4562, -7.1791, -6.6349, -6.5061, -6.4117, -6.7695],\n",
      "        [ 3.1129,  5.4564, -7.1797, -6.6353, -6.5065, -6.4119, -6.7699],\n",
      "        [ 3.1129,  5.4565, -7.1804, -6.6357, -6.5071, -6.4120, -6.7703],\n",
      "        [ 3.1129,  5.4567, -7.1813, -6.6362, -6.5078, -6.4123, -6.7709],\n",
      "        [ 3.1130,  5.4569, -7.1825, -6.6368, -6.5086, -6.4126, -6.7716],\n",
      "        [ 3.1131,  5.4571, -7.1838, -6.6375, -6.5096, -6.4129, -6.7724]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2])\n",
      "out:  tensor([[ 0.6179,  1.5329, -1.5842, -1.7367, -1.6726, -1.7098, -1.6699],\n",
      "        [ 1.9880,  4.4007, -4.7707, -5.0538, -4.9753, -4.9568, -5.0409],\n",
      "        [ 2.7730,  5.2347, -5.9318, -6.2731, -6.2133, -6.1385, -6.3836],\n",
      "        [ 2.9717,  5.2994, -6.1105, -6.4682, -6.4061, -6.3142, -6.6096],\n",
      "        [ 3.0130,  5.3025, -6.1398, -6.5038, -6.4369, -6.3439, -6.6477],\n",
      "        [ 3.0216,  5.3056, -6.1476, -6.5141, -6.4448, -6.3518, -6.6579],\n",
      "        [ 3.0234,  5.3084, -6.1507, -6.5181, -6.4479, -6.3544, -6.6621],\n",
      "        [ 3.0237,  5.3099, -6.1518, -6.5196, -6.4491, -6.3551, -6.6639],\n",
      "        [ 3.0237,  5.3106, -6.1522, -6.5202, -6.4496, -6.3552, -6.6647],\n",
      "        [ 3.0237,  5.3109, -6.1524, -6.5205, -6.4498, -6.3552, -6.6650],\n",
      "        [ 3.0237,  5.3111, -6.1525, -6.5206, -6.4499, -6.3552, -6.6652],\n",
      "        [ 3.0237,  5.3112, -6.1526, -6.5207, -6.4499, -6.3552, -6.6653],\n",
      "        [ 3.0237,  5.3113, -6.1527, -6.5208, -6.4500, -6.3553, -6.6655],\n",
      "        [ 3.0237,  5.3113, -6.1527, -6.5208, -6.4500, -6.3552, -6.6655],\n",
      "        [ 3.0237,  5.3114, -6.1527, -6.5208, -6.4501, -6.3553, -6.6655],\n",
      "        [ 3.0237,  5.3114, -6.1527, -6.5208, -6.4501, -6.3553, -6.6656]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "out:  tensor([[ 0.5584,  1.3222, -1.2218, -1.5984, -1.5349, -1.5723, -1.5322],\n",
      "        [ 1.8272,  3.8722, -3.7431, -4.7180, -4.6628, -4.6405, -4.6946],\n",
      "        [ 2.6369,  4.7262, -4.7532, -5.9962, -5.9963, -5.9415, -6.0987],\n",
      "        [ 2.8582,  4.7976, -4.9126, -6.2060, -6.2202, -6.1690, -6.3463],\n",
      "        [ 2.9074,  4.7993, -4.9388, -6.2434, -6.2584, -6.2107, -6.3891],\n",
      "        [ 2.9189,  4.8026, -4.9453, -6.2550, -6.2701, -6.2244, -6.4031],\n",
      "        [ 2.9211,  4.8095, -4.9481, -6.2610, -6.2766, -6.2332, -6.4126],\n",
      "        [ 2.9207,  4.8169, -4.9499, -6.2645, -6.2810, -6.2399, -6.4202],\n",
      "        [ 2.9200,  4.8226, -4.9509, -6.2666, -6.2838, -6.2444, -6.4256],\n",
      "        [ 2.9196,  4.8256, -4.9515, -6.2676, -6.2852, -6.2466, -6.4284],\n",
      "        [ 2.9194,  4.8269, -4.9518, -6.2681, -6.2858, -6.2476, -6.4296],\n",
      "        [ 2.9192,  4.8275, -4.9519, -6.2684, -6.2861, -6.2481, -6.4302],\n",
      "        [ 2.9192,  4.8279, -4.9520, -6.2685, -6.2863, -6.2484, -6.4305],\n",
      "        [ 2.9191,  4.8281, -4.9520, -6.2686, -6.2864, -6.2485, -6.4307],\n",
      "        [ 2.9191,  4.8282, -4.9521, -6.2686, -6.2865, -6.2486, -6.4308],\n",
      "        [ 2.9191,  4.8283, -4.9521, -6.2687, -6.2865, -6.2487, -6.4309]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "out:  tensor([[ 0.4787,  1.0845, -0.9138, -1.4020, -1.3386, -1.3764, -1.3367],\n",
      "        [ 1.6078,  3.3307, -2.8986, -4.2979, -4.2404, -4.2193, -4.2530],\n",
      "        [ 2.4265,  4.2623, -3.8055, -5.7081, -5.7090, -5.6566, -5.7625],\n",
      "        [ 2.6872,  4.3584, -3.9560, -5.9807, -5.9905, -5.9498, -6.0581],\n",
      "        [ 2.7519,  4.3600, -3.9778, -6.0350, -6.0416, -6.0069, -6.1088],\n",
      "        [ 2.7704,  4.3600, -3.9827, -6.0517, -6.0566, -6.0242, -6.1236],\n",
      "        [ 2.7771,  4.3634, -3.9854, -6.0605, -6.0651, -6.0342, -6.1333],\n",
      "        [ 2.7800,  4.3687, -3.9875, -6.0666, -6.0719, -6.0423, -6.1417],\n",
      "        [ 2.7813,  4.3745, -3.9891, -6.0708, -6.0778, -6.0491, -6.1490],\n",
      "        [ 2.7816,  4.3792, -3.9902, -6.0735, -6.0822, -6.0540, -6.1544],\n",
      "        [ 2.7816,  4.3823, -3.9910, -6.0750, -6.0848, -6.0570, -6.1578],\n",
      "        [ 2.7814,  4.3840, -3.9914, -6.0758, -6.0861, -6.0587, -6.1597],\n",
      "        [ 2.7813,  4.3850, -3.9917, -6.0762, -6.0869, -6.0596, -6.1607],\n",
      "        [ 2.7812,  4.3856, -3.9919, -6.0765, -6.0873, -6.0602, -6.1614],\n",
      "        [ 2.7812,  4.3859, -3.9920, -6.0766, -6.0875, -6.0605, -6.1616],\n",
      "        [ 2.7811,  4.3860, -3.9921, -6.0767, -6.0876, -6.0606, -6.1617]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "out:  tensor([[ 0.4248,  0.9328, -0.7141, -1.2835, -1.2188, -1.2568, -1.2185],\n",
      "        [ 1.4013,  2.8655, -2.2140, -3.9218, -3.8463, -3.8255, -3.8546],\n",
      "        [ 2.1490,  3.7924, -2.9076, -5.3616, -5.3247, -5.2541, -5.3519],\n",
      "        [ 2.4197,  3.9121, -3.0113, -5.6829, -5.6431, -5.5815, -5.6800],\n",
      "        [ 2.4932,  3.9143, -3.0194, -5.7522, -5.7020, -5.6482, -5.7372],\n",
      "        [ 2.5156,  3.9127, -3.0206, -5.7752, -5.7201, -5.6691, -5.7538],\n",
      "        [ 2.5248,  3.9144, -3.0233, -5.7882, -5.7312, -5.6814, -5.7649],\n",
      "        [ 2.5300,  3.9175, -3.0264, -5.7976, -5.7400, -5.6910, -5.7742],\n",
      "        [ 2.5333,  3.9206, -3.0294, -5.8048, -5.7469, -5.6986, -5.7817],\n",
      "        [ 2.5354,  3.9233, -3.0317, -5.8102, -5.7522, -5.7043, -5.7874],\n",
      "        [ 2.5368,  3.9253, -3.0334, -5.8141, -5.7559, -5.7084, -5.7916],\n",
      "        [ 2.5376,  3.9268, -3.0346, -5.8168, -5.7585, -5.7113, -5.7945],\n",
      "        [ 2.5381,  3.9278, -3.0354, -5.8186, -5.7602, -5.7131, -5.7964],\n",
      "        [ 2.5383,  3.9285, -3.0359, -5.8197, -5.7613, -5.7143, -5.7977],\n",
      "        [ 2.5384,  3.9289, -3.0362, -5.8205, -5.7619, -5.7151, -5.7984],\n",
      "        [ 2.5385,  3.9292, -3.0363, -5.8209, -5.7623, -5.7155, -5.7989]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "out:  tensor([[ 0.3788,  0.8109, -0.5579, -1.1853, -1.1191, -1.1575, -1.1210],\n",
      "        [ 1.1981,  2.4279, -1.6168, -3.5317, -3.4319, -3.4182, -3.4463],\n",
      "        [ 1.8014,  3.2700, -1.9990, -4.8877, -4.7832, -4.7009, -4.8034],\n",
      "        [ 2.0167,  3.3975, -1.9635, -5.2012, -5.0672, -4.9791, -5.0941],\n",
      "        [ 2.0717,  3.3901, -1.9085, -5.2542, -5.0926, -5.0107, -5.1193],\n",
      "        [ 2.0885,  3.3792, -1.8828, -5.2661, -5.0902, -5.0122, -5.1166],\n",
      "        [ 2.0968,  3.3758, -1.8737, -5.2732, -5.0909, -5.0150, -5.1177],\n",
      "        [ 2.1027,  3.3768, -1.8715, -5.2804, -5.0952, -5.0203, -5.1224],\n",
      "        [ 2.1074,  3.3797, -1.8719, -5.2875, -5.1009, -5.0267, -5.1286],\n",
      "        [ 2.1114,  3.3830, -1.8733, -5.2940, -5.1069, -5.0330, -5.1348],\n",
      "        [ 2.1148,  3.3863, -1.8748, -5.2998, -5.1124, -5.0387, -5.1406],\n",
      "        [ 2.1176,  3.3893, -1.8763, -5.3047, -5.1173, -5.0437, -5.1457],\n",
      "        [ 2.1199,  3.3919, -1.8777, -5.3089, -5.1215, -5.0480, -5.1501],\n",
      "        [ 2.1218,  3.3942, -1.8789, -5.3124, -5.1251, -5.0517, -5.1538],\n",
      "        [ 2.1234,  3.3960, -1.8799, -5.3154, -5.1281, -5.0547, -5.1569],\n",
      "        [ 2.1247,  3.3976, -1.8807, -5.3178, -5.1305, -5.0572, -5.1594]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n",
      "out:  tensor([[ 0.3384,  0.7054, -0.4633, -0.9608, -1.0291, -1.0683, -1.0341],\n",
      "        [ 0.9988,  1.9709, -1.2328, -2.6562, -2.9627, -2.9699, -2.9974],\n",
      "        [ 1.4219,  2.5843, -1.4172, -3.5543, -4.0318, -3.9945, -4.0883],\n",
      "        [ 1.5380,  2.6334, -1.2994, -3.6999, -4.1998, -4.1703, -4.2759],\n",
      "        [ 1.5507,  2.5757, -1.2076, -3.6755, -4.1568, -4.1447, -4.2430],\n",
      "        [ 1.5511,  2.5362, -1.1661, -3.6511, -4.1191, -4.1171, -4.2097],\n",
      "        [ 1.5516,  2.5176, -1.1490, -3.6399, -4.1015, -4.1041, -4.1940],\n",
      "        [ 1.5522,  2.5092, -1.1413, -3.6351, -4.0938, -4.0984, -4.1872],\n",
      "        [ 1.5526,  2.5052, -1.1374, -3.6328, -4.0901, -4.0957, -4.1840],\n",
      "        [ 1.5528,  2.5031, -1.1353, -3.6316, -4.0882, -4.0942, -4.1822],\n",
      "        [ 1.5530,  2.5019, -1.1340, -3.6309, -4.0871, -4.0934, -4.1813],\n",
      "        [ 1.5531,  2.5012, -1.1333, -3.6305, -4.0865, -4.0930, -4.1807],\n",
      "        [ 1.5532,  2.5008, -1.1329, -3.6303, -4.0862, -4.0927, -4.1805],\n",
      "        [ 1.5533,  2.5006, -1.1326, -3.6303, -4.0861, -4.0927, -4.1804],\n",
      "        [ 1.5534,  2.5005, -1.1324, -3.6303, -4.0861, -4.0927, -4.1804],\n",
      "        [ 1.5535,  2.5005, -1.1323, -3.6304, -4.0861, -4.0928, -4.1805]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n",
      "out:  tensor([[ 0.2983,  0.6031, -0.4180, -0.7478, -0.9317, -0.9711, -0.9393],\n",
      "        [ 0.8262,  1.5538, -1.0332, -1.8830, -2.4995, -2.5293, -2.5576],\n",
      "        [ 1.1102,  1.9054, -1.1097, -2.3477, -3.2458, -3.2697, -3.3603],\n",
      "        [ 1.1554,  1.8158, -0.9395, -2.2944, -3.2438, -3.2939, -3.3993],\n",
      "        [ 1.1444,  1.6853, -0.8254, -2.1788, -3.1137, -3.1828, -3.2878],\n",
      "        [ 1.1382,  1.6088, -0.7735, -2.1110, -3.0312, -3.1098, -3.2132],\n",
      "        [ 1.1363,  1.5705, -0.7506, -2.0767, -2.9887, -3.0721, -3.1741],\n",
      "        [ 1.1360,  1.5557, -0.7416, -2.0630, -2.9725, -3.0584, -3.1593],\n",
      "        [ 1.1347,  1.5441, -0.7354, -2.0510, -2.9577, -3.0451, -3.1454],\n",
      "        [ 1.1336,  1.5372, -0.7330, -2.0430, -2.9481, -3.0362, -3.1361],\n",
      "        [ 1.1326,  1.5337, -0.7326, -2.0383, -2.9427, -3.0310, -3.1306],\n",
      "        [ 1.1317,  1.5322, -0.7330, -2.0356, -2.9398, -3.0280, -3.1275],\n",
      "        [ 1.1310,  1.5318, -0.7337, -2.0341, -2.9383, -3.0264, -3.1258],\n",
      "        [ 1.1303,  1.5318, -0.7344, -2.0332, -2.9376, -3.0255, -3.1249],\n",
      "        [ 1.1298,  1.5320, -0.7350, -2.0328, -2.9373, -3.0250, -3.1244],\n",
      "        [ 1.1293,  1.5323, -0.7356, -2.0325, -2.9371, -3.0247, -3.1241]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n",
      "out:  tensor([[ 0.2684,  0.5405, -0.3865, -0.6077, -0.8814, -0.9191, -0.8902],\n",
      "        [ 0.6958,  1.2830, -0.8839, -1.3597, -2.2039, -2.2414, -2.2790],\n",
      "        [ 0.8716,  1.4238, -0.8673, -1.4767, -2.6648, -2.7165, -2.8212],\n",
      "        [ 0.8631,  1.2198, -0.6641, -1.2463, -2.4894, -2.5688, -2.6962],\n",
      "        [ 0.8279,  1.0493, -0.5498, -1.0504, -2.2767, -2.3652, -2.5003],\n",
      "        [ 0.7941,  0.9639, -0.5076, -0.9340, -2.1461, -2.2339, -2.3715],\n",
      "        [ 0.7553,  0.9295, -0.4980, -0.8633, -2.0668, -2.1511, -2.2856],\n",
      "        [ 0.7103,  0.9216, -0.5029, -0.8181, -2.0133, -2.0939, -2.2198],\n",
      "        [ 0.6613,  0.9287, -0.5154, -0.7904, -1.9747, -2.0521, -2.1651],\n",
      "        [ 0.6124,  0.9455, -0.5326, -0.7777, -1.9482, -2.0233, -2.1211],\n",
      "        [ 0.5693,  0.9704, -0.5538, -0.7802, -1.9360, -2.0093, -2.0920],\n",
      "        [ 0.5376,  1.0029, -0.5786, -0.7982, -1.9418, -2.0139, -2.0839],\n",
      "        [ 0.5217,  1.0420, -0.6062, -0.8306, -1.9683, -2.0398, -2.1008],\n",
      "        [ 0.5227,  1.0848, -0.6346, -0.8735, -2.0138, -2.0851, -2.1417],\n",
      "        [ 0.5376,  1.1255, -0.6601, -0.9195, -2.0702, -2.1419, -2.1983],\n",
      "        [ 0.5605,  1.1574, -0.6786, -0.9599, -2.1257, -2.1977, -2.2574]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n",
      "out:  tensor([[ 0.2536,  0.5146, -0.3756, -0.5178, -0.8895, -0.9268, -0.9017],\n",
      "        [ 0.6188,  1.1410, -0.7966, -0.9902, -2.1096, -2.1524, -2.2135],\n",
      "        [ 0.7091,  1.1037, -0.6679, -0.8143, -2.3192, -2.3946, -2.5363],\n",
      "        [ 0.6533,  0.8041, -0.4189, -0.4331, -1.9668, -2.0740, -2.2479],\n",
      "        [ 0.6005,  0.6177, -0.3064, -0.1871, -1.7055, -1.8133, -2.0073],\n",
      "        [ 0.5590,  0.5235, -0.2663, -0.0453, -1.5591, -1.6612, -1.8679],\n",
      "        [ 0.5244,  0.4698, -0.2509,  0.0448, -1.4667, -1.5640, -1.7772],\n",
      "        [ 0.4960,  0.4341, -0.2430,  0.1066, -1.4013, -1.4946, -1.7110],\n",
      "        [ 0.4730,  0.4086, -0.2381,  0.1504, -1.3527, -1.4421, -1.6606],\n",
      "        [ 0.4540,  0.3887, -0.2342,  0.1833, -1.3137, -1.3994, -1.6194],\n",
      "        [ 0.4379,  0.3725, -0.2306,  0.2089, -1.2811, -1.3632, -1.5845],\n",
      "        [ 0.4243,  0.3589, -0.2270,  0.2293, -1.2532, -1.3319, -1.5542],\n",
      "        [ 0.4127,  0.3474, -0.2236,  0.2459, -1.2289, -1.3047, -1.5277],\n",
      "        [ 0.4028,  0.3376, -0.2203,  0.2593, -1.2077, -1.2808, -1.5045],\n",
      "        [ 0.3939,  0.3291, -0.2168,  0.2706, -1.1884, -1.2595, -1.4834],\n",
      "        [ 0.3866,  0.3225, -0.2137,  0.2793, -1.1726, -1.2420, -1.4660]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n",
      "out:  tensor([[ 0.2261,  0.4757, -0.3569, -0.4294, -0.8624, -0.8999, -0.8739],\n",
      "        [ 0.5036,  1.0036, -0.7331, -0.6643, -1.9435, -1.9972, -2.0529],\n",
      "        [ 0.4965,  0.9264, -0.6274, -0.2603, -2.0252, -2.1197, -2.2520],\n",
      "        [ 0.3393,  0.6035, -0.4235,  0.3006, -1.5524, -1.6641, -1.8365],\n",
      "        [ 0.1914,  0.3415, -0.3036,  0.6864, -1.1266, -1.2124, -1.4178],\n",
      "        [ 0.0809,  0.1487, -0.2013,  0.9091, -0.7879, -0.8408, -1.0564],\n",
      "        [-0.0154, -0.0036, -0.0921,  1.0085, -0.4860, -0.5028, -0.7075],\n",
      "        [-0.1078, -0.1391,  0.0281,  1.0190, -0.1874, -0.1669, -0.3453],\n",
      "        [-0.1848, -0.2704,  0.1590,  0.9838,  0.1127,  0.1671,  0.0248],\n",
      "        [-0.2348, -0.4063,  0.2929,  0.9446,  0.3970,  0.4782,  0.3770],\n",
      "        [-0.2577, -0.5502,  0.4213,  0.9190,  0.6548,  0.7512,  0.6925],\n",
      "        [-0.2638, -0.7025,  0.5414,  0.9069,  0.8920,  0.9914,  0.9723],\n",
      "        [-0.2589, -0.8548,  0.6441,  0.8995,  1.1046,  1.1970,  1.2092],\n",
      "        [-0.2378, -0.9838,  0.7068,  0.8732,  1.2620,  1.3408,  1.3730],\n",
      "        [-0.1872, -1.0476,  0.6961,  0.7931,  1.3049,  1.3693,  1.4075],\n",
      "        [-0.1004, -1.0045,  0.5919,  0.6430,  1.1817,  1.2343,  1.2632]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n",
      "out:  tensor([[ 0.2322,  0.4850, -0.3685, -0.4317, -0.8493, -0.8859, -0.8611],\n",
      "        [ 0.5213,  1.0090, -0.7606, -0.6251, -1.9335, -1.9878, -2.0504],\n",
      "        [ 0.5285,  0.8976, -0.6513, -0.1466, -2.0528, -2.1511, -2.3002],\n",
      "        [ 0.4030,  0.5679, -0.4616,  0.4409, -1.6702, -1.7877, -1.9829],\n",
      "        [ 0.3009,  0.3430, -0.3934,  0.8272, -1.3893, -1.4890, -1.7206],\n",
      "        [ 0.2417,  0.2091, -0.3713,  1.0573, -1.2297, -1.3097, -1.5641],\n",
      "        [ 0.2116,  0.1323, -0.3604,  1.1906, -1.1418, -1.2077, -1.4724],\n",
      "        [ 0.1964,  0.0889, -0.3533,  1.2664, -1.0938, -1.1498, -1.4185],\n",
      "        [ 0.1881,  0.0640, -0.3485,  1.3094, -1.0675, -1.1163, -1.3867],\n",
      "        [ 0.1831,  0.0494, -0.3454,  1.3340, -1.0525, -1.0964, -1.3674],\n",
      "        [ 0.1799,  0.0406, -0.3434,  1.3484, -1.0435, -1.0840, -1.3552],\n",
      "        [ 0.1776,  0.0350, -0.3421,  1.3570, -1.0376, -1.0758, -1.3472],\n",
      "        [ 0.1760,  0.0314, -0.3413,  1.3624, -1.0335, -1.0701, -1.3416],\n",
      "        [ 0.1747,  0.0288, -0.3408,  1.3658, -1.0305, -1.0660, -1.3375],\n",
      "        [ 0.1737,  0.0271, -0.3404,  1.3681, -1.0282, -1.0628, -1.3344],\n",
      "        [ 0.1729,  0.0258, -0.3401,  1.3696, -1.0264, -1.0604, -1.3320]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n",
      "out:  tensor([[ 0.2192,  0.4630, -0.3617, -0.3729, -0.8431, -0.8803, -0.8565],\n",
      "        [ 0.4703,  0.9258, -0.7355, -0.4132, -1.8776, -1.9382, -2.0020],\n",
      "        [ 0.4340,  0.7781, -0.6490,  0.2275, -1.9618, -2.0683, -2.2196],\n",
      "        [ 0.2803,  0.4340, -0.5130,  0.9307, -1.5921, -1.7033, -1.9125],\n",
      "        [ 0.1778,  0.1967, -0.4745,  1.3830, -1.3399, -1.4185, -1.6730],\n",
      "        [ 0.1285,  0.0698, -0.4616,  1.6366, -1.2201, -1.2680, -1.5448],\n",
      "        [ 0.1044,  0.0058, -0.4525,  1.7725, -1.1683, -1.1914, -1.4782],\n",
      "        [ 0.0912, -0.0274, -0.4455,  1.8452, -1.1451, -1.1497, -1.4412],\n",
      "        [ 0.0832, -0.0458, -0.4405,  1.8849, -1.1334, -1.1249, -1.4189],\n",
      "        [ 0.0778, -0.0568, -0.4371,  1.9072, -1.1262, -1.1088, -1.4042],\n",
      "        [ 0.0739, -0.0639, -0.4347,  1.9202, -1.1209, -1.0975, -1.3939],\n",
      "        [ 0.0710, -0.0688, -0.4331,  1.9280, -1.1166, -1.0890, -1.3861],\n",
      "        [ 0.0688, -0.0724, -0.4318,  1.9328, -1.1128, -1.0824, -1.3800],\n",
      "        [ 0.0671, -0.0750, -0.4308,  1.9358, -1.1095, -1.0771, -1.3752],\n",
      "        [ 0.0658, -0.0771, -0.4300,  1.9377, -1.1067, -1.0729, -1.3713],\n",
      "        [ 0.0648, -0.0787, -0.4293,  1.9390, -1.1043, -1.0694, -1.3681]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n",
      "out:  tensor([[ 2.0955e-01,  4.4616e-01, -3.5826e-01, -3.2377e-01, -8.4078e-01,\n",
      "         -8.7849e-01, -8.5668e-01],\n",
      "        [ 4.3201e-01,  8.5973e-01, -7.2173e-01, -2.3524e-01, -1.8442e+00,\n",
      "         -1.9089e+00, -1.9771e+00],\n",
      "        [ 3.6279e-01,  6.7947e-01, -6.5920e-01,  5.4420e-01, -1.9137e+00,\n",
      "         -2.0223e+00, -2.1813e+00],\n",
      "        [ 1.9772e-01,  3.2639e-01, -5.7205e-01,  1.3371e+00, -1.5848e+00,\n",
      "         -1.6804e+00, -1.9097e+00],\n",
      "        [ 1.0285e-01,  1.0165e-01, -5.6058e-01,  1.8329e+00, -1.3970e+00,\n",
      "         -1.4441e+00, -1.7228e+00],\n",
      "        [ 5.9137e-02, -4.7557e-03, -5.5897e-01,  2.1043e+00, -1.3314e+00,\n",
      "         -1.3351e+00, -1.6378e+00],\n",
      "        [ 3.7504e-02, -5.4290e-02, -5.5562e-01,  2.2479e+00, -1.3119e+00,\n",
      "         -1.2823e+00, -1.5967e+00],\n",
      "        [ 2.5612e-02, -7.9132e-02, -5.5169e-01,  2.3244e+00, -1.3058e+00,\n",
      "         -1.2531e+00, -1.5734e+00],\n",
      "        [ 1.8360e-02, -9.2844e-02, -5.4839e-01,  2.3664e+00, -1.3031e+00,\n",
      "         -1.2347e+00, -1.5583e+00],\n",
      "        [ 1.3538e-02, -1.0120e-01, -5.4590e-01,  2.3904e+00, -1.3009e+00,\n",
      "         -1.2220e+00, -1.5475e+00],\n",
      "        [ 1.0114e-02, -1.0677e-01, -5.4403e-01,  2.4045e+00, -1.2984e+00,\n",
      "         -1.2125e+00, -1.5393e+00],\n",
      "        [ 7.4341e-03, -1.1084e-01, -5.4248e-01,  2.4132e+00, -1.2952e+00,\n",
      "         -1.2046e+00, -1.5323e+00],\n",
      "        [ 5.3958e-03, -1.1395e-01, -5.4122e-01,  2.4188e+00, -1.2922e+00,\n",
      "         -1.1982e+00, -1.5266e+00],\n",
      "        [ 3.8348e-03, -1.1636e-01, -5.4017e-01,  2.4223e+00, -1.2893e+00,\n",
      "         -1.1930e+00, -1.5220e+00],\n",
      "        [ 2.6325e-03, -1.1825e-01, -5.3930e-01,  2.4246e+00, -1.2867e+00,\n",
      "         -1.1887e+00, -1.5182e+00],\n",
      "        [ 1.7061e-03, -1.1974e-01, -5.3858e-01,  2.4260e+00, -1.2844e+00,\n",
      "         -1.1852e+00, -1.5152e+00]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n",
      "out:  tensor([[ 2.0096e-01,  4.3148e-01, -3.5597e-01, -2.7901e-01, -8.3906e-01,\n",
      "         -8.7727e-01, -8.5762e-01],\n",
      "        [ 3.9776e-01,  8.0154e-01, -7.1165e-01, -7.4115e-02, -1.8150e+00,\n",
      "         -1.8832e+00, -1.9562e+00],\n",
      "        [ 3.0025e-01,  5.9171e-01, -6.7215e-01,  8.2880e-01, -1.8737e+00,\n",
      "         -1.9819e+00, -2.1500e+00],\n",
      "        [ 1.3127e-01,  2.3663e-01, -6.2701e-01,  1.6937e+00, -1.5935e+00,\n",
      "         -1.6702e+00, -1.9189e+00],\n",
      "        [ 4.2600e-02,  3.3643e-02, -6.3698e-01,  2.2237e+00, -1.4725e+00,\n",
      "         -1.4853e+00, -1.7864e+00],\n",
      "        [ 1.0192e-03, -5.4797e-02, -6.4498e-01,  2.5135e+00, -1.4497e+00,\n",
      "         -1.4086e+00, -1.7361e+00],\n",
      "        [-1.9651e-02, -9.4945e-02, -6.4627e-01,  2.6666e+00, -1.4509e+00,\n",
      "         -1.3715e+00, -1.7124e+00],\n",
      "        [-3.0793e-02, -1.1531e-01, -6.4481e-01,  2.7482e+00, -1.4548e+00,\n",
      "         -1.3497e+00, -1.6978e+00],\n",
      "        [-3.7373e-02, -1.2688e-01, -6.4292e-01,  2.7931e+00, -1.4570e+00,\n",
      "         -1.3351e+00, -1.6873e+00],\n",
      "        [-4.1614e-02, -1.3417e-01, -6.4127e-01,  2.8189e+00, -1.4572e+00,\n",
      "         -1.3243e+00, -1.6791e+00],\n",
      "        [-4.4556e-02, -1.3918e-01, -6.3992e-01,  2.8343e+00, -1.4561e+00,\n",
      "         -1.3159e+00, -1.6723e+00],\n",
      "        [-4.6644e-02, -1.4275e-01, -6.3887e-01,  2.8435e+00, -1.4542e+00,\n",
      "         -1.3092e+00, -1.6669e+00],\n",
      "        [-4.7934e-02, -1.4522e-01, -6.3819e-01,  2.8491e+00, -1.4526e+00,\n",
      "         -1.3044e+00, -1.6631e+00],\n",
      "        [-4.9070e-02, -1.4723e-01, -6.3750e-01,  2.8529e+00, -1.4505e+00,\n",
      "         -1.3002e+00, -1.6597e+00],\n",
      "        [-5.0069e-02, -1.4902e-01, -6.3673e-01,  2.8557e+00, -1.4481e+00,\n",
      "         -1.2964e+00, -1.6563e+00],\n",
      "        [-5.0963e-02, -1.5061e-01, -6.3591e-01,  2.8578e+00, -1.4457e+00,\n",
      "         -1.2928e+00, -1.6531e+00]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n",
      "out:  tensor([[ 0.1907,  0.4106, -0.3517, -0.2187, -0.8326, -0.8712, -0.8555],\n",
      "        [ 0.3473,  0.7039, -0.6812,  0.1480, -1.7304, -1.8021, -1.8838],\n",
      "        [ 0.2188,  0.4558, -0.6683,  1.1758, -1.7617, -1.8628, -2.0462],\n",
      "        [ 0.0625,  0.1294, -0.6701,  2.0643, -1.5717, -1.6189, -1.8895],\n",
      "        [-0.0157, -0.0334, -0.6976,  2.5964, -1.5311, -1.5027, -1.8252],\n",
      "        [-0.0533, -0.1021, -0.7120,  2.8880, -1.5441, -1.4572, -1.8066],\n",
      "        [-0.0719, -0.1342, -0.7162,  3.0427, -1.5593, -1.4332, -1.7966],\n",
      "        [-0.0816, -0.1512, -0.7163,  3.1257, -1.5688, -1.4173, -1.7885],\n",
      "        [-0.0871, -0.1612, -0.7155,  3.1717, -1.5736, -1.4057, -1.7816],\n",
      "        [-0.0904, -0.1676, -0.7145,  3.1984, -1.5754, -1.3967, -1.7756],\n",
      "        [-0.0926, -0.1721, -0.7137,  3.2145, -1.5753, -1.3896, -1.7706],\n",
      "        [-0.0942, -0.1753, -0.7130,  3.2245, -1.5742, -1.3837, -1.7663],\n",
      "        [-0.0953, -0.1778, -0.7124,  3.2309, -1.5726, -1.3789, -1.7627],\n",
      "        [-0.0961, -0.1798, -0.7119,  3.2351, -1.5709, -1.3749, -1.7596],\n",
      "        [-0.0968, -0.1813, -0.7114,  3.2379, -1.5691, -1.3716, -1.7570],\n",
      "        [-0.0973, -0.1825, -0.7110,  3.2398, -1.5675, -1.3688, -1.7549]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n",
      "out:  tensor([[ 0.1865,  0.4073, -0.3538, -0.2008, -0.8381, -0.8770, -0.8615],\n",
      "        [ 0.3399,  0.7057, -0.6994,  0.2032, -1.7697, -1.8429, -1.9254],\n",
      "        [ 0.1992,  0.4462, -0.7003,  1.3069, -1.8143, -1.9177, -2.1039],\n",
      "        [ 0.0332,  0.1052, -0.7178,  2.2714, -1.6354, -1.6749, -1.9548],\n",
      "        [-0.0483, -0.0574, -0.7574,  2.8555, -1.6201, -1.5731, -1.9106],\n",
      "        [-0.0875, -0.1247, -0.7771,  3.1785, -1.6478, -1.5365, -1.9034],\n",
      "        [-0.1064, -0.1569, -0.7828,  3.3501, -1.6685, -1.5154, -1.8971],\n",
      "        [-0.1161, -0.1747, -0.7830,  3.4423, -1.6794, -1.4996, -1.8891],\n",
      "        [-0.1205, -0.1843, -0.7829,  3.4920, -1.6867, -1.4901, -1.8847],\n",
      "        [-0.1226, -0.1900, -0.7828,  3.5204, -1.6907, -1.4837, -1.8817],\n",
      "        [-0.1239, -0.1939, -0.7826,  3.5379, -1.6923, -1.4784, -1.8790],\n",
      "        [-0.1248, -0.1970, -0.7823,  3.5494, -1.6921, -1.4736, -1.8760],\n",
      "        [-0.1266, -0.2007, -0.7806,  3.5590, -1.6884, -1.4663, -1.8696],\n",
      "        [-0.1284, -0.2044, -0.7786,  3.5662, -1.6837, -1.4585, -1.8624],\n",
      "        [-0.1300, -0.2076, -0.7767,  3.5711, -1.6789, -1.4513, -1.8555],\n",
      "        [-0.1314, -0.2102, -0.7750,  3.5743, -1.6745, -1.4451, -1.8495]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n",
      "out:  tensor([[ 0.1798,  0.3964, -0.3533, -0.1637, -0.8381, -0.8773, -0.8638],\n",
      "        [ 0.3132,  0.6619, -0.6944,  0.3323, -1.7475, -1.8229, -1.9099],\n",
      "        [ 0.1558,  0.3807, -0.7132,  1.5187, -1.7866, -1.8861, -2.0813],\n",
      "        [-0.0053,  0.0537, -0.7549,  2.5133, -1.6594, -1.6815, -1.9738],\n",
      "        [-0.0842, -0.0930, -0.8035,  3.1141, -1.6806, -1.6098, -1.9597],\n",
      "        [-0.1218, -0.1546, -0.8260,  3.4464, -1.7211, -1.5853, -1.9640],\n",
      "        [-0.1394, -0.1854, -0.8327,  3.6225, -1.7462, -1.5691, -1.9620],\n",
      "        [-0.1476, -0.2018, -0.8340,  3.7153, -1.7598, -1.5568, -1.9576],\n",
      "        [-0.1525, -0.2129, -0.8329,  3.7687, -1.7645, -1.5449, -1.9501],\n",
      "        [-0.1555, -0.2206, -0.8314,  3.8002, -1.7651, -1.5345, -1.9426],\n",
      "        [-0.1576, -0.2261, -0.8299,  3.8195, -1.7636, -1.5257, -1.9358],\n",
      "        [-0.1591, -0.2303, -0.8287,  3.8319, -1.7611, -1.5182, -1.9298],\n",
      "        [-0.1602, -0.2335, -0.8276,  3.8400, -1.7583, -1.5119, -1.9247],\n",
      "        [-0.1610, -0.2361, -0.8266,  3.8454, -1.7555, -1.5066, -1.9203],\n",
      "        [-0.1617, -0.2381, -0.8258,  3.8491, -1.7529, -1.5021, -1.9166],\n",
      "        [-0.1622, -0.2397, -0.8251,  3.8516, -1.7505, -1.4984, -1.9135]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n",
      "out:  tensor([[ 0.1737,  0.3863, -0.3532, -0.1284, -0.8388, -0.8782, -0.8667],\n",
      "        [ 0.2883,  0.6215, -0.6907,  0.4539, -1.7282, -1.8053, -1.8968],\n",
      "        [ 0.1176,  0.3216, -0.7265,  1.7122, -1.7648, -1.8600, -2.0637],\n",
      "        [-0.0383,  0.0101, -0.7886,  2.7291, -1.6869, -1.6933, -1.9960],\n",
      "        [-0.1145, -0.1237, -0.8447,  3.3427, -1.7376, -1.6474, -2.0073],\n",
      "        [-0.1505, -0.1817, -0.8691,  3.6812, -1.7870, -1.6322, -2.0197],\n",
      "        [-0.1672, -0.2118, -0.8763,  3.8595, -1.8142, -1.6190, -2.0198],\n",
      "        [-0.1753, -0.2293, -0.8774,  3.9547, -1.8269, -1.6064, -2.0143],\n",
      "        [-0.1798, -0.2403, -0.8765,  4.0078, -1.8317, -1.5950, -2.0073],\n",
      "        [-0.1825, -0.2478, -0.8753,  4.0390, -1.8323, -1.5851, -2.0003],\n",
      "        [-0.1844, -0.2533, -0.8740,  4.0582, -1.8308, -1.5765, -1.9937],\n",
      "        [-0.1858, -0.2575, -0.8728,  4.0706, -1.8282, -1.5691, -1.9879],\n",
      "        [-0.1869, -0.2607, -0.8717,  4.0788, -1.8252, -1.5627, -1.9827],\n",
      "        [-0.1877, -0.2633, -0.8707,  4.0844, -1.8222, -1.5572, -1.9782],\n",
      "        [-0.1884, -0.2655, -0.8698,  4.0882, -1.8194, -1.5526, -1.9743],\n",
      "        [-0.1890, -0.2672, -0.8691,  4.0908, -1.8169, -1.5488, -1.9711]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n",
      "out:  tensor([[ 0.1679,  0.3771, -0.3536, -0.0946, -0.8402, -0.8797, -0.8701],\n",
      "        [ 0.2651,  0.5840, -0.6883,  0.5693, -1.7114, -1.7901, -1.8857],\n",
      "        [ 0.0837,  0.2683, -0.7402,  1.8899, -1.7487, -1.8392, -2.0508],\n",
      "        [-0.0671, -0.0274, -0.8198,  2.9237, -1.7167, -1.7087, -2.0203],\n",
      "        [-0.1410, -0.1511, -0.8816,  3.5469, -1.7902, -1.6838, -2.0516],\n",
      "        [-0.1757, -0.2066, -0.9070,  3.8886, -1.8454, -1.6754, -2.0693],\n",
      "        [-0.1917, -0.2364, -0.9145,  4.0674, -1.8735, -1.6642, -2.0704],\n",
      "        [-0.1997, -0.2540, -0.9157,  4.1622, -1.8859, -1.6521, -2.0649],\n",
      "        [-0.2041, -0.2652, -0.9150,  4.2149, -1.8902, -1.6408, -2.0578],\n",
      "        [-0.2068, -0.2729, -0.9139,  4.2459, -1.8904, -1.6308, -2.0506],\n",
      "        [-0.2088, -0.2785, -0.9126,  4.2651, -1.8885, -1.6220, -2.0440],\n",
      "        [-0.2102, -0.2827, -0.9114,  4.2774, -1.8857, -1.6145, -2.0380],\n",
      "        [-0.2113, -0.2861, -0.9103,  4.2856, -1.8825, -1.6079, -2.0328],\n",
      "        [-0.2122, -0.2887, -0.9093,  4.2912, -1.8794, -1.6024, -2.0282],\n",
      "        [-0.2130, -0.2909, -0.9085,  4.2950, -1.8765, -1.5978, -2.0244],\n",
      "        [-0.2135, -0.2926, -0.9077,  4.2976, -1.8739, -1.5939, -2.0211]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n",
      "out:  tensor([[ 0.1625,  0.3684, -0.3543, -0.0620, -0.8422, -0.8818, -0.8740],\n",
      "        [ 0.2433,  0.5489, -0.6869,  0.6792, -1.6969, -1.7769, -1.8766],\n",
      "        [ 0.0534,  0.2204, -0.7543,  2.0541, -1.7379, -1.8234, -2.0423],\n",
      "        [-0.0927, -0.0602, -0.8490,  3.1012, -1.7480, -1.7268, -2.0462],\n",
      "        [-0.1647, -0.1759, -0.9150,  3.7310, -1.8391, -1.7190, -2.0932],\n",
      "        [-0.1983, -0.2298, -0.9411,  4.0739, -1.8979, -1.7156, -2.1142],\n",
      "        [-0.2140, -0.2595, -0.9487,  4.2517, -1.9261, -1.7056, -2.1155],\n",
      "        [-0.2219, -0.2771, -0.9500,  4.3455, -1.9380, -1.6937, -2.1099],\n",
      "        [-0.2264, -0.2885, -0.9494,  4.3975, -1.9417, -1.6824, -2.1025],\n",
      "        [-0.2293, -0.2962, -0.9483,  4.4279, -1.9414, -1.6722, -2.0952],\n",
      "        [-0.2314, -0.3019, -0.9471,  4.4468, -1.9391, -1.6633, -2.0885],\n",
      "        [-0.2329, -0.3062, -0.9459,  4.4590, -1.9360, -1.6556, -2.0824],\n",
      "        [-0.2341, -0.3096, -0.9448,  4.4671, -1.9327, -1.6490, -2.0771],\n",
      "        [-0.2351, -0.3123, -0.9438,  4.4727, -1.9294, -1.6435, -2.0726],\n",
      "        [-0.2358, -0.3144, -0.9430,  4.4765, -1.9265, -1.6388, -2.0687],\n",
      "        [-0.2364, -0.3162, -0.9423,  4.4791, -1.9239, -1.6349, -2.0655]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n",
      "out:  tensor([[ 0.1573,  0.3603, -0.3554, -0.0304, -0.8447, -0.8844, -0.8784],\n",
      "        [ 0.2227,  0.5159, -0.6864,  0.7846, -1.6844, -1.7655, -1.8692],\n",
      "        [ 0.0260,  0.1770, -0.7686,  2.2067, -1.7319, -1.8123, -2.0380],\n",
      "        [-0.1159, -0.0892, -0.8765,  3.2644, -1.7802, -1.7470, -2.0733],\n",
      "        [-0.1861, -0.1987, -0.9457,  3.8987, -1.8848, -1.7530, -2.1323],\n",
      "        [-0.2190, -0.2514, -0.9720,  4.2410, -1.9457, -1.7532, -2.1553],\n",
      "        [-0.2346, -0.2810, -0.9796,  4.4171, -1.9736, -1.7439, -2.1565],\n",
      "        [-0.2426, -0.2987, -0.9810,  4.5093, -1.9847, -1.7320, -2.1505],\n",
      "        [-0.2473, -0.3101, -0.9804,  4.5602, -1.9877, -1.7205, -2.1429],\n",
      "        [-0.2504, -0.3180, -0.9794,  4.5901, -1.9869, -1.7103, -2.1354],\n",
      "        [-0.2525, -0.3237, -0.9782,  4.6086, -1.9843, -1.7012, -2.1285],\n",
      "        [-0.2542, -0.3281, -0.9771,  4.6206, -1.9809, -1.6934, -2.1225],\n",
      "        [-0.2554, -0.3315, -0.9760,  4.6286, -1.9773, -1.6868, -2.1171],\n",
      "        [-0.2565, -0.3342, -0.9751,  4.6340, -1.9740, -1.6811, -2.1126],\n",
      "        [-0.2573, -0.3364, -0.9742,  4.6378, -1.9710, -1.6764, -2.1087],\n",
      "        [-0.2579, -0.3381, -0.9735,  4.6403, -1.9684, -1.6725, -2.1055]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n",
      "out:  tensor([[ 1.5238e-01,  3.5262e-01, -3.5670e-01,  3.0287e-04, -8.4772e-01,\n",
      "         -8.8746e-01, -8.8321e-01],\n",
      "        [ 2.0311e-01,  4.8478e-01, -6.8677e-01,  8.8591e-01, -1.6736e+00,\n",
      "         -1.7558e+00, -1.8632e+00],\n",
      "        [ 1.1601e-03,  1.3779e-01, -7.8320e-01,  2.3494e+00, -1.7302e+00,\n",
      "         -1.8053e+00, -2.0373e+00],\n",
      "        [-1.3700e-01, -1.1528e-01, -9.0267e-01,  3.4157e+00, -1.8127e+00,\n",
      "         -1.7686e+00, -2.1010e+00],\n",
      "        [-2.0582e-01, -2.1970e-01, -9.7420e-01,  4.0527e+00, -1.9278e+00,\n",
      "         -1.7860e+00, -2.1694e+00],\n",
      "        [-2.3820e-01, -2.7163e-01, -1.0005e+00,  4.3932e+00, -1.9898e+00,\n",
      "         -1.7886e+00, -2.1934e+00],\n",
      "        [-2.5374e-01, -3.0117e-01, -1.0080e+00,  4.5667e+00, -2.0169e+00,\n",
      "         -1.7796e+00, -2.1942e+00],\n",
      "        [-2.6198e-01, -3.1897e-01, -1.0094e+00,  4.6571e+00, -2.0271e+00,\n",
      "         -1.7677e+00, -2.1877e+00],\n",
      "        [-2.6688e-01, -3.3043e-01, -1.0089e+00,  4.7069e+00, -2.0295e+00,\n",
      "         -1.7560e+00, -2.1798e+00],\n",
      "        [-2.7010e-01, -3.3834e-01, -1.0079e+00,  4.7360e+00, -2.0281e+00,\n",
      "         -1.7456e+00, -2.1722e+00],\n",
      "        [-2.7240e-01, -3.4413e-01, -1.0067e+00,  4.7541e+00, -2.0251e+00,\n",
      "         -1.7364e+00, -2.1652e+00],\n",
      "        [-2.7414e-01, -3.4855e-01, -1.0056e+00,  4.7659e+00, -2.0214e+00,\n",
      "         -1.7285e+00, -2.1591e+00],\n",
      "        [-2.7550e-01, -3.5200e-01, -1.0045e+00,  4.7737e+00, -2.0177e+00,\n",
      "         -1.7218e+00, -2.1537e+00],\n",
      "        [-2.7657e-01, -3.5473e-01, -1.0036e+00,  4.7791e+00, -2.0143e+00,\n",
      "         -1.7161e+00, -2.1491e+00],\n",
      "        [-2.7741e-01, -3.5689e-01, -1.0028e+00,  4.7828e+00, -2.0112e+00,\n",
      "         -1.7114e+00, -2.1453e+00],\n",
      "        [-2.7806e-01, -3.5860e-01, -1.0021e+00,  4.7853e+00, -2.0085e+00,\n",
      "         -1.7075e+00, -2.1421e+00]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4])\n",
      "out:  tensor([[ 0.1439,  0.3366, -0.3472, -0.0053, -0.7914, -0.8654, -0.8631],\n",
      "        [ 0.1687,  0.4340, -0.6400,  0.7804, -1.3874, -1.6367, -1.7403],\n",
      "        [-0.0433,  0.0818, -0.6805,  1.9326, -1.1222, -1.5756, -1.7815],\n",
      "        [-0.1865, -0.1720, -0.7323,  2.6421, -0.9071, -1.4366, -1.7163],\n",
      "        [-0.2629, -0.2805, -0.7647,  3.0254, -0.8173, -1.3773, -1.6940],\n",
      "        [-0.3047, -0.3392, -0.7710,  3.2217, -0.7544, -1.3272, -1.6614],\n",
      "        [-0.3296, -0.3793, -0.7651,  3.3194, -0.7036, -1.2781, -1.6203],\n",
      "        [-0.3465, -0.4100, -0.7551,  3.3683, -0.6614, -1.2324, -1.5773],\n",
      "        [-0.3591, -0.4348, -0.7445,  3.3926, -0.6262, -1.1916, -1.5363],\n",
      "        [-0.3689, -0.4549, -0.7347,  3.4044, -0.5972, -1.1568, -1.4995],\n",
      "        [-0.3767, -0.4711, -0.7262,  3.4096, -0.5736, -1.1280, -1.4680],\n",
      "        [-0.3828, -0.4838, -0.7192,  3.4114, -0.5549, -1.1048, -1.4419],\n",
      "        [-0.3875, -0.4936, -0.7136,  3.4113, -0.5404, -1.0866, -1.4209],\n",
      "        [-0.3912, -0.5010, -0.7094,  3.4103, -0.5293, -1.0726, -1.4044],\n",
      "        [-0.3940, -0.5066, -0.7062,  3.4089, -0.5210, -1.0619, -1.3917],\n",
      "        [-0.3961, -0.5107, -0.7039,  3.4074, -0.5148, -1.0540, -1.3821]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4])\n",
      "out:  tensor([[ 0.1219,  0.2969, -0.3127, -0.0190, -0.6709, -0.7842, -0.7781],\n",
      "        [ 0.1027,  0.3365, -0.5429,  0.6485, -0.9794, -1.3795, -1.4586],\n",
      "        [-0.1418, -0.0277, -0.5182,  1.5761, -0.4329, -1.1730, -1.3214],\n",
      "        [-0.3321, -0.3135, -0.4758,  2.0800,  0.0535, -0.8545, -1.0311],\n",
      "        [-0.4584, -0.4840, -0.4167,  2.3185,  0.3835, -0.5954, -0.7690],\n",
      "        [-0.5394, -0.5993, -0.3336,  2.4282,  0.6354, -0.3685, -0.5399],\n",
      "        [-0.5894, -0.6796, -0.2458,  2.4797,  0.8270, -0.1790, -0.3550],\n",
      "        [-0.6192, -0.7370, -0.1686,  2.5056,  0.9683, -0.0302, -0.2105],\n",
      "        [-0.6359, -0.7788, -0.1058,  2.5188,  1.0711,  0.0825, -0.0976],\n",
      "        [-0.6438, -0.8097, -0.0563,  2.5245,  1.1462,  0.1668, -0.0085],\n",
      "        [-0.6462, -0.8329, -0.0179,  2.5255,  1.2014,  0.2300,  0.0623],\n",
      "        [-0.6453, -0.8504,  0.0115,  2.5233,  1.2421,  0.2774,  0.1182],\n",
      "        [-0.6426, -0.8635,  0.0337,  2.5192,  1.2717,  0.3128,  0.1617],\n",
      "        [-0.6389, -0.8730,  0.0502,  2.5141,  1.2927,  0.3390,  0.1950],\n",
      "        [-0.6351, -0.8798,  0.0623,  2.5086,  1.3073,  0.3582,  0.2201],\n",
      "        [-0.6315, -0.8846,  0.0710,  2.5033,  1.3172,  0.3721,  0.2387]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4])\n",
      "out:  tensor([[ 0.1012,  0.2589, -0.2842, -0.0052, -0.5824, -0.7081, -0.7003],\n",
      "        [ 0.0446,  0.2333, -0.4672,  0.6242, -0.6521, -1.1656, -1.2289],\n",
      "        [-0.2210, -0.1518, -0.3977,  1.4062,  0.1326, -0.8724, -0.9787],\n",
      "        [-0.4384, -0.4758, -0.2472,  1.7462,  0.9320, -0.3798, -0.4765],\n",
      "        [-0.5612, -0.7134, -0.0409,  1.8665,  1.5871,  0.0835,  0.0211],\n",
      "        [-0.6011, -0.9106,  0.1703,  1.9117,  2.0744,  0.4479,  0.4299],\n",
      "        [-0.5921, -1.0776,  0.3555,  1.9156,  2.4175,  0.7237,  0.7502],\n",
      "        [-0.5604, -1.2158,  0.5099,  1.8920,  2.6562,  0.9437,  1.0075],\n",
      "        [-0.5149, -1.3279,  0.6329,  1.8400,  2.8147,  1.1273,  1.2171],\n",
      "        [-0.4563, -1.4102,  0.7164,  1.7511,  2.8911,  1.2692,  1.3716],\n",
      "        [-0.3862, -1.4519,  0.7497,  1.6233,  2.8720,  1.3514,  1.4524],\n",
      "        [-0.3131, -1.4460,  0.7312,  1.4721,  2.7596,  1.3626,  1.4507],\n",
      "        [-0.2506, -1.4002,  0.6756,  1.3308,  2.5885,  1.3132,  1.3823],\n",
      "        [-0.2108, -1.3365,  0.6087,  1.2327,  2.4150,  1.2345,  1.2853],\n",
      "        [-0.1975, -1.2791,  0.5544,  1.1908,  2.2875,  1.1618,  1.2000],\n",
      "        [-0.2048, -1.2425,  0.5244,  1.1942,  2.2247,  1.1164,  1.1488]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4])\n",
      "out:  tensor([[ 8.8702e-02,  2.3648e-01, -2.7259e-01,  2.0765e-02, -5.3733e-01,\n",
      "         -6.6354e-01, -6.5645e-01],\n",
      "        [ 2.6829e-03,  1.5416e-01, -4.2921e-01,  6.8810e-01, -4.4109e-01,\n",
      "         -1.0548e+00, -1.1191e+00],\n",
      "        [-2.7981e-01, -2.5664e-01, -3.5092e-01,  1.4555e+00,  5.0219e-01,\n",
      "         -7.7910e-01, -8.8442e-01],\n",
      "        [-5.0146e-01, -5.9063e-01, -1.9654e-01,  1.7890e+00,  1.4293e+00,\n",
      "         -3.3982e-01, -4.3601e-01],\n",
      "        [-6.2135e-01, -8.4236e-01,  3.5239e-03,  1.9363e+00,  2.1868e+00,\n",
      "          4.6945e-02, -1.7509e-02],\n",
      "        [-6.6252e-01, -1.0443e+00,  1.9328e-01,  2.0134e+00,  2.7426e+00,\n",
      "          3.2565e-01,  3.0059e-01],\n",
      "        [-6.6582e-01, -1.2003e+00,  3.4237e-01,  2.0518e+00,  3.1246e+00,\n",
      "          5.1512e-01,  5.2414e-01],\n",
      "        [-6.5668e-01, -1.3162e+00,  4.5134e-01,  2.0697e+00,  3.3846e+00,\n",
      "          6.4585e-01,  6.8019e-01],\n",
      "        [-6.4389e-01, -1.4007e+00,  5.3052e-01,  2.0743e+00,  3.5646e+00,\n",
      "          7.4043e-01,  7.9249e-01],\n",
      "        [-6.2977e-01, -1.4602e+00,  5.8721e-01,  2.0684e+00,  3.6880e+00,\n",
      "          8.1006e-01,  8.7361e-01],\n",
      "        [-6.1526e-01, -1.4989e+00,  6.2539e-01,  2.0547e+00,  3.7670e+00,\n",
      "          8.5925e-01,  9.2939e-01],\n",
      "        [-6.0137e-01, -1.5205e+00,  6.4831e-01,  2.0363e+00,  3.8103e+00,\n",
      "          8.9087e-01,  9.6405e-01],\n",
      "        [-5.8905e-01, -1.5293e+00,  6.5978e-01,  2.0168e+00,  3.8272e+00,\n",
      "          9.0856e-01,  9.8247e-01],\n",
      "        [-5.7897e-01, -1.5301e+00,  6.6393e-01,  1.9993e+00,  3.8274e+00,\n",
      "          9.1672e-01,  9.9009e-01],\n",
      "        [-5.7133e-01, -1.5270e+00,  6.6435e-01,  1.9854e+00,  3.8197e+00,\n",
      "          9.1956e-01,  9.9184e-01],\n",
      "        [-5.6590e-01, -1.5229e+00,  6.6355e-01,  1.9755e+00,  3.8100e+00,\n",
      "          9.2022e-01,  9.9134e-01]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[ 0.0997,  0.2705, -0.2962, -0.0042, -0.5766, -0.7065, -0.6989],\n",
      "        [ 0.0345,  0.2700, -0.4906,  0.6171, -0.6297, -1.2184, -1.2845],\n",
      "        [-0.2169, -0.0325, -0.4521,  1.3250,  0.0748, -1.0871, -1.2004],\n",
      "        [-0.4018, -0.2066, -0.3986,  1.5734,  0.6226, -0.8589, -0.9701],\n",
      "        [-0.5155, -0.2807, -0.3389,  1.6132,  0.9896, -0.6653, -0.7552],\n",
      "        [-0.5772, -0.3168, -0.2813,  1.5890,  1.2321, -0.5172, -0.5857],\n",
      "        [-0.6057, -0.3357, -0.2379,  1.5524,  1.3798, -0.4193, -0.4686],\n",
      "        [-0.6162, -0.3458, -0.2087,  1.5186,  1.4649, -0.3588, -0.3926],\n",
      "        [-0.6183, -0.3513, -0.1901,  1.4920,  1.5124, -0.3226, -0.3450],\n",
      "        [-0.6172, -0.3544, -0.1786,  1.4726,  1.5384, -0.3013, -0.3159],\n",
      "        [-0.6152, -0.3561, -0.1717,  1.4593,  1.5522, -0.2888, -0.2983],\n",
      "        [-0.6133, -0.3570, -0.1677,  1.4504,  1.5591, -0.2817, -0.2880],\n",
      "        [-0.6118, -0.3575, -0.1655,  1.4447,  1.5624, -0.2777, -0.2820],\n",
      "        [-0.6107, -0.3577, -0.1643,  1.4411,  1.5637, -0.2756, -0.2787],\n",
      "        [-0.6099, -0.3578, -0.1637,  1.4389,  1.5641, -0.2744, -0.2769],\n",
      "        [-0.6094, -0.3578, -0.1635,  1.4377,  1.5640, -0.2739, -0.2760]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[ 1.0154e-01,  3.0316e-01, -3.1151e-01, -2.8731e-02, -6.1057e-01,\n",
      "         -7.3561e-01, -7.2532e-01],\n",
      "        [ 3.9309e-02,  3.7291e-01, -5.3040e-01,  5.4056e-01, -7.4750e-01,\n",
      "         -1.3182e+00, -1.3786e+00],\n",
      "        [-2.1335e-01,  1.3387e-01, -4.9916e-01,  1.2050e+00, -1.2262e-01,\n",
      "         -1.2351e+00, -1.3381e+00],\n",
      "        [-3.9799e-01,  2.2277e-02, -4.5819e-01,  1.4100e+00,  3.3408e-01,\n",
      "         -1.0427e+00, -1.1390e+00],\n",
      "        [-5.1262e-01,  1.5881e-03, -4.1653e-01,  1.4155e+00,  6.1698e-01,\n",
      "         -8.8257e-01, -9.5289e-01],\n",
      "        [-5.7679e-01, -4.5288e-04, -3.7275e-01,  1.3672e+00,  8.0443e-01,\n",
      "         -7.5261e-01, -7.9896e-01],\n",
      "        [-6.0910e-01, -4.9453e-04, -3.3906e-01,  1.3167e+00,  9.1994e-01,\n",
      "         -6.6243e-01, -6.9010e-01],\n",
      "        [-6.2389e-01, -1.1922e-03, -3.1689e-01,  1.2768e+00,  9.8679e-01,\n",
      "         -6.0534e-01, -6.1973e-01],\n",
      "        [-6.2983e-01, -2.3161e-03, -3.0298e-01,  1.2484e+00,  1.0243e+00,\n",
      "         -5.7057e-01, -5.7599e-01],\n",
      "        [-6.3164e-01, -3.4928e-03, -2.9429e-01,  1.2292e+00,  1.0452e+00,\n",
      "         -5.4959e-01, -5.4911e-01],\n",
      "        [-6.3167e-01, -4.5320e-03, -2.8881e-01,  1.2165e+00,  1.0567e+00,\n",
      "         -5.3689e-01, -5.3256e-01],\n",
      "        [-6.3105e-01, -5.3692e-03, -2.8531e-01,  1.2083e+00,  1.0631e+00,\n",
      "         -5.2913e-01, -5.2231e-01],\n",
      "        [-6.3030e-01, -6.0036e-03, -2.8306e-01,  1.2031e+00,  1.0665e+00,\n",
      "         -5.2437e-01, -5.1593e-01],\n",
      "        [-6.2960e-01, -6.4620e-03, -2.8162e-01,  1.1997e+00,  1.0684e+00,\n",
      "         -5.2144e-01, -5.1196e-01],\n",
      "        [-6.2904e-01, -6.7801e-03, -2.8069e-01,  1.1976e+00,  1.0693e+00,\n",
      "         -5.1964e-01, -5.0949e-01],\n",
      "        [-6.2861e-01, -6.9933e-03, -2.8010e-01,  1.1963e+00,  1.0697e+00,\n",
      "         -5.1854e-01, -5.0796e-01]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[ 0.1015,  0.3330, -0.3256, -0.0483, -0.6407, -0.7640, -0.7517],\n",
      "        [ 0.0356,  0.4640, -0.5666,  0.4853, -0.8404, -1.4079, -1.4637],\n",
      "        [-0.2272,  0.2726, -0.5397,  1.1276, -0.2546, -1.3549, -1.4502],\n",
      "        [-0.4206,  0.2046, -0.5038,  1.3078,  0.1627, -1.1730, -1.2585],\n",
      "        [-0.5419,  0.2205, -0.4689,  1.2932,  0.4051, -1.0250, -1.0800],\n",
      "        [-0.6097,  0.2395, -0.4287,  1.2335,  0.5638, -0.9037, -0.9322],\n",
      "        [-0.6447,  0.2492, -0.3967,  1.1777,  0.6617, -0.8182, -0.8280],\n",
      "        [-0.6622,  0.2526, -0.3758,  1.1362,  0.7186, -0.7632, -0.7610],\n",
      "        [-0.6707,  0.2532, -0.3631,  1.1079,  0.7508, -0.7292, -0.7195],\n",
      "        [-0.6746,  0.2528, -0.3555,  1.0893,  0.7691, -0.7084, -0.6941],\n",
      "        [-0.6763,  0.2520, -0.3509,  1.0773,  0.7795, -0.6957, -0.6784],\n",
      "        [-0.6770,  0.2513, -0.3481,  1.0697,  0.7855, -0.6878, -0.6686],\n",
      "        [-0.6771,  0.2507, -0.3463,  1.0649,  0.7890, -0.6828, -0.6625],\n",
      "        [-0.6771,  0.2503, -0.3452,  1.0618,  0.7911, -0.6797, -0.6586],\n",
      "        [-0.6770,  0.2499, -0.3445,  1.0598,  0.7923, -0.6777, -0.6561],\n",
      "        [-0.6769,  0.2497, -0.3441,  1.0586,  0.7930, -0.6765, -0.6545]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[ 0.1004,  0.3611, -0.3388, -0.0651, -0.6684, -0.7919, -0.7777],\n",
      "        [ 0.0211,  0.5440, -0.5987,  0.4621, -0.9038, -1.4937, -1.5470],\n",
      "        [-0.2596,  0.3907, -0.5736,  1.0859, -0.3268, -1.4477, -1.5372],\n",
      "        [-0.4654,  0.3697, -0.5452,  1.2340,  0.0630, -1.2720, -1.3445],\n",
      "        [-0.5939,  0.4180, -0.5137,  1.2015,  0.2813, -1.1320, -1.1679],\n",
      "        [-0.6641,  0.4525, -0.4743,  1.1366,  0.4198, -1.0205, -1.0278],\n",
      "        [-0.7004,  0.4685, -0.4429,  1.0812,  0.5035, -0.9426, -0.9319],\n",
      "        [-0.7193,  0.4745, -0.4225,  1.0416,  0.5521, -0.8919, -0.8704],\n",
      "        [-0.7291,  0.4761, -0.4100,  1.0153,  0.5800, -0.8598, -0.8319],\n",
      "        [-0.7342,  0.4759, -0.4025,  0.9982,  0.5963, -0.8395, -0.8078],\n",
      "        [-0.7369,  0.4752, -0.3980,  0.9872,  0.6060, -0.8267, -0.7926],\n",
      "        [-0.7382,  0.4744, -0.3953,  0.9802,  0.6119, -0.8184, -0.7829],\n",
      "        [-0.7389,  0.4737, -0.3936,  0.9757,  0.6155, -0.8131, -0.7766],\n",
      "        [-0.7393,  0.4731, -0.3925,  0.9728,  0.6179, -0.8096, -0.7725],\n",
      "        [-0.7392,  0.4730, -0.3919,  0.9702,  0.6183, -0.8075, -0.7700],\n",
      "        [-0.7390,  0.4739, -0.3919,  0.9675,  0.6161, -0.8070, -0.7694]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[ 0.1172,  0.4650, -0.4042, -0.1011, -0.8283, -0.9490, -0.9382],\n",
      "        [ 0.0199,  0.7052, -0.6788,  0.4404, -1.1216, -1.7350, -1.7922],\n",
      "        [-0.2872,  0.5339, -0.6289,  1.0850, -0.4601, -1.6254, -1.7178],\n",
      "        [-0.5090,  0.5368, -0.5995,  1.2097, -0.0448, -1.4164, -1.4849],\n",
      "        [-0.6491,  0.6112, -0.5700,  1.1572,  0.1731, -1.2694, -1.2918],\n",
      "        [-0.7249,  0.6590, -0.5309,  1.0846,  0.3044, -1.1603, -1.1505],\n",
      "        [-0.7640,  0.6813, -0.5000,  1.0281,  0.3809, -1.0866, -1.0586],\n",
      "        [-0.7847,  0.6906, -0.4804,  0.9895,  0.4247, -1.0388, -1.0006],\n",
      "        [-0.7961,  0.6939, -0.4688,  0.9643,  0.4501, -1.0080, -0.9640],\n",
      "        [-0.8024,  0.6947, -0.4620,  0.9481,  0.4653, -0.9880, -0.9406],\n",
      "        [-0.8061,  0.6944, -0.4579,  0.9376,  0.4747, -0.9748, -0.9254],\n",
      "        [-0.8082,  0.6938, -0.4555,  0.9308,  0.4807, -0.9660, -0.9153],\n",
      "        [-0.8095,  0.6931, -0.4540,  0.9262,  0.4847, -0.9601, -0.9085],\n",
      "        [-0.8102,  0.6925, -0.4530,  0.9232,  0.4874, -0.9559, -0.9038],\n",
      "        [-0.8107,  0.6920, -0.4524,  0.9211,  0.4893, -0.9530, -0.9005],\n",
      "        [-0.8110,  0.6915, -0.4519,  0.9197,  0.4906, -0.9510, -0.8982]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[ 9.5621e-02,  4.1462e-01, -3.6381e-01, -9.4772e-02, -7.1946e-01,\n",
      "         -8.4712e-01, -8.2972e-01],\n",
      "        [ 7.9450e-05,  7.0929e-01, -6.6599e-01,  3.7267e-01, -1.0521e+00,\n",
      "         -1.6529e+00, -1.6974e+00],\n",
      "        [-3.1612e-01,  6.3869e-01, -6.5666e-01,  9.9450e-01, -4.9205e-01,\n",
      "         -1.6616e+00, -1.7377e+00],\n",
      "        [-5.6009e-01,  6.8424e-01, -6.3692e-01,  1.1296e+00, -8.2648e-02,\n",
      "         -1.4802e+00, -1.5283e+00],\n",
      "        [-7.1131e-01,  7.8714e-01, -6.1010e-01,  1.0826e+00,  1.2564e-01,\n",
      "         -1.3526e+00, -1.3511e+00],\n",
      "        [-7.9134e-01,  8.4899e-01, -5.7523e-01,  1.0189e+00,  2.4252e-01,\n",
      "         -1.2630e+00, -1.2302e+00],\n",
      "        [-8.3264e-01,  8.7886e-01, -5.4912e-01,  9.7072e-01,  3.0686e-01,\n",
      "         -1.2042e+00, -1.1553e+00],\n",
      "        [-8.5483e-01,  8.9333e-01, -5.3324e-01,  9.3895e-01,  3.4227e-01,\n",
      "         -1.1670e+00, -1.1097e+00],\n",
      "        [-8.6735e-01,  9.0061e-01, -5.2441e-01,  9.1888e-01,  3.6213e-01,\n",
      "         -1.1435e+00, -1.0818e+00],\n",
      "        [-8.7472e-01,  9.0439e-01, -5.1970e-01,  9.0628e-01,  3.7358e-01,\n",
      "         -1.1284e+00, -1.0641e+00],\n",
      "        [-8.7922e-01,  9.0639e-01, -5.1725e-01,  8.9829e-01,  3.8043e-01,\n",
      "         -1.1186e+00, -1.0527e+00],\n",
      "        [-8.8206e-01,  9.0744e-01, -5.1600e-01,  8.9314e-01,  3.8472e-01,\n",
      "         -1.1120e+00, -1.0452e+00],\n",
      "        [-8.8389e-01,  9.0797e-01, -5.1536e-01,  8.8975e-01,  3.8752e-01,\n",
      "         -1.1074e+00, -1.0400e+00],\n",
      "        [-8.8510e-01,  9.0821e-01, -5.1504e-01,  8.8745e-01,  3.8943e-01,\n",
      "         -1.1042e+00, -1.0364e+00],\n",
      "        [-8.8590e-01,  9.0828e-01, -5.1487e-01,  8.8587e-01,  3.9080e-01,\n",
      "         -1.1020e+00, -1.0338e+00],\n",
      "        [-8.8645e-01,  9.0826e-01, -5.1478e-01,  8.8475e-01,  3.9180e-01,\n",
      "         -1.1003e+00, -1.0319e+00]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[ 0.0925,  0.4403, -0.3758, -0.1082, -0.7435, -0.8745, -0.8557],\n",
      "        [-0.0167,  0.7858, -0.6972,  0.3437, -1.1110, -1.7304, -1.7720],\n",
      "        [-0.3564,  0.7553, -0.6959,  0.9632, -0.5473, -1.7572, -1.8273],\n",
      "        [-0.6212,  0.8412, -0.6808,  1.0858, -0.1256, -1.5750, -1.6077],\n",
      "        [-0.7821,  0.9698, -0.6534,  1.0330,  0.0837, -1.4543, -1.4316],\n",
      "        [-0.8652,  1.0417, -0.6204,  0.9707,  0.1940, -1.3752, -1.3207],\n",
      "        [-0.9076,  1.0762, -0.5968,  0.9259,  0.2519, -1.3249, -1.2555],\n",
      "        [-0.9305,  1.0938, -0.5828,  0.8974,  0.2830, -1.2938, -1.2174],\n",
      "        [-0.9436,  1.1035, -0.5753,  0.8800,  0.3000, -1.2746, -1.1948],\n",
      "        [-0.9515,  1.1094, -0.5716,  0.8692,  0.3095, -1.2626, -1.1811],\n",
      "        [-0.9566,  1.1131, -0.5699,  0.8626,  0.3149, -1.2550, -1.1725],\n",
      "        [-0.9599,  1.1155, -0.5693,  0.8584,  0.3180, -1.2500, -1.1669],\n",
      "        [-0.9621,  1.1171, -0.5692,  0.8556,  0.3199, -1.2466, -1.1632],\n",
      "        [-0.9636,  1.1183, -0.5693,  0.8538,  0.3210, -1.2442, -1.1607],\n",
      "        [-0.9647,  1.1190, -0.5694,  0.8526,  0.3218, -1.2426, -1.1589],\n",
      "        [-0.9655,  1.1196, -0.5696,  0.8518,  0.3223, -1.2414, -1.1576]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[ 0.1021,  0.5245, -0.4279, -0.1373, -0.8650, -0.9993, -0.9832],\n",
      "        [-0.0415,  0.9008, -0.7508,  0.3490, -1.2225, -1.8924, -1.9373],\n",
      "        [-0.4133,  0.8802, -0.7390,  0.9647, -0.5924, -1.8696, -1.9387],\n",
      "        [-0.6957,  1.0113, -0.7250,  1.0539, -0.1565, -1.6742, -1.6916],\n",
      "        [-0.8615,  1.1618, -0.6949,  0.9904,  0.0531, -1.5584, -1.5156],\n",
      "        [-0.9446,  1.2404, -0.6631,  0.9280,  0.1572, -1.4880, -1.4147],\n",
      "        [-0.9863,  1.2779, -0.6416,  0.8859,  0.2100, -1.4447, -1.3585],\n",
      "        [-1.0089,  1.2977, -0.6290,  0.8601,  0.2379, -1.4184, -1.3267],\n",
      "        [-1.0219,  1.3093, -0.6223,  0.8446,  0.2531, -1.4026, -1.3085],\n",
      "        [-1.0300,  1.3168, -0.6190,  0.8353,  0.2615, -1.3930, -1.2978],\n",
      "        [-1.0352,  1.3219, -0.6177,  0.8295,  0.2662, -1.3871, -1.2914],\n",
      "        [-1.0388,  1.3255, -0.6173,  0.8259,  0.2688, -1.3834, -1.2875],\n",
      "        [-1.0413,  1.3281, -0.6174,  0.8236,  0.2702, -1.3810, -1.2850],\n",
      "        [-1.0430,  1.3301, -0.6177,  0.8221,  0.2710, -1.3795, -1.2834],\n",
      "        [-1.0443,  1.3316, -0.6180,  0.8211,  0.2714, -1.3784, -1.2823],\n",
      "        [-1.0453,  1.3327, -0.6184,  0.8204,  0.2716, -1.3777, -1.2816]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[ 0.0850,  0.4901, -0.3986, -0.1338, -0.7887, -0.9269, -0.9057],\n",
      "        [-0.0561,  0.9340, -0.7566,  0.2907, -1.2162, -1.8758, -1.9118],\n",
      "        [-0.4492,  0.9897, -0.7743,  0.9023, -0.6392, -1.9358, -1.9928],\n",
      "        [-0.7549,  1.1639, -0.7625,  1.0026, -0.1884, -1.7559, -1.7586],\n",
      "        [-0.9314,  1.3416, -0.7327,  0.9437,  0.0236, -1.6554, -1.5989],\n",
      "        [-1.0182,  1.4332, -0.7043,  0.8859,  0.1226, -1.5984, -1.5138],\n",
      "        [-1.0613,  1.4778, -0.6856,  0.8484,  0.1707, -1.5642, -1.4684],\n",
      "        [-1.0845,  1.5019, -0.6749,  0.8263,  0.1954, -1.5442, -1.4437],\n",
      "        [-1.0981,  1.5165, -0.6694,  0.8134,  0.2086, -1.5330, -1.4303],\n",
      "        [-1.1066,  1.5262, -0.6669,  0.8060,  0.2157, -1.5269, -1.4231],\n",
      "        [-1.1122,  1.5332, -0.6661,  0.8018,  0.2195, -1.5238, -1.4193],\n",
      "        [-1.1160,  1.5383, -0.6661,  0.7993,  0.2213, -1.5224, -1.4174],\n",
      "        [-1.1187,  1.5421, -0.6665,  0.7979,  0.2222, -1.5219, -1.4166],\n",
      "        [-1.1207,  1.5451, -0.6671,  0.7971,  0.2225, -1.5218, -1.4163],\n",
      "        [-1.1221,  1.5473, -0.6676,  0.7967,  0.2225, -1.5221, -1.4164],\n",
      "        [-1.1232,  1.5491, -0.6682,  0.7964,  0.2223, -1.5224, -1.4166]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[ 0.0809,  0.5148, -0.4102, -0.1459, -0.8111, -0.9533, -0.9309],\n",
      "        [-0.0772,  1.0069, -0.7865,  0.2663, -1.2666, -1.9469, -1.9802],\n",
      "        [-0.4978,  1.1082, -0.8144,  0.8723, -0.6828, -2.0225, -2.0727],\n",
      "        [-0.8214,  1.3260, -0.8021,  0.9629, -0.2191, -1.8474, -1.8388],\n",
      "        [-1.0043,  1.5250, -0.7728,  0.9020, -0.0083, -1.7602, -1.6940],\n",
      "        [-1.0925,  1.6257, -0.7480,  0.8473,  0.0848, -1.7144, -1.6224],\n",
      "        [-1.1362,  1.6752, -0.7326,  0.8144,  0.1281, -1.6885, -1.5861],\n",
      "        [-1.1598,  1.7026, -0.7242,  0.7962,  0.1495, -1.6748, -1.5677],\n",
      "        [-1.1735,  1.7197, -0.7203,  0.7866,  0.1605, -1.6685, -1.5589],\n",
      "        [-1.1821,  1.7314, -0.7189,  0.7818,  0.1659, -1.6666, -1.5555],\n",
      "        [-1.1876,  1.7398, -0.7188,  0.7796,  0.1683, -1.6671, -1.5549],\n",
      "        [-1.1913,  1.7461, -0.7195,  0.7789,  0.1691, -1.6688, -1.5559],\n",
      "        [-1.1938,  1.7507, -0.7204,  0.7790,  0.1689, -1.6710, -1.5575],\n",
      "        [-1.1956,  1.7543, -0.7214,  0.7795,  0.1684, -1.6732, -1.5594],\n",
      "        [-1.1968,  1.7569, -0.7224,  0.7801,  0.1676, -1.6753, -1.5612],\n",
      "        [-1.1976,  1.7589, -0.7232,  0.7808,  0.1669, -1.6772, -1.5628]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[ 0.0768,  0.5395, -0.4217, -0.1578, -0.8332, -0.9793, -0.9559],\n",
      "        [-0.0989,  1.0794, -0.8163,  0.2420, -1.3154, -2.0159, -2.0463],\n",
      "        [-0.5468,  1.2274, -0.8545,  0.8405, -0.7254, -2.1054, -2.1483],\n",
      "        [-0.8870,  1.4852, -0.8413,  0.9215, -0.2507, -1.9374, -1.9189],\n",
      "        [-1.0758,  1.7015, -0.8139,  0.8586, -0.0425, -1.8636, -1.7900],\n",
      "        [-1.1660,  1.8095, -0.7933,  0.8074,  0.0449, -1.8281, -1.7305],\n",
      "        [-1.2106,  1.8632, -0.7815,  0.7791,  0.0838, -1.8100, -1.7025],\n",
      "        [-1.2347,  1.8934, -0.7758,  0.7651,  0.1021, -1.8026, -1.6904],\n",
      "        [-1.2486,  1.9127, -0.7738,  0.7590,  0.1106, -1.8019, -1.6870],\n",
      "        [-1.2571,  1.9260, -0.7738,  0.7571,  0.1139, -1.8049, -1.6884],\n",
      "        [-1.2623,  1.9355, -0.7750,  0.7574,  0.1145, -1.8097, -1.6922],\n",
      "        [-1.2656,  1.9424, -0.7766,  0.7588,  0.1136, -1.8150, -1.6968],\n",
      "        [-1.2677,  1.9474, -0.7783,  0.7607,  0.1121, -1.8202, -1.7015],\n",
      "        [-1.2690,  1.9511, -0.7799,  0.7625,  0.1104, -1.8249, -1.7057],\n",
      "        [-1.2697,  1.9537, -0.7812,  0.7643,  0.1087, -1.8289, -1.7095],\n",
      "        [-1.2702,  1.9557, -0.7824,  0.7658,  0.1071, -1.8322, -1.7126]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[ 7.2511e-02,  5.6413e-01, -4.3343e-01, -1.6963e-01, -8.5527e-01,\n",
      "         -1.0054e+00, -9.8094e-01],\n",
      "        [-1.2095e-01,  1.1518e+00, -8.4630e-01,  2.1762e-01, -1.3638e+00,\n",
      "         -2.0836e+00, -2.1111e+00],\n",
      "        [-5.9546e-01,  1.3472e+00, -8.9465e-01,  8.0681e-01, -7.6878e-01,\n",
      "         -2.1859e+00, -2.2211e+00],\n",
      "        [-9.5114e-01,  1.6401e+00, -8.8081e-01,  8.7847e-01, -2.8565e-01,\n",
      "         -2.0268e+00, -1.9998e+00],\n",
      "        [-1.1456e+00,  1.8702e+00, -8.5649e-01,  8.1371e-01, -8.1545e-02,\n",
      "         -1.9664e+00, -1.8867e+00],\n",
      "        [-1.2381e+00,  1.9844e+00, -8.4031e-01,  7.6579e-01,  4.0244e-05,\n",
      "         -1.9411e+00, -1.8389e+00],\n",
      "        [-1.2839e+00,  2.0422e+00, -8.3249e-01,  7.4212e-01,  3.4187e-02,\n",
      "         -1.9315e+00, -1.8199e+00],\n",
      "        [-1.3087e+00,  2.0758e+00, -8.3012e-01,  7.3252e-01,  4.8575e-02,\n",
      "         -1.9319e+00, -1.8157e+00],\n",
      "        [-1.3229e+00,  2.0976e+00, -8.3083e-01,  7.3015e-01,  5.3625e-02,\n",
      "         -1.9382e+00, -1.8195e+00],\n",
      "        [-1.3312e+00,  2.1127e+00, -8.3310e-01,  7.3139e-01,  5.3913e-02,\n",
      "         -1.9473e+00, -1.8272e+00],\n",
      "        [-1.3360e+00,  2.1234e+00, -8.3595e-01,  7.3423e-01,  5.1875e-02,\n",
      "         -1.9572e+00, -1.8362e+00],\n",
      "        [-1.3388e+00,  2.1308e+00, -8.3875e-01,  7.3753e-01,  4.8929e-02,\n",
      "         -1.9663e+00, -1.8448e+00],\n",
      "        [-1.3403e+00,  2.1360e+00, -8.4123e-01,  7.4071e-01,  4.5863e-02,\n",
      "         -1.9742e+00, -1.8523e+00],\n",
      "        [-1.3411e+00,  2.1396e+00, -8.4319e-01,  7.4330e-01,  4.3174e-02,\n",
      "         -1.9804e+00, -1.8582e+00],\n",
      "        [-1.3415e+00,  2.1423e+00, -8.4496e-01,  7.4562e-01,  4.0664e-02,\n",
      "         -1.9858e+00, -1.8636e+00],\n",
      "        [-1.3417e+00,  2.1444e+00, -8.4644e-01,  7.4771e-01,  3.8476e-02,\n",
      "         -1.9903e+00, -1.8680e+00]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[ 0.0682,  0.5889, -0.4453, -0.1814, -0.8776, -1.0316, -1.0062],\n",
      "        [-0.1433,  1.2245, -0.8766,  0.1928, -1.4127, -2.1511, -2.1755],\n",
      "        [-0.6437,  1.4671, -0.9348,  0.7714, -0.8145, -2.2663, -2.2935],\n",
      "        [-1.0140,  1.7904, -0.9214,  0.8339, -0.3258, -2.1175, -2.0824],\n",
      "        [-1.2139,  2.0317, -0.9007,  0.7675, -0.1269, -2.0696, -1.9843],\n",
      "        [-1.3087,  2.1523, -0.8889,  0.7225, -0.0520, -2.0552, -1.9489],\n",
      "        [-1.3561,  2.2153, -0.8854,  0.7030, -0.0239, -2.0560, -1.9410],\n",
      "        [-1.3817,  2.2534, -0.8870,  0.6974, -0.0152, -2.0663, -1.9474],\n",
      "        [-1.3962,  2.2788, -0.8912,  0.6985, -0.0152, -2.0816, -1.9606],\n",
      "        [-1.4043,  2.2962, -0.8962,  0.7024, -0.0191, -2.0978, -1.9757],\n",
      "        [-1.4087,  2.3080, -0.9008,  0.7070, -0.0242, -2.1124, -1.9898],\n",
      "        [-1.4109,  2.3159, -0.9045,  0.7113, -0.0290, -2.1243, -2.0013],\n",
      "        [-1.4120,  2.3211, -0.9074,  0.7149, -0.0332, -2.1335, -2.0104],\n",
      "        [-1.4124,  2.3247, -0.9095,  0.7177, -0.0365, -2.1405, -2.0172],\n",
      "        [-1.4125,  2.3271, -0.9110,  0.7199, -0.0390, -2.1457, -2.0224],\n",
      "        [-1.4125,  2.3288, -0.9122,  0.7215, -0.0410, -2.1495, -2.0262]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "out:  tensor([[ 0.0637,  0.6137, -0.4571, -0.1930, -0.9000, -1.0577, -1.0312],\n",
      "        [-0.1662,  1.2968, -0.9069,  0.1676, -1.4617, -2.2175, -2.2385],\n",
      "        [-0.6921,  1.5858, -0.9743,  0.7341, -0.8622, -2.3459, -2.3645],\n",
      "        [-1.0761,  1.9363, -0.9635,  0.7884, -0.3721, -2.2102, -2.1670],\n",
      "        [-1.2812,  2.1869, -0.9471,  0.7211, -0.1793, -2.1733, -2.0818],\n",
      "        [-1.3787,  2.3132, -0.9397,  0.6790, -0.1111, -2.1688, -2.0574],\n",
      "        [-1.4277,  2.3821, -0.9410,  0.6633, -0.0903, -2.1809, -2.0615],\n",
      "        [-1.4544,  2.4241, -0.9464,  0.6606, -0.0871, -2.1998, -2.0768],\n",
      "        [-1.4693,  2.4523, -0.9535,  0.6638, -0.0917, -2.2219, -2.0970],\n",
      "        [-1.4774,  2.4712, -0.9604,  0.6689, -0.0989, -2.2424, -2.1165],\n",
      "        [-1.4815,  2.4834, -0.9659,  0.6739, -0.1059, -2.2589, -2.1324],\n",
      "        [-1.4834,  2.4911, -0.9699,  0.6781, -0.1116, -2.2712, -2.1444],\n",
      "        [-1.4842,  2.4959, -0.9727,  0.6813, -0.1159, -2.2799, -2.1530],\n",
      "        [-1.4845,  2.4991, -0.9746,  0.6837, -0.1191, -2.2861, -2.1591],\n",
      "        [-1.4846,  2.5011, -0.9759,  0.6854, -0.1214, -2.2904, -2.1634],\n",
      "        [-1.4845,  2.5025, -0.9768,  0.6867, -0.1231, -2.2935, -2.1666]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "out:  tensor([[ 0.0599,  0.6186, -0.4378, -0.2039, -0.9053, -1.0654, -1.0377],\n",
      "        [-0.1722,  1.2834, -0.8082,  0.1283, -1.4454, -2.1910, -2.2069],\n",
      "        [-0.6761,  1.5209, -0.7380,  0.6350, -0.8154, -2.2444, -2.2566],\n",
      "        [-1.0313,  1.8044, -0.5836,  0.6393, -0.2953, -2.0418, -1.9988],\n",
      "        [-1.2133,  2.0093, -0.4780,  0.5431, -0.0813, -1.9583, -1.8757],\n",
      "        [-1.2953,  2.1087, -0.4226,  0.4843,  0.0040, -1.9213, -1.8247],\n",
      "        [-1.3348,  2.1587, -0.3937,  0.4553,  0.0421, -1.9044, -1.8025],\n",
      "        [-1.3557,  2.1873, -0.3774,  0.4411,  0.0607, -1.8982, -1.7937],\n",
      "        [-1.3676,  2.2054, -0.3675,  0.4340,  0.0702, -1.8974, -1.7914],\n",
      "        [-1.3747,  2.2175, -0.3612,  0.4302,  0.0750, -1.8991, -1.7921],\n",
      "        [-1.3790,  2.2257, -0.3571,  0.4283,  0.0773, -1.9015, -1.7939],\n",
      "        [-1.3817,  2.2313, -0.3543,  0.4273,  0.0784, -1.9040, -1.7959],\n",
      "        [-1.3834,  2.2351, -0.3525,  0.4269,  0.0789, -1.9061, -1.7978],\n",
      "        [-1.3845,  2.2378, -0.3513,  0.4267,  0.0790, -1.9079, -1.7993],\n",
      "        [-1.3852,  2.2397, -0.3505,  0.4266,  0.0789, -1.9094, -1.8006],\n",
      "        [-1.3856,  2.2410, -0.3500,  0.4267,  0.0788, -1.9105, -1.8017]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "out:  tensor([[ 0.0550,  0.5920, -0.3853, -0.2047, -0.8773, -1.0377, -1.0102],\n",
      "        [-0.1739,  1.1936, -0.6283,  0.1045, -1.3644, -2.0869, -2.1075],\n",
      "        [-0.6497,  1.3677, -0.4042,  0.5416, -0.7178, -2.0651, -2.0946],\n",
      "        [-0.9767,  1.6083, -0.1367,  0.4936, -0.1967, -1.8067, -1.7887],\n",
      "        [-1.1415,  1.7899,  0.0283,  0.3793,  0.0206, -1.6904, -1.6399],\n",
      "        [-1.2173,  1.8785,  0.1109,  0.3153,  0.1079, -1.6381, -1.5771],\n",
      "        [-1.2546,  1.9225,  0.1519,  0.2846,  0.1451, -1.6144, -1.5490],\n",
      "        [-1.2745,  1.9471,  0.1742,  0.2693,  0.1622, -1.6043, -1.5361],\n",
      "        [-1.2859,  1.9627,  0.1879,  0.2610,  0.1706, -1.6005, -1.5305],\n",
      "        [-1.2929,  1.9733,  0.1969,  0.2563,  0.1750, -1.5997, -1.5284],\n",
      "        [-1.2973,  1.9807,  0.2032,  0.2534,  0.1774, -1.6001, -1.5280],\n",
      "        [-1.3001,  1.9860,  0.2077,  0.2515,  0.1788, -1.6010, -1.5283],\n",
      "        [-1.3020,  1.9898,  0.2109,  0.2503,  0.1795, -1.6020, -1.5289],\n",
      "        [-1.3032,  1.9926,  0.2131,  0.2495,  0.1800, -1.6028, -1.5295],\n",
      "        [-1.3040,  1.9945,  0.2147,  0.2490,  0.1803, -1.6036, -1.5301],\n",
      "        [-1.3046,  1.9959,  0.2159,  0.2487,  0.1804, -1.6042, -1.5306]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "out:  tensor([[ 0.0484,  0.5751, -0.3427, -0.2045, -0.8577, -1.0213, -0.9938],\n",
      "        [-0.1873,  1.1364, -0.4779,  0.0901, -1.3012, -2.0166, -2.0407],\n",
      "        [-0.6482,  1.2748, -0.1205,  0.4680, -0.6398, -1.9340, -1.9796],\n",
      "        [-0.9531,  1.4874,  0.2411,  0.3819, -0.1319, -1.6395, -1.6487],\n",
      "        [-1.1058,  1.6498,  0.4583,  0.2599,  0.0767, -1.4995, -1.4858],\n",
      "        [-1.1774,  1.7296,  0.5672,  0.1952,  0.1598, -1.4344, -1.4142],\n",
      "        [-1.2127,  1.7699,  0.6224,  0.1641,  0.1950, -1.4032, -1.3804],\n",
      "        [-1.2314,  1.7930,  0.6535,  0.1482,  0.2113, -1.3882, -1.3638],\n",
      "        [-1.2420,  1.8078,  0.6730,  0.1393,  0.2195, -1.3812, -1.3558],\n",
      "        [-1.2484,  1.8181,  0.6861,  0.1341,  0.2238, -1.3781, -1.3521],\n",
      "        [-1.2523,  1.8254,  0.6952,  0.1307,  0.2263, -1.3771, -1.3506],\n",
      "        [-1.2548,  1.8305,  0.7016,  0.1285,  0.2277, -1.3770, -1.3502],\n",
      "        [-1.2564,  1.8342,  0.7062,  0.1271,  0.2286, -1.3773, -1.3502],\n",
      "        [-1.2574,  1.8369,  0.7094,  0.1262,  0.2291, -1.3777, -1.3505],\n",
      "        [-1.2582,  1.8388,  0.7116,  0.1256,  0.2294, -1.3781, -1.3508],\n",
      "        [-1.2586,  1.8401,  0.7132,  0.1251,  0.2296, -1.3785, -1.3511]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "out:  tensor([[ 0.0410,  0.5637, -0.3046, -0.2039, -0.8423, -1.0112, -0.9835],\n",
      "        [-0.2079,  1.0958, -0.3376,  0.0812, -1.2433, -1.9629, -1.9902],\n",
      "        [-0.6628,  1.2127,  0.1473,  0.4046, -0.5646, -1.8261, -1.8858],\n",
      "        [-0.9512,  1.4081,  0.5984,  0.2873, -0.0739, -1.5046, -1.5408],\n",
      "        [-1.0950,  1.5554,  0.8666,  0.1634,  0.1232, -1.3439, -1.3678],\n",
      "        [-1.1633,  1.6275,  1.0013,  0.1020,  0.1998, -1.2648, -1.2872],\n",
      "        [-1.1967,  1.6642,  1.0706,  0.0729,  0.2320, -1.2248, -1.2473],\n",
      "        [-1.2141,  1.6855,  1.1100,  0.0578,  0.2470, -1.2049, -1.2276],\n",
      "        [-1.2236,  1.6993,  1.1346,  0.0492,  0.2547, -1.1954, -1.2183],\n",
      "        [-1.2290,  1.7087,  1.1508,  0.0441,  0.2588, -1.1914, -1.2143],\n",
      "        [-1.2322,  1.7152,  1.1617,  0.0409,  0.2610, -1.1901, -1.2130],\n",
      "        [-1.2341,  1.7196,  1.1691,  0.0389,  0.2623, -1.1900, -1.2129],\n",
      "        [-1.2353,  1.7227,  1.1741,  0.0376,  0.2630, -1.1904, -1.2133],\n",
      "        [-1.2360,  1.7249,  1.1774,  0.0369,  0.2634, -1.1909, -1.2139],\n",
      "        [-1.2365,  1.7264,  1.1797,  0.0364,  0.2636, -1.1914, -1.2144],\n",
      "        [-1.2369,  1.7274,  1.1812,  0.0361,  0.2637, -1.1919, -1.2148]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "out:  tensor([[ 3.3040e-02,  5.5608e-01, -2.6925e-01, -2.0307e-01, -8.3013e-01,\n",
      "         -1.0060e+00, -9.7820e-01],\n",
      "        [-2.3342e-01,  1.0658e+00, -2.0324e-01,  7.5664e-02, -1.1899e+00,\n",
      "         -1.9240e+00, -1.9537e+00],\n",
      "        [-6.8823e-01,  1.1693e+00,  4.0234e-01,  3.4880e-01, -4.9597e-01,\n",
      "         -1.7445e+00, -1.8152e+00],\n",
      "        [-9.6457e-01,  1.3538e+00,  9.3671e-01,  2.0728e-01, -2.6307e-02,\n",
      "         -1.4086e+00, -1.4679e+00],\n",
      "        [-1.1020e+00,  1.4878e+00,  1.2495e+00,  8.5705e-02,  1.5666e-01,\n",
      "         -1.2379e+00, -1.2931e+00],\n",
      "        [-1.1670e+00,  1.5517e+00,  1.4042e+00,  2.8591e-02,  2.2551e-01,\n",
      "         -1.1552e+00, -1.2114e+00],\n",
      "        [-1.1979e+00,  1.5839e+00,  1.4830e+00,  1.2435e-03,  2.5416e-01,\n",
      "         -1.1156e+00, -1.1728e+00],\n",
      "        [-1.2133e+00,  1.6026e+00,  1.5277e+00, -1.3229e-02,  2.6753e-01,\n",
      "         -1.0975e+00, -1.1554e+00],\n",
      "        [-1.2212e+00,  1.6144e+00,  1.5551e+00, -2.1336e-02,  2.7412e-01,\n",
      "         -1.0899e+00, -1.1484e+00],\n",
      "        [-1.2254e+00,  1.6220e+00,  1.5723e+00, -2.5919e-02,  2.7737e-01,\n",
      "         -1.0875e+00, -1.1464e+00],\n",
      "        [-1.2276e+00,  1.6270e+00,  1.5833e+00, -2.8473e-02,  2.7892e-01,\n",
      "         -1.0873e+00, -1.1465e+00],\n",
      "        [-1.2289e+00,  1.6304e+00,  1.5902e+00, -2.9877e-02,  2.7962e-01,\n",
      "         -1.0881e+00, -1.1475e+00],\n",
      "        [-1.2297e+00,  1.6326e+00,  1.5946e+00, -3.0644e-02,  2.7991e-01,\n",
      "         -1.0890e+00, -1.1486e+00],\n",
      "        [-1.2303e+00,  1.6341e+00,  1.5974e+00, -3.1066e-02,  2.8000e-01,\n",
      "         -1.0900e+00, -1.1496e+00],\n",
      "        [-1.2306e+00,  1.6352e+00,  1.5993e+00, -3.1301e-02,  2.8001e-01,\n",
      "         -1.0908e+00, -1.1504e+00],\n",
      "        [-1.2309e+00,  1.6359e+00,  1.6005e+00, -3.1435e-02,  2.7997e-01,\n",
      "         -1.0914e+00, -1.1511e+00]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "out:  tensor([[ 0.0247,  0.5510, -0.2359, -0.2022, -0.8205, -1.0045, -0.9764],\n",
      "        [-0.2622,  1.0423, -0.0735,  0.0716, -1.1413, -1.8966, -1.9275],\n",
      "        [-0.7208,  1.1374,  0.6442,  0.2985, -0.4383, -1.6866, -1.7639],\n",
      "        [-0.9901,  1.3143,  1.2528,  0.1389,  0.0069, -1.3468, -1.4203],\n",
      "        [-1.1242,  1.4359,  1.6005,  0.0217,  0.1730, -1.1768, -1.2481],\n",
      "        [-1.1872,  1.4916,  1.7692, -0.0317,  0.2323, -1.0981, -1.1689],\n",
      "        [-1.2166,  1.5190,  1.8550, -0.0576,  0.2556, -1.0625, -1.1331],\n",
      "        [-1.2309,  1.5344,  1.9031, -0.0712,  0.2655, -1.0473, -1.1178],\n",
      "        [-1.2381,  1.5437,  1.9315, -0.0785,  0.2696, -1.0417, -1.1123],\n",
      "        [-1.2420,  1.5494,  1.9483, -0.0822,  0.2711, -1.0405, -1.1111],\n",
      "        [-1.2442,  1.5531,  1.9583, -0.0841,  0.2713, -1.0412, -1.1116],\n",
      "        [-1.2456,  1.5555,  1.9642, -0.0851,  0.2712, -1.0423, -1.1126],\n",
      "        [-1.2465,  1.5571,  1.9677, -0.0856,  0.2709, -1.0435, -1.1137],\n",
      "        [-1.2471,  1.5581,  1.9699, -0.0859,  0.2706, -1.0445, -1.1146],\n",
      "        [-1.2476,  1.5589,  1.9712, -0.0860,  0.2704, -1.0453, -1.1152],\n",
      "        [-1.2479,  1.5593,  1.9721, -0.0862,  0.2701, -1.0459, -1.1158]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "out:  tensor([[ 0.0199,  0.5754, -0.2158, -0.2130, -0.8585, -1.0514, -1.0242],\n",
      "        [-0.2967,  1.0426,  0.0547,  0.0709, -1.1250, -1.9134, -1.9474],\n",
      "        [-0.7616,  1.1184,  0.8808,  0.2549, -0.3951, -1.6526, -1.7347],\n",
      "        [-1.0264,  1.2868,  1.5495,  0.0810,  0.0244, -1.3109, -1.3898],\n",
      "        [-1.1588,  1.3957,  1.9211, -0.0303,  0.1722, -1.1469, -1.2197],\n",
      "        [-1.2203,  1.4428,  2.0970, -0.0792,  0.2217, -1.0749, -1.1430],\n",
      "        [-1.2485,  1.4649,  2.1856, -0.1028,  0.2396, -1.0441, -1.1096],\n",
      "        [-1.2621,  1.4769,  2.2352, -0.1148,  0.2458, -1.0326, -1.0969],\n",
      "        [-1.2690,  1.4837,  2.2633, -0.1207,  0.2475, -1.0293, -1.0928],\n",
      "        [-1.2728,  1.4877,  2.2791, -0.1234,  0.2475, -1.0294, -1.0924],\n",
      "        [-1.2751,  1.4903,  2.2879, -0.1246,  0.2470, -1.0305, -1.0931],\n",
      "        [-1.2766,  1.4919,  2.2930, -0.1251,  0.2465, -1.0318, -1.0940],\n",
      "        [-1.2776,  1.4930,  2.2960, -0.1254,  0.2460, -1.0328, -1.0947],\n",
      "        [-1.2782,  1.4938,  2.2978, -0.1255,  0.2456, -1.0337, -1.0954],\n",
      "        [-1.2787,  1.4943,  2.2991, -0.1256,  0.2452, -1.0345, -1.0961],\n",
      "        [-1.2790,  1.4947,  2.2999, -0.1257,  0.2449, -1.0352, -1.0967]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5])\n",
      "out:  tensor([[ 0.0072,  0.5441, -0.1732, -0.2007, -0.8041, -0.9914, -0.9766],\n",
      "        [-0.3241,  1.0022,  0.1682,  0.0629, -1.0491, -1.7927, -1.8809],\n",
      "        [-0.7927,  1.0837,  1.0665,  0.2057, -0.3435, -1.4717, -1.6706],\n",
      "        [-1.0553,  1.2460,  1.7810,  0.0228,  0.0504, -1.0833, -1.3283],\n",
      "        [-1.1865,  1.3440,  2.1661, -0.0846,  0.1839, -0.8975, -1.1586],\n",
      "        [-1.2459,  1.3841,  2.3439, -0.1316,  0.2275, -0.8168, -1.0828],\n",
      "        [-1.2727,  1.4021,  2.4328, -0.1544,  0.2425, -0.7820, -1.0513],\n",
      "        [-1.2858,  1.4112,  2.4795, -0.1654,  0.2478, -0.7672, -1.0384],\n",
      "        [-1.2926,  1.4161,  2.5047, -0.1705,  0.2492, -0.7616, -1.0340],\n",
      "        [-1.2964,  1.4190,  2.5184, -0.1729,  0.2493, -0.7599, -1.0331],\n",
      "        [-1.2988,  1.4208,  2.5259, -0.1740,  0.2489, -0.7598, -1.0333],\n",
      "        [-1.3003,  1.4220,  2.5302, -0.1745,  0.2485, -0.7602, -1.0338],\n",
      "        [-1.3012,  1.4228,  2.5327, -0.1747,  0.2481, -0.7607, -1.0343],\n",
      "        [-1.3019,  1.4235,  2.5343, -0.1748,  0.2478, -0.7613, -1.0348],\n",
      "        [-1.3024,  1.4238,  2.5352, -0.1749,  0.2475, -0.7617, -1.0352],\n",
      "        [-1.3027,  1.4241,  2.5357, -0.1749,  0.2474, -0.7619, -1.0354]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5])\n",
      "out:  tensor([[ 3.2082e-04,  5.0981e-01, -1.6864e-01, -1.9512e-01, -7.5703e-01,\n",
      "         -8.7477e-01, -9.2007e-01],\n",
      "        [-3.2893e-01,  9.0258e-01,  1.4306e-01,  4.5141e-02, -9.2823e-01,\n",
      "         -1.4419e+00, -1.6973e+00],\n",
      "        [-7.6687e-01,  9.4898e-01,  9.6127e-01,  1.2724e-01, -2.2483e-01,\n",
      "         -9.3735e-01, -1.3907e+00],\n",
      "        [-9.9849e-01,  1.0807e+00,  1.6132e+00, -8.5470e-02,  1.5759e-01,\n",
      "         -4.3817e-01, -1.0043e+00],\n",
      "        [-1.1126e+00,  1.1610e+00,  1.9604e+00, -2.0901e-01,  2.9584e-01,\n",
      "         -1.8921e-01, -8.1071e-01],\n",
      "        [-1.1622e+00,  1.1954e+00,  2.1238e+00, -2.6802e-01,  3.4983e-01,\n",
      "         -7.2098e-02, -7.1998e-01],\n",
      "        [-1.1839e+00,  1.2122e+00,  2.2072e+00, -2.9885e-01,  3.7402e-01,\n",
      "         -1.4570e-02, -6.7724e-01],\n",
      "        [-1.1938e+00,  1.2213e+00,  2.2537e+00, -3.1604e-01,  3.8584e-01,\n",
      "          1.5268e-02, -6.5659e-01],\n",
      "        [-1.1988e+00,  1.2264e+00,  2.2802e+00, -3.2551e-01,  3.9192e-01,\n",
      "          3.1004e-02, -6.4642e-01],\n",
      "        [-1.2014e+00,  1.2294e+00,  2.2956e+00, -3.3086e-01,  3.9503e-01,\n",
      "          3.9547e-02, -6.4140e-01],\n",
      "        [-1.2030e+00,  1.2313e+00,  2.3046e+00, -3.3388e-01,  3.9665e-01,\n",
      "          4.4123e-02, -6.3913e-01],\n",
      "        [-1.2040e+00,  1.2325e+00,  2.3100e+00, -3.3563e-01,  3.9747e-01,\n",
      "          4.6607e-02, -6.3811e-01],\n",
      "        [-1.2047e+00,  1.2333e+00,  2.3134e+00, -3.3670e-01,  3.9789e-01,\n",
      "          4.7995e-02, -6.3772e-01],\n",
      "        [-1.2052e+00,  1.2339e+00,  2.3156e+00, -3.3739e-01,  3.9810e-01,\n",
      "          4.8779e-02, -6.3763e-01],\n",
      "        [-1.2055e+00,  1.2343e+00,  2.3170e+00, -3.3785e-01,  3.9819e-01,\n",
      "          4.9225e-02, -6.3768e-01],\n",
      "        [-1.2058e+00,  1.2345e+00,  2.3180e+00, -3.3817e-01,  3.9823e-01,\n",
      "          4.9476e-02, -6.3780e-01]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5])\n",
      "out:  tensor([[-0.0134,  0.5003, -0.1601, -0.1873, -0.7328, -0.8145, -0.9056],\n",
      "        [-0.3670,  0.8290,  0.1762,  0.0500, -0.7852, -1.1670, -1.5424],\n",
      "        [-0.7755,  0.8661,  0.9503,  0.0522, -0.0951, -0.5183, -1.1453],\n",
      "        [-0.9804,  0.9796,  1.5359, -0.1767,  0.2465,  0.0348, -0.7429],\n",
      "        [-1.0754,  1.0408,  1.8340, -0.3024,  0.3782,  0.3188, -0.5319],\n",
      "        [-1.1132,  1.0648,  1.9719, -0.3634,  0.4384,  0.4620, -0.4207],\n",
      "        [-1.1285,  1.0752,  2.0424, -0.3964,  0.4706,  0.5404, -0.3575],\n",
      "        [-1.1350,  1.0803,  2.0827, -0.4158,  0.4897,  0.5870, -0.3190],\n",
      "        [-1.1379,  1.0829,  2.1070, -0.4277,  0.5015,  0.6159, -0.2948],\n",
      "        [-1.1394,  1.0841,  2.1216, -0.4350,  0.5090,  0.6342, -0.2793],\n",
      "        [-1.1403,  1.0847,  2.1304, -0.4395,  0.5139,  0.6459, -0.2693],\n",
      "        [-1.1409,  1.0851,  2.1358, -0.4424,  0.5171,  0.6535, -0.2627],\n",
      "        [-1.1415,  1.0853,  2.1391, -0.4442,  0.5192,  0.6585, -0.2583],\n",
      "        [-1.1419,  1.0854,  2.1411, -0.4454,  0.5207,  0.6619, -0.2554],\n",
      "        [-1.1422,  1.0855,  2.1425, -0.4462,  0.5217,  0.6643, -0.2533],\n",
      "        [-1.1425,  1.0855,  2.1433, -0.4468,  0.5223,  0.6660, -0.2518]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5])\n",
      "out:  tensor([[-1.7208e-02,  4.6051e-01, -1.5208e-01, -1.8402e-01, -6.7737e-01,\n",
      "         -7.1940e-01, -8.3038e-01],\n",
      "        [-3.6509e-01,  7.6358e-01,  1.4958e-01,  2.4550e-02, -7.1172e-01,\n",
      "         -9.5863e-01, -1.4032e+00],\n",
      "        [-7.7403e-01,  7.8958e-01,  8.8220e-01,  2.1589e-03, -2.0195e-02,\n",
      "         -2.0855e-01, -9.6034e-01],\n",
      "        [-9.7737e-01,  8.8281e-01,  1.4254e+00, -2.4516e-01,  3.2159e-01,\n",
      "          4.3535e-01, -5.0185e-01],\n",
      "        [-1.0660e+00,  9.2800e-01,  1.6918e+00, -3.8496e-01,  4.6137e-01,\n",
      "          7.7541e-01, -2.4981e-01],\n",
      "        [-1.0999e+00,  9.4508e-01,  1.8118e+00, -4.5566e-01,  5.2482e-01,\n",
      "          9.4125e-01, -1.2312e-01],\n",
      "        [-1.1146e+00,  9.5450e-01,  1.8719e+00, -4.9465e-01,  5.5466e-01,\n",
      "          1.0240e+00, -6.0002e-02],\n",
      "        [-1.1217e+00,  9.6102e-01,  1.9062e+00, -5.1778e-01,  5.6919e-01,\n",
      "          1.0679e+00, -2.7551e-02],\n",
      "        [-1.1254e+00,  9.6565e-01,  1.9273e+00, -5.3187e-01,  5.7657e-01,\n",
      "          1.0923e+00, -1.0314e-02],\n",
      "        [-1.1275e+00,  9.6889e-01,  1.9408e+00, -5.4044e-01,  5.8048e-01,\n",
      "          1.1064e+00, -9.8877e-04],\n",
      "        [-1.1288e+00,  9.7114e-01,  1.9495e+00, -5.4560e-01,  5.8264e-01,\n",
      "          1.1147e+00,  4.0983e-03],\n",
      "        [-1.1297e+00,  9.7270e-01,  1.9552e+00, -5.4870e-01,  5.8388e-01,\n",
      "          1.1197e+00,  6.8933e-03],\n",
      "        [-1.1304e+00,  9.7380e-01,  1.9590e+00, -5.5055e-01,  5.8462e-01,\n",
      "          1.1228e+00,  8.4474e-03],\n",
      "        [-1.1308e+00,  9.7458e-01,  1.9615e+00, -5.5166e-01,  5.8507e-01,\n",
      "          1.1247e+00,  9.3272e-03],\n",
      "        [-1.1312e+00,  9.7513e-01,  1.9633e+00, -5.5234e-01,  5.8536e-01,\n",
      "          1.1259e+00,  9.8373e-03],\n",
      "        [-1.1315e+00,  9.7553e-01,  1.9645e+00, -5.5275e-01,  5.8554e-01,\n",
      "          1.1267e+00,  1.0142e-02]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5])\n",
      "out:  tensor([[-0.0268,  0.4425, -0.1429, -0.1800, -0.6449, -0.6623, -0.7963],\n",
      "        [-0.3894,  0.7132,  0.1651,  0.0126, -0.6202, -0.7699, -1.2906],\n",
      "        [-0.7917,  0.7369,  0.8684, -0.0587,  0.0569,  0.0735, -0.8102],\n",
      "        [-0.9844,  0.8103,  1.3551, -0.3230,  0.3768,  0.7591, -0.3400],\n",
      "        [-1.0619,  0.8334,  1.5729, -0.4755,  0.5142,  1.1173, -0.0751],\n",
      "        [-1.0900,  0.8354,  1.6578, -0.5567,  0.5794,  1.2885,  0.0628],\n",
      "        [-1.1012,  0.8347,  1.6930, -0.6033,  0.6119,  1.3726,  0.1357],\n",
      "        [-1.1060,  0.8346,  1.7098, -0.6315,  0.6290,  1.4168,  0.1758],\n",
      "        [-1.1082,  0.8350,  1.7190, -0.6488,  0.6386,  1.4415,  0.1987],\n",
      "        [-1.1092,  0.8355,  1.7245, -0.6595,  0.6442,  1.4559,  0.2122],\n",
      "        [-1.1098,  0.8360,  1.7279, -0.6661,  0.6476,  1.4646,  0.2203],\n",
      "        [-1.1102,  0.8364,  1.7301, -0.6702,  0.6498,  1.4699,  0.2253],\n",
      "        [-1.1105,  0.8367,  1.7316, -0.6727,  0.6513,  1.4733,  0.2284],\n",
      "        [-1.1107,  0.8369,  1.7326, -0.6743,  0.6522,  1.4754,  0.2304],\n",
      "        [-1.1109,  0.8370,  1.7333, -0.6753,  0.6529,  1.4769,  0.2318],\n",
      "        [-1.1110,  0.8371,  1.7337, -0.6760,  0.6534,  1.4779,  0.2327]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5])\n",
      "out:  tensor([[-3.6476e-02,  4.2668e-01, -1.3390e-01, -1.7639e-01, -6.1495e-01,\n",
      "         -6.1089e-01, -7.6529e-01],\n",
      "        [-4.1550e-01,  6.6867e-01,  1.8464e-01,  1.1310e-03, -5.3366e-01,\n",
      "         -5.9294e-01, -1.1886e+00],\n",
      "        [-8.1509e-01,  6.9083e-01,  8.6248e-01, -1.1600e-01,  1.2938e-01,\n",
      "          3.4083e-01, -6.7652e-01],\n",
      "        [-9.9783e-01,  7.4186e-01,  1.2872e+00, -3.9862e-01,  4.3570e-01,\n",
      "          1.0658e+00, -1.9207e-01],\n",
      "        [-1.0629e+00,  7.4203e-01,  1.4485e+00, -5.6282e-01,  5.7468e-01,\n",
      "          1.4367e+00,  8.4164e-02],\n",
      "        [-1.0826e+00,  7.3228e-01,  1.5010e+00, -6.4912e-01,  6.4057e-01,\n",
      "          1.6068e+00,  2.2418e-01],\n",
      "        [-1.0888e+00,  7.2693e-01,  1.5211e+00, -6.9703e-01,  6.7233e-01,\n",
      "          1.6870e+00,  2.9511e-01],\n",
      "        [-1.0908e+00,  7.2503e-01,  1.5310e+00, -7.2511e-01,  6.8849e-01,\n",
      "          1.7277e+00,  3.3268e-01],\n",
      "        [-1.0914e+00,  7.2457e-01,  1.5367e+00, -7.4192e-01,  6.9721e-01,\n",
      "          1.7498e+00,  3.5345e-01],\n",
      "        [-1.0915e+00,  7.2458e-01,  1.5403e+00, -7.5203e-01,  7.0219e-01,\n",
      "          1.7624e+00,  3.6534e-01],\n",
      "        [-1.0916e+00,  7.2468e-01,  1.5426e+00, -7.5811e-01,  7.0519e-01,\n",
      "          1.7697e+00,  3.7233e-01],\n",
      "        [-1.0916e+00,  7.2479e-01,  1.5440e+00, -7.6180e-01,  7.0707e-01,\n",
      "          1.7742e+00,  3.7655e-01],\n",
      "        [-1.0917e+00,  7.2488e-01,  1.5450e+00, -7.6405e-01,  7.0829e-01,\n",
      "          1.7770e+00,  3.7915e-01],\n",
      "        [-1.0918e+00,  7.2495e-01,  1.5457e+00, -7.6546e-01,  7.0911e-01,\n",
      "          1.7788e+00,  3.8080e-01],\n",
      "        [-1.0919e+00,  7.2500e-01,  1.5462e+00, -7.6636e-01,  7.0966e-01,\n",
      "          1.7800e+00,  3.8186e-01],\n",
      "        [-1.0919e+00,  7.2505e-01,  1.5465e+00, -7.6694e-01,  7.1005e-01,\n",
      "          1.7808e+00,  3.8256e-01]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5])\n",
      "out:  tensor([[-0.0464,  0.4138, -0.1242, -0.1730, -0.5890, -0.5649, -0.7397],\n",
      "        [-0.4439,  0.6332,  0.2119, -0.0088, -0.4581, -0.4286, -1.1058],\n",
      "        [-0.8444,  0.6583,  0.8766, -0.1657,  0.1847,  0.5894, -0.5801],\n",
      "        [-1.0214,  0.6955,  1.2596, -0.4589,  0.4736,  1.3491, -0.1039],\n",
      "        [-1.0805,  0.6845,  1.3896, -0.6242,  0.6058,  1.7297,  0.1613],\n",
      "        [-1.0974,  0.6712,  1.4286, -0.7080,  0.6666,  1.9004,  0.2908],\n",
      "        [-1.1026,  0.6650,  1.4435, -0.7530,  0.6951,  1.9795,  0.3544],\n",
      "        [-1.1044,  0.6628,  1.4512, -0.7786,  0.7090,  2.0191,  0.3869],\n",
      "        [-1.1051,  0.6623,  1.4559, -0.7934,  0.7161,  2.0401,  0.4043],\n",
      "        [-1.1054,  0.6622,  1.4589, -0.8019,  0.7200,  2.0518,  0.4139],\n",
      "        [-1.1057,  0.6623,  1.4609, -0.8069,  0.7223,  2.0585,  0.4192],\n",
      "        [-1.1059,  0.6624,  1.4623, -0.8098,  0.7236,  2.0624,  0.4223],\n",
      "        [-1.1061,  0.6625,  1.4632, -0.8115,  0.7244,  2.0649,  0.4242],\n",
      "        [-1.1063,  0.6626,  1.4638, -0.8126,  0.7250,  2.0664,  0.4253],\n",
      "        [-1.1064,  0.6626,  1.4643, -0.8132,  0.7253,  2.0675,  0.4260],\n",
      "        [-1.1065,  0.6627,  1.4646, -0.8136,  0.7255,  2.0682,  0.4264]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5])\n",
      "out:  tensor([[-0.0565,  0.4023, -0.1149, -0.1699, -0.5651, -0.5212, -0.7169],\n",
      "        [-0.4735,  0.6015,  0.2397, -0.0191, -0.3887, -0.2684, -1.0313],\n",
      "        [-0.8774,  0.6287,  0.8914, -0.2119,  0.2331,  0.8332, -0.4956],\n",
      "        [-1.0525,  0.6534,  1.2378, -0.5113,  0.5058,  1.6301, -0.0332],\n",
      "        [-1.1101,  0.6341,  1.3445, -0.6723,  0.6298,  2.0245,  0.2161],\n",
      "        [-1.1272,  0.6179,  1.3749, -0.7505,  0.6854,  2.2007,  0.3343],\n",
      "        [-1.1331,  0.6105,  1.3867, -0.7913,  0.7106,  2.2830,  0.3914],\n",
      "        [-1.1356,  0.6075,  1.3929, -0.8137,  0.7226,  2.3242,  0.4203],\n",
      "        [-1.1368,  0.6063,  1.3967, -0.8263,  0.7287,  2.3461,  0.4355],\n",
      "        [-1.1374,  0.6057,  1.3990, -0.8333,  0.7319,  2.3583,  0.4438],\n",
      "        [-1.1379,  0.6054,  1.4006, -0.8373,  0.7337,  2.3652,  0.4484],\n",
      "        [-1.1383,  0.6053,  1.4016, -0.8395,  0.7348,  2.3694,  0.4510],\n",
      "        [-1.1385,  0.6053,  1.4023, -0.8408,  0.7355,  2.3719,  0.4526],\n",
      "        [-1.1387,  0.6052,  1.4029, -0.8416,  0.7359,  2.3735,  0.4535],\n",
      "        [-1.1389,  0.6053,  1.4033, -0.8421,  0.7362,  2.3746,  0.4541],\n",
      "        [-1.1391,  0.6053,  1.4035, -0.8424,  0.7363,  2.3753,  0.4544]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5])\n",
      "out:  tensor([[-0.0667,  0.3918, -0.1058, -0.1670, -0.5430, -0.4788, -0.6963],\n",
      "        [-0.5039,  0.5724,  0.2673, -0.0298, -0.3241, -0.1102, -0.9630],\n",
      "        [-0.9125,  0.6001,  0.9043, -0.2552,  0.2768,  1.0753, -0.4193],\n",
      "        [-1.0883,  0.6130,  1.2168, -0.5564,  0.5346,  1.9123,  0.0251],\n",
      "        [-1.1467,  0.5867,  1.3046, -0.7095,  0.6509,  2.3248,  0.2567],\n",
      "        [-1.1651,  0.5677,  1.3281, -0.7805,  0.7021,  2.5108,  0.3651],\n",
      "        [-1.1720,  0.5587,  1.3370, -0.8163,  0.7251,  2.5988,  0.4175],\n",
      "        [-1.1751,  0.5546,  1.3416, -0.8354,  0.7360,  2.6436,  0.4442],\n",
      "        [-1.1767,  0.5525,  1.3443, -0.8458,  0.7414,  2.6677,  0.4583],\n",
      "        [-1.1776,  0.5514,  1.3459, -0.8513,  0.7443,  2.6813,  0.4662],\n",
      "        [-1.1782,  0.5507,  1.3469, -0.8543,  0.7460,  2.6891,  0.4706],\n",
      "        [-1.1787,  0.5502,  1.3476, -0.8560,  0.7469,  2.6939,  0.4732],\n",
      "        [-1.1790,  0.5500,  1.3481, -0.8569,  0.7475,  2.6969,  0.4748],\n",
      "        [-1.1792,  0.5498,  1.3485, -0.8574,  0.7479,  2.6988,  0.4757],\n",
      "        [-1.1794,  0.5497,  1.3488, -0.8577,  0.7482,  2.7001,  0.4763],\n",
      "        [-1.1795,  0.5496,  1.3490, -0.8579,  0.7484,  2.7009,  0.4767]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5])\n",
      "out:  tensor([[-0.0770,  0.3822, -0.0972, -0.1645, -0.5224, -0.4371, -0.6778],\n",
      "        [-0.5343,  0.5454,  0.2943, -0.0407, -0.2639,  0.0466, -0.8996],\n",
      "        [-0.9473,  0.5723,  0.9139, -0.2953,  0.3171,  1.3130, -0.3510],\n",
      "        [-1.1250,  0.5744,  1.1937, -0.5941,  0.5612,  2.1883,  0.0705],\n",
      "        [-1.1852,  0.5425,  1.2641, -0.7370,  0.6711,  2.6190,  0.2835],\n",
      "        [-1.2052,  0.5212,  1.2805, -0.8002,  0.7195,  2.8144,  0.3831],\n",
      "        [-1.2132,  0.5109,  1.2854, -0.8311,  0.7413,  2.9075,  0.4319],\n",
      "        [-1.2169,  0.5058,  1.2871, -0.8470,  0.7518,  2.9550,  0.4571],\n",
      "        [-1.2188,  0.5030,  1.2877, -0.8553,  0.7572,  2.9805,  0.4707],\n",
      "        [-1.2198,  0.5013,  1.2878, -0.8595,  0.7601,  2.9948,  0.4783],\n",
      "        [-1.2204,  0.5001,  1.2877, -0.8616,  0.7618,  3.0031,  0.4827],\n",
      "        [-1.2208,  0.4994,  1.2876, -0.8627,  0.7628,  3.0082,  0.4854],\n",
      "        [-1.2210,  0.4989,  1.2875, -0.8633,  0.7634,  3.0113,  0.4871],\n",
      "        [-1.2212,  0.4986,  1.2874, -0.8635,  0.7639,  3.0134,  0.4881],\n",
      "        [-1.2213,  0.4984,  1.2874, -0.8636,  0.7641,  3.0147,  0.4888],\n",
      "        [-1.2213,  0.4982,  1.2873, -0.8637,  0.7643,  3.0157,  0.4893]],\n",
      "       dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "y_batch:  tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 35\u001b[0m\n\u001b[0;32m     32\u001b[0m x_batch \u001b[38;5;241m=\u001b[39m x_batch\u001b[38;5;241m.\u001b[39mlong()\n\u001b[0;32m     33\u001b[0m y_batch \u001b[38;5;241m=\u001b[39m y_batch\u001b[38;5;241m.\u001b[39mlong()\n\u001b[1;32m---> 35\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout: \u001b[39m\u001b[38;5;124m\"\u001b[39m, out)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_batch: \u001b[39m\u001b[38;5;124m\"\u001b[39m, y_batch)\n",
      "File \u001b[1;32md:\\Wifi_based_HAR\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Wifi_based_HAR\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[12], line 15\u001b[0m, in \u001b[0;36mLSTMClassifier.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     14\u001b[0m     h0, c0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_hidden(x)\n\u001b[1;32m---> 15\u001b[0m     out, (hn, cn) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdouble\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mh0\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdouble\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc0\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdouble\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m# out = self.fc(out[:, -1, :].double())\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(out[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\u001b[38;5;241m.\u001b[39mdouble())\n",
      "File \u001b[1;32md:\\Wifi_based_HAR\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Wifi_based_HAR\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\Wifi_based_HAR\\venv\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:879\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    876\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[0;32m    878\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 879\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    882\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[0;32m    883\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### training loop\n",
    "input_dim = 468\n",
    "hidden_dim = 256\n",
    "layer_dim = 3\n",
    "output_dim = 7\n",
    "seq_dim = 128\n",
    "\n",
    "lr = 0.0005\n",
    "n_epochs = 10\n",
    "iterations_per_epoch = len(trn_dl)\n",
    "best_acc = 0\n",
    "patience, trials = 100, 0\n",
    "\n",
    "model = LSTMClassifier(input_dim, hidden_dim, layer_dim, output_dim)\n",
    "# model = model.cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
    "sched = CyclicLR(opt, cosine(t_max=iterations_per_epoch * 2, eta_min=lr/100))\n",
    "\n",
    "print('Start model training')\n",
    "\n",
    "model = model.double()\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "\n",
    "    for i, (x_batch, y_batch) in enumerate(trn_dl):\n",
    "        model.train()\n",
    "        # x_batch = x_batch.cuda()\n",
    "        # y_batch = y_batch.cuda()\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        x_batch = x_batch.long()\n",
    "        y_batch = y_batch.long()\n",
    "\n",
    "        out = model(x_batch)\n",
    "\n",
    "        print(\"out: \", out)\n",
    "        print(\"y_batch: \", y_batch)\n",
    "\n",
    "        loss = criterion(out, y_batch)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        sched.step()\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    for x_val, y_val in val_dl:\n",
    "        # x_val, y_val = [t.cuda() for t in (x_val, y_val)]\n",
    "        out = model(x_val)\n",
    "        preds = F.log_softmax(out, dim=1).argmax(dim=1)\n",
    "        total += y_val.size(0)\n",
    "        correct += (preds == y_val).sum().item()\n",
    "\n",
    "    acc = correct / total\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        print(f'Epoch: {epoch:3d}. Loss: {loss.item():.4f}. Acc.: {acc:2.2%}')\n",
    "\n",
    "    if acc > best_acc:\n",
    "        trials = 0\n",
    "        best_acc = acc\n",
    "        torch.save(model.state_dict(), 'best.pth')\n",
    "        print(f'Epoch {epoch} best model saved with accuracy: {best_acc:2.2%}')\n",
    "    else:\n",
    "        trials += 1\n",
    "        if trials >= patience:\n",
    "            print(f'Early stopping on epoch {epoch}')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
